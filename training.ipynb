{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3d76c1-16d9-4730-bf1f-d3de11c889ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1224 images belonging to 2 classes.\n",
      "Epoch 1/200\n",
      "39/39 [==============================] - 10s 229ms/step - loss: 0.4517 - accuracy: 0.8595 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "39/39 [==============================] - 9s 232ms/step - loss: 0.3973 - accuracy: 0.8709 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "39/39 [==============================] - 9s 232ms/step - loss: 0.3606 - accuracy: 0.8709 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "39/39 [==============================] - 9s 236ms/step - loss: 0.3576 - accuracy: 0.8709 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "39/39 [==============================] - 9s 230ms/step - loss: 0.3163 - accuracy: 0.8709 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "39/39 [==============================] - 9s 244ms/step - loss: 0.3164 - accuracy: 0.8734 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "39/39 [==============================] - 9s 239ms/step - loss: 0.2887 - accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "39/39 [==============================] - 9s 235ms/step - loss: 0.2672 - accuracy: 0.8791 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "39/39 [==============================] - 9s 238ms/step - loss: 0.2721 - accuracy: 0.8832 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "39/39 [==============================] - 9s 236ms/step - loss: 0.2732 - accuracy: 0.8824 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "39/39 [==============================] - 10s 239ms/step - loss: 0.2685 - accuracy: 0.8775 - lr: 9.0000e-04\n",
      "Epoch 12/200\n",
      "39/39 [==============================] - 10s 240ms/step - loss: 0.2523 - accuracy: 0.8954 - lr: 9.0000e-04\n",
      "Epoch 13/200\n",
      "39/39 [==============================] - 9s 234ms/step - loss: 0.2645 - accuracy: 0.8889 - lr: 9.0000e-04\n",
      "Epoch 14/200\n",
      "39/39 [==============================] - 10s 243ms/step - loss: 0.2463 - accuracy: 0.9069 - lr: 9.0000e-04\n",
      "Epoch 15/200\n",
      "39/39 [==============================] - 10s 243ms/step - loss: 0.2219 - accuracy: 0.9011 - lr: 9.0000e-04\n",
      "Epoch 16/200\n",
      "39/39 [==============================] - 10s 245ms/step - loss: 0.2161 - accuracy: 0.9044 - lr: 9.0000e-04\n",
      "Epoch 17/200\n",
      "39/39 [==============================] - 10s 243ms/step - loss: 0.2254 - accuracy: 0.8995 - lr: 9.0000e-04\n",
      "Epoch 18/200\n",
      "39/39 [==============================] - 10s 263ms/step - loss: 0.2159 - accuracy: 0.9052 - lr: 9.0000e-04\n",
      "Epoch 19/200\n",
      "39/39 [==============================] - 10s 242ms/step - loss: 0.2048 - accuracy: 0.9118 - lr: 9.0000e-04\n",
      "Epoch 20/200\n",
      "39/39 [==============================] - 10s 245ms/step - loss: 0.1944 - accuracy: 0.9158 - lr: 9.0000e-04\n",
      "Epoch 21/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.1987 - accuracy: 0.9216 - lr: 8.1000e-04\n",
      "Epoch 22/200\n",
      "39/39 [==============================] - 10s 241ms/step - loss: 0.1905 - accuracy: 0.9297 - lr: 8.1000e-04\n",
      "Epoch 23/200\n",
      "39/39 [==============================] - 10s 244ms/step - loss: 0.1787 - accuracy: 0.9183 - lr: 8.1000e-04\n",
      "Epoch 24/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.2056 - accuracy: 0.9208 - lr: 8.1000e-04\n",
      "Epoch 25/200\n",
      "39/39 [==============================] - 10s 241ms/step - loss: 0.1933 - accuracy: 0.9191 - lr: 8.1000e-04\n",
      "Epoch 26/200\n",
      "39/39 [==============================] - 10s 246ms/step - loss: 0.1762 - accuracy: 0.9363 - lr: 8.1000e-04\n",
      "Epoch 27/200\n",
      "39/39 [==============================] - 10s 245ms/step - loss: 0.1736 - accuracy: 0.9281 - lr: 8.1000e-04\n",
      "Epoch 28/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.1783 - accuracy: 0.9330 - lr: 8.1000e-04\n",
      "Epoch 29/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.1694 - accuracy: 0.9314 - lr: 8.1000e-04\n",
      "Epoch 30/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.1641 - accuracy: 0.9387 - lr: 8.1000e-04\n",
      "Epoch 31/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.1584 - accuracy: 0.9346 - lr: 7.2900e-04\n",
      "Epoch 32/200\n",
      "39/39 [==============================] - 10s 244ms/step - loss: 0.1527 - accuracy: 0.9355 - lr: 7.2900e-04\n",
      "Epoch 33/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.1406 - accuracy: 0.9444 - lr: 7.2900e-04\n",
      "Epoch 34/200\n",
      "39/39 [==============================] - 10s 260ms/step - loss: 0.1474 - accuracy: 0.9436 - lr: 7.2900e-04\n",
      "Epoch 35/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.1589 - accuracy: 0.9314 - lr: 7.2900e-04\n",
      "Epoch 36/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.1581 - accuracy: 0.9379 - lr: 7.2900e-04\n",
      "Epoch 37/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.1335 - accuracy: 0.9469 - lr: 7.2900e-04\n",
      "Epoch 38/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.1403 - accuracy: 0.9510 - lr: 7.2900e-04\n",
      "Epoch 39/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.1128 - accuracy: 0.9510 - lr: 7.2900e-04\n",
      "Epoch 40/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.1336 - accuracy: 0.9551 - lr: 7.2900e-04\n",
      "Epoch 41/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.1311 - accuracy: 0.9502 - lr: 6.5610e-04\n",
      "Epoch 42/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.1053 - accuracy: 0.9592 - lr: 6.5610e-04\n",
      "Epoch 43/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.1250 - accuracy: 0.9575 - lr: 6.5610e-04\n",
      "Epoch 44/200\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.1368 - accuracy: 0.9485 - lr: 6.5610e-04\n",
      "Epoch 45/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.1298 - accuracy: 0.9526 - lr: 6.5610e-04\n",
      "Epoch 46/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.1077 - accuracy: 0.9673 - lr: 6.5610e-04\n",
      "Epoch 47/200\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.1113 - accuracy: 0.9600 - lr: 6.5610e-04\n",
      "Epoch 48/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.1161 - accuracy: 0.9518 - lr: 6.5610e-04\n",
      "Epoch 49/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.1003 - accuracy: 0.9632 - lr: 6.5610e-04\n",
      "Epoch 50/200\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 0.1028 - accuracy: 0.9616 - lr: 6.5610e-04\n",
      "Epoch 51/200\n",
      "39/39 [==============================] - 10s 264ms/step - loss: 0.1111 - accuracy: 0.9526 - lr: 5.9049e-04\n",
      "Epoch 52/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.1112 - accuracy: 0.9608 - lr: 5.9049e-04\n",
      "Epoch 53/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.1077 - accuracy: 0.9583 - lr: 5.9049e-04\n",
      "Epoch 54/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.1069 - accuracy: 0.9608 - lr: 5.9049e-04\n",
      "Epoch 55/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0991 - accuracy: 0.9632 - lr: 5.9049e-04\n",
      "Epoch 56/200\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.0758 - accuracy: 0.9763 - lr: 5.9049e-04\n",
      "Epoch 57/200\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.0905 - accuracy: 0.9755 - lr: 5.9049e-04\n",
      "Epoch 58/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0830 - accuracy: 0.9747 - lr: 5.9049e-04\n",
      "Epoch 59/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0885 - accuracy: 0.9714 - lr: 5.9049e-04\n",
      "Epoch 60/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0895 - accuracy: 0.9722 - lr: 5.9049e-04\n",
      "Epoch 61/200\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 0.0894 - accuracy: 0.9755 - lr: 5.3144e-04\n",
      "Epoch 62/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0888 - accuracy: 0.9698 - lr: 5.3144e-04\n",
      "Epoch 63/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0820 - accuracy: 0.9755 - lr: 5.3144e-04\n",
      "Epoch 64/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0810 - accuracy: 0.9796 - lr: 5.3144e-04\n",
      "Epoch 65/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0802 - accuracy: 0.9722 - lr: 5.3144e-04\n",
      "Epoch 66/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0769 - accuracy: 0.9763 - lr: 5.3144e-04\n",
      "Epoch 67/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0805 - accuracy: 0.9739 - lr: 5.3144e-04\n",
      "Epoch 68/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.0870 - accuracy: 0.9722 - lr: 5.3144e-04\n",
      "Epoch 69/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0974 - accuracy: 0.9714 - lr: 5.3144e-04\n",
      "Epoch 70/200\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.0988 - accuracy: 0.9624 - lr: 5.3144e-04\n",
      "Epoch 71/200\n",
      "39/39 [==============================] - 10s 264ms/step - loss: 0.0791 - accuracy: 0.9788 - lr: 4.7830e-04\n",
      "Epoch 72/200\n",
      "39/39 [==============================] - 10s 264ms/step - loss: 0.0726 - accuracy: 0.9763 - lr: 4.7830e-04\n",
      "Epoch 73/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0666 - accuracy: 0.9747 - lr: 4.7830e-04\n",
      "Epoch 74/200\n",
      "39/39 [==============================] - 10s 264ms/step - loss: 0.0629 - accuracy: 0.9820 - lr: 4.7830e-04\n",
      "Epoch 75/200\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 0.0627 - accuracy: 0.9869 - lr: 4.7830e-04\n",
      "Epoch 76/200\n",
      "39/39 [==============================] - 10s 263ms/step - loss: 0.0547 - accuracy: 0.9837 - lr: 4.7830e-04\n",
      "Epoch 77/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0720 - accuracy: 0.9828 - lr: 4.7830e-04\n",
      "Epoch 78/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0657 - accuracy: 0.9788 - lr: 4.7830e-04\n",
      "Epoch 79/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0627 - accuracy: 0.9853 - lr: 4.7830e-04\n",
      "Epoch 80/200\n",
      "39/39 [==============================] - 10s 264ms/step - loss: 0.0661 - accuracy: 0.9812 - lr: 4.7830e-04\n",
      "Epoch 81/200\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.0587 - accuracy: 0.9837 - lr: 4.3047e-04\n",
      "Epoch 82/200\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.0563 - accuracy: 0.9845 - lr: 4.3047e-04\n",
      "Epoch 83/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0479 - accuracy: 0.9853 - lr: 4.3047e-04\n",
      "Epoch 84/200\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.0563 - accuracy: 0.9796 - lr: 4.3047e-04\n",
      "Epoch 85/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0511 - accuracy: 0.9869 - lr: 4.3047e-04\n",
      "Epoch 86/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0607 - accuracy: 0.9779 - lr: 4.3047e-04\n",
      "Epoch 87/200\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.0580 - accuracy: 0.9837 - lr: 4.3047e-04\n",
      "Epoch 88/200\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 0.0503 - accuracy: 0.9894 - lr: 4.3047e-04\n",
      "Epoch 89/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0493 - accuracy: 0.9837 - lr: 4.3047e-04\n",
      "Epoch 90/200\n",
      "39/39 [==============================] - 10s 264ms/step - loss: 0.0489 - accuracy: 0.9902 - lr: 4.3047e-04\n",
      "Epoch 91/200\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.0410 - accuracy: 0.9861 - lr: 3.8742e-04\n",
      "Epoch 92/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0501 - accuracy: 0.9845 - lr: 3.8742e-04\n",
      "Epoch 93/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.0513 - accuracy: 0.9845 - lr: 3.8742e-04\n",
      "Epoch 94/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0457 - accuracy: 0.9894 - lr: 3.8742e-04\n",
      "Epoch 95/200\n",
      "39/39 [==============================] - 10s 257ms/step - loss: 0.0514 - accuracy: 0.9845 - lr: 3.8742e-04\n",
      "Epoch 96/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.0432 - accuracy: 0.9853 - lr: 3.8742e-04\n",
      "Epoch 97/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0467 - accuracy: 0.9886 - lr: 3.8742e-04\n",
      "Epoch 98/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0421 - accuracy: 0.9902 - lr: 3.8742e-04\n",
      "Epoch 99/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0522 - accuracy: 0.9869 - lr: 3.8742e-04\n",
      "Epoch 100/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0432 - accuracy: 0.9869 - lr: 3.8742e-04\n",
      "Epoch 101/200\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 0.0608 - accuracy: 0.9820 - lr: 3.4868e-04\n",
      "Epoch 102/200\n",
      "39/39 [==============================] - 10s 257ms/step - loss: 0.0520 - accuracy: 0.9869 - lr: 3.4868e-04\n",
      "Epoch 103/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.0556 - accuracy: 0.9812 - lr: 3.4868e-04\n",
      "Epoch 104/200\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.0442 - accuracy: 0.9894 - lr: 3.4868e-04\n",
      "Epoch 105/200\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.0503 - accuracy: 0.9886 - lr: 3.4868e-04\n",
      "Epoch 106/200\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.0461 - accuracy: 0.9894 - lr: 3.4868e-04\n",
      "Epoch 107/200\n",
      "39/39 [==============================] - 10s 260ms/step - loss: 0.0495 - accuracy: 0.9861 - lr: 3.4868e-04\n",
      "Epoch 108/200\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.0500 - accuracy: 0.9853 - lr: 3.4868e-04\n",
      "Epoch 109/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0438 - accuracy: 0.9902 - lr: 3.4868e-04\n",
      "Epoch 110/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0384 - accuracy: 0.9902 - lr: 3.4868e-04\n",
      "Epoch 111/200\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.0399 - accuracy: 0.9845 - lr: 3.1381e-04\n",
      "Epoch 112/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0411 - accuracy: 0.9894 - lr: 3.1381e-04\n",
      "Epoch 113/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0406 - accuracy: 0.9886 - lr: 3.1381e-04\n",
      "Epoch 114/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0326 - accuracy: 0.9943 - lr: 3.1381e-04\n",
      "Epoch 115/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0382 - accuracy: 0.9861 - lr: 3.1381e-04\n",
      "Epoch 116/200\n",
      "39/39 [==============================] - 10s 257ms/step - loss: 0.0377 - accuracy: 0.9910 - lr: 3.1381e-04\n",
      "Epoch 117/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.0333 - accuracy: 0.9935 - lr: 3.1381e-04\n",
      "Epoch 118/200\n",
      "39/39 [==============================] - 10s 257ms/step - loss: 0.0347 - accuracy: 0.9902 - lr: 3.1381e-04\n",
      "Epoch 119/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0370 - accuracy: 0.9910 - lr: 3.1381e-04\n",
      "Epoch 120/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0418 - accuracy: 0.9861 - lr: 3.1381e-04\n",
      "Epoch 121/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0381 - accuracy: 0.9926 - lr: 2.8243e-04\n",
      "Epoch 122/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0388 - accuracy: 0.9894 - lr: 2.8243e-04\n",
      "Epoch 123/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0368 - accuracy: 0.9926 - lr: 2.8243e-04\n",
      "Epoch 124/200\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.0288 - accuracy: 0.9959 - lr: 2.8243e-04\n",
      "Epoch 125/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0335 - accuracy: 0.9894 - lr: 2.8243e-04\n",
      "Epoch 126/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0368 - accuracy: 0.9902 - lr: 2.8243e-04\n",
      "Epoch 127/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0289 - accuracy: 0.9943 - lr: 2.8243e-04\n",
      "Epoch 128/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0374 - accuracy: 0.9853 - lr: 2.8243e-04\n",
      "Epoch 129/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0333 - accuracy: 0.9886 - lr: 2.8243e-04\n",
      "Epoch 130/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0325 - accuracy: 0.9918 - lr: 2.8243e-04\n",
      "Epoch 131/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0363 - accuracy: 0.9918 - lr: 2.5419e-04\n",
      "Epoch 132/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0288 - accuracy: 0.9935 - lr: 2.5419e-04\n",
      "Epoch 133/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0352 - accuracy: 0.9910 - lr: 2.5419e-04\n",
      "Epoch 134/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.0276 - accuracy: 0.9935 - lr: 2.5419e-04\n",
      "Epoch 135/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0294 - accuracy: 0.9926 - lr: 2.5419e-04\n",
      "Epoch 136/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0302 - accuracy: 0.9951 - lr: 2.5419e-04\n",
      "Epoch 137/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0330 - accuracy: 0.9910 - lr: 2.5419e-04\n",
      "Epoch 138/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0315 - accuracy: 0.9910 - lr: 2.5419e-04\n",
      "Epoch 139/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0326 - accuracy: 0.9910 - lr: 2.5419e-04\n",
      "Epoch 140/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0320 - accuracy: 0.9894 - lr: 2.5419e-04\n",
      "Epoch 141/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0280 - accuracy: 0.9926 - lr: 2.2877e-04\n",
      "Epoch 142/200\n",
      "39/39 [==============================] - 10s 246ms/step - loss: 0.0244 - accuracy: 0.9959 - lr: 2.2877e-04\n",
      "Epoch 143/200\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.0316 - accuracy: 0.9935 - lr: 2.2877e-04\n",
      "Epoch 144/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0274 - accuracy: 0.9935 - lr: 2.2877e-04\n",
      "Epoch 145/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0271 - accuracy: 0.9943 - lr: 2.2877e-04\n",
      "Epoch 146/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0268 - accuracy: 0.9935 - lr: 2.2877e-04\n",
      "Epoch 147/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0294 - accuracy: 0.9935 - lr: 2.2877e-04\n",
      "Epoch 148/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0237 - accuracy: 0.9943 - lr: 2.2877e-04\n",
      "Epoch 149/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0262 - accuracy: 0.9935 - lr: 2.2877e-04\n",
      "Epoch 150/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0302 - accuracy: 0.9935 - lr: 2.2877e-04\n",
      "Epoch 151/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0238 - accuracy: 0.9951 - lr: 2.0589e-04\n",
      "Epoch 152/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.0277 - accuracy: 0.9918 - lr: 2.0589e-04\n",
      "Epoch 153/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0249 - accuracy: 0.9943 - lr: 2.0589e-04\n",
      "Epoch 154/200\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.0269 - accuracy: 0.9943 - lr: 2.0589e-04\n",
      "Epoch 155/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0209 - accuracy: 0.9975 - lr: 2.0589e-04\n",
      "Epoch 156/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0285 - accuracy: 0.9926 - lr: 2.0589e-04\n",
      "Epoch 157/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0238 - accuracy: 0.9959 - lr: 2.0589e-04\n",
      "Epoch 158/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0216 - accuracy: 0.9967 - lr: 2.0589e-04\n",
      "Epoch 159/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0247 - accuracy: 0.9943 - lr: 2.0589e-04\n",
      "Epoch 160/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0330 - accuracy: 0.9910 - lr: 2.0589e-04\n",
      "Epoch 161/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0278 - accuracy: 0.9951 - lr: 1.8530e-04\n",
      "Epoch 162/200\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.0189 - accuracy: 0.9967 - lr: 1.8530e-04\n",
      "Epoch 163/200\n",
      "39/39 [==============================] - 11s 272ms/step - loss: 0.0265 - accuracy: 0.9943 - lr: 1.8530e-04\n",
      "Epoch 164/200\n",
      "39/39 [==============================] - 11s 268ms/step - loss: 0.0247 - accuracy: 0.9943 - lr: 1.8530e-04\n",
      "Epoch 165/200\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.0186 - accuracy: 0.9967 - lr: 1.8530e-04\n",
      "Epoch 166/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.0220 - accuracy: 0.9951 - lr: 1.8530e-04\n",
      "Epoch 167/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.0249 - accuracy: 0.9918 - lr: 1.8530e-04\n",
      "Epoch 168/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0237 - accuracy: 0.9943 - lr: 1.8530e-04\n",
      "Epoch 169/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.0196 - accuracy: 0.9959 - lr: 1.8530e-04\n",
      "Epoch 170/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0238 - accuracy: 0.9943 - lr: 1.8530e-04\n",
      "Epoch 171/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0202 - accuracy: 0.9959 - lr: 1.6677e-04\n",
      "Epoch 172/200\n",
      "39/39 [==============================] - 10s 246ms/step - loss: 0.0235 - accuracy: 0.9967 - lr: 1.6677e-04\n",
      "Epoch 173/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.0255 - accuracy: 0.9959 - lr: 1.6677e-04\n",
      "Epoch 174/200\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.0243 - accuracy: 0.9959 - lr: 1.6677e-04\n",
      "Epoch 175/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0177 - accuracy: 0.9984 - lr: 1.6677e-04\n",
      "Epoch 176/200\n",
      "39/39 [==============================] - 10s 245ms/step - loss: 0.0287 - accuracy: 0.9926 - lr: 1.6677e-04\n",
      "Epoch 177/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0202 - accuracy: 0.9967 - lr: 1.6677e-04\n",
      "Epoch 178/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.0263 - accuracy: 0.9951 - lr: 1.6677e-04\n",
      "Epoch 179/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.0202 - accuracy: 0.9951 - lr: 1.6677e-04\n",
      "Epoch 180/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.0243 - accuracy: 0.9943 - lr: 1.6677e-04\n",
      "Epoch 181/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.0228 - accuracy: 0.9951 - lr: 1.5009e-04\n",
      "Epoch 182/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.0211 - accuracy: 0.9943 - lr: 1.5009e-04\n",
      "Epoch 183/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0180 - accuracy: 0.9975 - lr: 1.5009e-04\n",
      "Epoch 184/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0181 - accuracy: 0.9975 - lr: 1.5009e-04\n",
      "Epoch 185/200\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.0133 - accuracy: 0.9992 - lr: 1.5009e-04\n",
      "Epoch 186/200\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.0245 - accuracy: 0.9943 - lr: 1.5009e-04\n",
      "Epoch 187/200\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.0190 - accuracy: 0.9975 - lr: 1.5009e-04\n",
      "Epoch 188/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0186 - accuracy: 0.9967 - lr: 1.5009e-04\n",
      "Epoch 189/200\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.0200 - accuracy: 0.9951 - lr: 1.5009e-04\n",
      "Epoch 190/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0181 - accuracy: 0.9984 - lr: 1.5009e-04\n",
      "Epoch 191/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0213 - accuracy: 0.9935 - lr: 1.3509e-04\n",
      "Epoch 192/200\n",
      "39/39 [==============================] - 15s 380ms/step - loss: 0.0173 - accuracy: 0.9975 - lr: 1.3509e-04\n",
      "Epoch 193/200\n",
      "39/39 [==============================] - 15s 383ms/step - loss: 0.0240 - accuracy: 0.9951 - lr: 1.3509e-04\n",
      "Epoch 194/200\n",
      "39/39 [==============================] - 10s 244ms/step - loss: 0.0172 - accuracy: 0.9975 - lr: 1.3509e-04\n",
      "Epoch 195/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.0184 - accuracy: 0.9967 - lr: 1.3509e-04\n",
      "Epoch 196/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.0217 - accuracy: 0.9951 - lr: 1.3509e-04\n",
      "Epoch 197/200\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.0194 - accuracy: 0.9967 - lr: 1.3509e-04\n",
      "Epoch 198/200\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.0154 - accuracy: 0.9967 - lr: 1.3509e-04\n",
      "Epoch 199/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.0211 - accuracy: 0.9943 - lr: 1.3509e-04\n",
      "Epoch 200/200\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.0206 - accuracy: 0.9935 - lr: 1.3509e-04\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def det_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    def lr_schedule(epoch):\n",
    "        initial_learning_rate = 0.001\n",
    "        decay = 0.9\n",
    "        epochs_drop = 10\n",
    "        learning_rate = initial_learning_rate * decay ** (epoch // epochs_drop)\n",
    "        return learning_rate\n",
    "\n",
    "    lr_callback = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model, lr_callback\n",
    "\n",
    "\n",
    "data_dir = 'D:/Final Year Project/db/PNG' \n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "cnn_model, lr_callback = det_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=200,\n",
    "    callbacks=[lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5971fbc8-d5c1-4694-bb58-b8ddb58cdae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1040 images belonging to 2 classes.\n",
      "Epoch 1/300\n",
      "33/33 [==============================] - 9s 264ms/step - loss: 0.6253 - accuracy: 0.6481 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "33/33 [==============================] - 9s 255ms/step - loss: 0.3968 - accuracy: 0.8317 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.3908 - accuracy: 0.8346 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.3584 - accuracy: 0.8538 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.3144 - accuracy: 0.8740 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "33/33 [==============================] - 9s 279ms/step - loss: 0.3036 - accuracy: 0.8865 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "33/33 [==============================] - 10s 306ms/step - loss: 0.2800 - accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "33/33 [==============================] - 10s 309ms/step - loss: 0.2406 - accuracy: 0.9067 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "33/33 [==============================] - 9s 277ms/step - loss: 0.2498 - accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "33/33 [==============================] - 10s 311ms/step - loss: 0.2723 - accuracy: 0.8962 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "33/33 [==============================] - 15s 432ms/step - loss: 0.2836 - accuracy: 0.8894 - lr: 9.0000e-04\n",
      "Epoch 12/300\n",
      "33/33 [==============================] - 13s 394ms/step - loss: 0.2513 - accuracy: 0.8952 - lr: 9.0000e-04\n",
      "Epoch 13/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.2329 - accuracy: 0.9010 - lr: 9.0000e-04\n",
      "Epoch 14/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.2482 - accuracy: 0.8913 - lr: 9.0000e-04\n",
      "Epoch 15/300\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 0.2224 - accuracy: 0.9144 - lr: 9.0000e-04\n",
      "Epoch 16/300\n",
      "33/33 [==============================] - 12s 371ms/step - loss: 0.2262 - accuracy: 0.9048 - lr: 9.0000e-04\n",
      "Epoch 17/300\n",
      "33/33 [==============================] - 13s 374ms/step - loss: 0.1951 - accuracy: 0.9317 - lr: 9.0000e-04\n",
      "Epoch 18/300\n",
      "33/33 [==============================] - 13s 383ms/step - loss: 0.1997 - accuracy: 0.9231 - lr: 9.0000e-04\n",
      "Epoch 19/300\n",
      "33/33 [==============================] - 13s 378ms/step - loss: 0.2236 - accuracy: 0.9173 - lr: 9.0000e-04\n",
      "Epoch 20/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.1925 - accuracy: 0.9260 - lr: 9.0000e-04\n",
      "Epoch 21/300\n",
      "33/33 [==============================] - 13s 377ms/step - loss: 0.1689 - accuracy: 0.9365 - lr: 8.1000e-04\n",
      "Epoch 22/300\n",
      "33/33 [==============================] - 12s 374ms/step - loss: 0.1620 - accuracy: 0.9337 - lr: 8.1000e-04\n",
      "Epoch 23/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.1435 - accuracy: 0.9558 - lr: 8.1000e-04\n",
      "Epoch 24/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.1824 - accuracy: 0.9365 - lr: 8.1000e-04\n",
      "Epoch 25/300\n",
      "33/33 [==============================] - 13s 394ms/step - loss: 0.1768 - accuracy: 0.9365 - lr: 8.1000e-04\n",
      "Epoch 26/300\n",
      "33/33 [==============================] - 13s 399ms/step - loss: 0.1665 - accuracy: 0.9413 - lr: 8.1000e-04\n",
      "Epoch 27/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.1391 - accuracy: 0.9510 - lr: 8.1000e-04\n",
      "Epoch 28/300\n",
      "33/33 [==============================] - 13s 398ms/step - loss: 0.1329 - accuracy: 0.9471 - lr: 8.1000e-04\n",
      "Epoch 29/300\n",
      "33/33 [==============================] - 13s 393ms/step - loss: 0.1403 - accuracy: 0.9500 - lr: 8.1000e-04\n",
      "Epoch 30/300\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.1231 - accuracy: 0.9471 - lr: 8.1000e-04\n",
      "Epoch 31/300\n",
      "33/33 [==============================] - 15s 462ms/step - loss: 0.0976 - accuracy: 0.9635 - lr: 7.2900e-04\n",
      "Epoch 32/300\n",
      "33/33 [==============================] - 14s 420ms/step - loss: 0.1007 - accuracy: 0.9615 - lr: 7.2900e-04\n",
      "Epoch 33/300\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.1332 - accuracy: 0.9510 - lr: 7.2900e-04\n",
      "Epoch 34/300\n",
      "33/33 [==============================] - 14s 417ms/step - loss: 0.0904 - accuracy: 0.9673 - lr: 7.2900e-04\n",
      "Epoch 35/300\n",
      "33/33 [==============================] - 14s 421ms/step - loss: 0.1039 - accuracy: 0.9567 - lr: 7.2900e-04\n",
      "Epoch 36/300\n",
      "33/33 [==============================] - 14s 427ms/step - loss: 0.1036 - accuracy: 0.9577 - lr: 7.2900e-04\n",
      "Epoch 37/300\n",
      "33/33 [==============================] - 14s 434ms/step - loss: 0.1054 - accuracy: 0.9625 - lr: 7.2900e-04\n",
      "Epoch 38/300\n",
      "33/33 [==============================] - 14s 406ms/step - loss: 0.1335 - accuracy: 0.9490 - lr: 7.2900e-04\n",
      "Epoch 39/300\n",
      "33/33 [==============================] - 14s 419ms/step - loss: 0.0906 - accuracy: 0.9654 - lr: 7.2900e-04\n",
      "Epoch 40/300\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.0732 - accuracy: 0.9740 - lr: 7.2900e-04\n",
      "Epoch 41/300\n",
      "33/33 [==============================] - 14s 407ms/step - loss: 0.0670 - accuracy: 0.9750 - lr: 6.5610e-04\n",
      "Epoch 42/300\n",
      "33/33 [==============================] - 14s 426ms/step - loss: 0.0811 - accuracy: 0.9721 - lr: 6.5610e-04\n",
      "Epoch 43/300\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.0794 - accuracy: 0.9702 - lr: 6.5610e-04\n",
      "Epoch 44/300\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.0677 - accuracy: 0.9769 - lr: 6.5610e-04\n",
      "Epoch 45/300\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.0504 - accuracy: 0.9837 - lr: 6.5610e-04\n",
      "Epoch 46/300\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.0490 - accuracy: 0.9827 - lr: 6.5610e-04\n",
      "Epoch 47/300\n",
      "33/33 [==============================] - 14s 432ms/step - loss: 0.0665 - accuracy: 0.9769 - lr: 6.5610e-04\n",
      "Epoch 48/300\n",
      "33/33 [==============================] - 12s 375ms/step - loss: 0.0483 - accuracy: 0.9817 - lr: 6.5610e-04\n",
      "Epoch 49/300\n",
      "33/33 [==============================] - 13s 383ms/step - loss: 0.0554 - accuracy: 0.9760 - lr: 6.5610e-04\n",
      "Epoch 50/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0434 - accuracy: 0.9885 - lr: 6.5610e-04\n",
      "Epoch 51/300\n",
      "33/33 [==============================] - 12s 368ms/step - loss: 0.0676 - accuracy: 0.9740 - lr: 5.9049e-04\n",
      "Epoch 52/300\n",
      "33/33 [==============================] - 13s 394ms/step - loss: 0.0618 - accuracy: 0.9769 - lr: 5.9049e-04\n",
      "Epoch 53/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0556 - accuracy: 0.9788 - lr: 5.9049e-04\n",
      "Epoch 54/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.0381 - accuracy: 0.9894 - lr: 5.9049e-04\n",
      "Epoch 55/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0366 - accuracy: 0.9885 - lr: 5.9049e-04\n",
      "Epoch 56/300\n",
      "33/33 [==============================] - 12s 373ms/step - loss: 0.0371 - accuracy: 0.9885 - lr: 5.9049e-04\n",
      "Epoch 57/300\n",
      "33/33 [==============================] - 12s 365ms/step - loss: 0.0358 - accuracy: 0.9856 - lr: 5.9049e-04\n",
      "Epoch 58/300\n",
      "33/33 [==============================] - 13s 383ms/step - loss: 0.0400 - accuracy: 0.9894 - lr: 5.9049e-04\n",
      "Epoch 59/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0341 - accuracy: 0.9875 - lr: 5.9049e-04\n",
      "Epoch 60/300\n",
      "33/33 [==============================] - 13s 392ms/step - loss: 0.0357 - accuracy: 0.9856 - lr: 5.9049e-04\n",
      "Epoch 61/300\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 0.0473 - accuracy: 0.9808 - lr: 5.3144e-04\n",
      "Epoch 62/300\n",
      "33/33 [==============================] - 13s 376ms/step - loss: 0.0752 - accuracy: 0.9644 - lr: 5.3144e-04\n",
      "Epoch 63/300\n",
      "33/33 [==============================] - 12s 373ms/step - loss: 0.0324 - accuracy: 0.9894 - lr: 5.3144e-04\n",
      "Epoch 64/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0372 - accuracy: 0.9846 - lr: 5.3144e-04\n",
      "Epoch 65/300\n",
      "33/33 [==============================] - 13s 397ms/step - loss: 0.0418 - accuracy: 0.9865 - lr: 5.3144e-04\n",
      "Epoch 66/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0193 - accuracy: 0.9971 - lr: 5.3144e-04\n",
      "Epoch 67/300\n",
      "33/33 [==============================] - 13s 379ms/step - loss: 0.0329 - accuracy: 0.9904 - lr: 5.3144e-04\n",
      "Epoch 68/300\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.0265 - accuracy: 0.9894 - lr: 5.3144e-04\n",
      "Epoch 69/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0394 - accuracy: 0.9875 - lr: 5.3144e-04\n",
      "Epoch 70/300\n",
      "33/33 [==============================] - 13s 383ms/step - loss: 0.0430 - accuracy: 0.9913 - lr: 5.3144e-04\n",
      "Epoch 71/300\n",
      "33/33 [==============================] - 13s 404ms/step - loss: 0.0407 - accuracy: 0.9856 - lr: 4.7830e-04\n",
      "Epoch 72/300\n",
      "33/33 [==============================] - 13s 382ms/step - loss: 0.0300 - accuracy: 0.9894 - lr: 4.7830e-04\n",
      "Epoch 73/300\n",
      "33/33 [==============================] - 13s 393ms/step - loss: 0.0490 - accuracy: 0.9885 - lr: 4.7830e-04\n",
      "Epoch 74/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0308 - accuracy: 0.9923 - lr: 4.7830e-04\n",
      "Epoch 75/300\n",
      "33/33 [==============================] - 13s 392ms/step - loss: 0.0237 - accuracy: 0.9875 - lr: 4.7830e-04\n",
      "Epoch 76/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0343 - accuracy: 0.9846 - lr: 4.7830e-04\n",
      "Epoch 77/300\n",
      "33/33 [==============================] - 13s 384ms/step - loss: 0.0228 - accuracy: 0.9933 - lr: 4.7830e-04\n",
      "Epoch 78/300\n",
      "33/33 [==============================] - 13s 403ms/step - loss: 0.0223 - accuracy: 0.9894 - lr: 4.7830e-04\n",
      "Epoch 79/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.0196 - accuracy: 0.9942 - lr: 4.7830e-04\n",
      "Epoch 80/300\n",
      "33/33 [==============================] - 12s 368ms/step - loss: 0.0197 - accuracy: 0.9933 - lr: 4.7830e-04\n",
      "Epoch 81/300\n",
      "33/33 [==============================] - 13s 399ms/step - loss: 0.0177 - accuracy: 0.9952 - lr: 4.3047e-04\n",
      "Epoch 82/300\n",
      "33/33 [==============================] - 13s 404ms/step - loss: 0.0216 - accuracy: 0.9923 - lr: 4.3047e-04\n",
      "Epoch 83/300\n",
      "33/33 [==============================] - 14s 408ms/step - loss: 0.0154 - accuracy: 0.9952 - lr: 4.3047e-04\n",
      "Epoch 84/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0128 - accuracy: 0.9981 - lr: 4.3047e-04\n",
      "Epoch 85/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0168 - accuracy: 0.9942 - lr: 4.3047e-04\n",
      "Epoch 86/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0190 - accuracy: 0.9933 - lr: 4.3047e-04\n",
      "Epoch 87/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0221 - accuracy: 0.9904 - lr: 4.3047e-04\n",
      "Epoch 88/300\n",
      "33/33 [==============================] - 12s 368ms/step - loss: 0.0110 - accuracy: 0.9962 - lr: 4.3047e-04\n",
      "Epoch 89/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0237 - accuracy: 0.9913 - lr: 4.3047e-04\n",
      "Epoch 90/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0149 - accuracy: 0.9971 - lr: 4.3047e-04\n",
      "Epoch 91/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0097 - accuracy: 0.9981 - lr: 3.8742e-04\n",
      "Epoch 92/300\n",
      "33/33 [==============================] - 13s 404ms/step - loss: 0.0106 - accuracy: 0.9962 - lr: 3.8742e-04\n",
      "Epoch 93/300\n",
      "33/33 [==============================] - 13s 378ms/step - loss: 0.0080 - accuracy: 0.9971 - lr: 3.8742e-04\n",
      "Epoch 94/300\n",
      "33/33 [==============================] - 13s 397ms/step - loss: 0.0089 - accuracy: 0.9962 - lr: 3.8742e-04\n",
      "Epoch 95/300\n",
      "33/33 [==============================] - 13s 378ms/step - loss: 0.0112 - accuracy: 0.9933 - lr: 3.8742e-04\n",
      "Epoch 96/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0101 - accuracy: 0.9971 - lr: 3.8742e-04\n",
      "Epoch 97/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0150 - accuracy: 0.9952 - lr: 3.8742e-04\n",
      "Epoch 98/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0142 - accuracy: 0.9942 - lr: 3.8742e-04\n",
      "Epoch 99/300\n",
      "33/33 [==============================] - 14s 423ms/step - loss: 0.0111 - accuracy: 0.9952 - lr: 3.8742e-04\n",
      "Epoch 100/300\n",
      "33/33 [==============================] - 14s 419ms/step - loss: 0.0098 - accuracy: 0.9971 - lr: 3.8742e-04\n",
      "Epoch 101/300\n",
      "33/33 [==============================] - 13s 402ms/step - loss: 0.0108 - accuracy: 0.9971 - lr: 3.4868e-04\n",
      "Epoch 102/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0164 - accuracy: 0.9952 - lr: 3.4868e-04\n",
      "Epoch 103/300\n",
      "33/33 [==============================] - 13s 377ms/step - loss: 0.0068 - accuracy: 0.9990 - lr: 3.4868e-04\n",
      "Epoch 104/300\n",
      "33/33 [==============================] - 13s 383ms/step - loss: 0.0108 - accuracy: 0.9962 - lr: 3.4868e-04\n",
      "Epoch 105/300\n",
      "33/33 [==============================] - 13s 376ms/step - loss: 0.0138 - accuracy: 0.9933 - lr: 3.4868e-04\n",
      "Epoch 106/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0103 - accuracy: 0.9952 - lr: 3.4868e-04\n",
      "Epoch 107/300\n",
      "33/33 [==============================] - 13s 377ms/step - loss: 0.0094 - accuracy: 0.9981 - lr: 3.4868e-04\n",
      "Epoch 108/300\n",
      "33/33 [==============================] - 13s 384ms/step - loss: 0.0131 - accuracy: 0.9942 - lr: 3.4868e-04\n",
      "Epoch 109/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0173 - accuracy: 0.9923 - lr: 3.4868e-04\n",
      "Epoch 110/300\n",
      "33/33 [==============================] - 13s 382ms/step - loss: 0.0161 - accuracy: 0.9971 - lr: 3.4868e-04\n",
      "Epoch 111/300\n",
      "33/33 [==============================] - 12s 371ms/step - loss: 0.0174 - accuracy: 0.9942 - lr: 3.1381e-04\n",
      "Epoch 112/300\n",
      "33/33 [==============================] - 13s 398ms/step - loss: 0.0152 - accuracy: 0.9971 - lr: 3.1381e-04\n",
      "Epoch 113/300\n",
      "33/33 [==============================] - 13s 377ms/step - loss: 0.0198 - accuracy: 0.9913 - lr: 3.1381e-04\n",
      "Epoch 114/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.0175 - accuracy: 0.9933 - lr: 3.1381e-04\n",
      "Epoch 115/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.0080 - accuracy: 0.9981 - lr: 3.1381e-04\n",
      "Epoch 116/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0107 - accuracy: 0.9962 - lr: 3.1381e-04\n",
      "Epoch 117/300\n",
      "33/33 [==============================] - 14s 411ms/step - loss: 0.0055 - accuracy: 0.9990 - lr: 3.1381e-04\n",
      "Epoch 118/300\n",
      "33/33 [==============================] - 14s 422ms/step - loss: 0.0089 - accuracy: 0.9971 - lr: 3.1381e-04\n",
      "Epoch 119/300\n",
      "33/33 [==============================] - 13s 402ms/step - loss: 0.0101 - accuracy: 0.9971 - lr: 3.1381e-04\n",
      "Epoch 120/300\n",
      "33/33 [==============================] - 13s 402ms/step - loss: 0.0058 - accuracy: 0.9990 - lr: 3.1381e-04\n",
      "Epoch 121/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0094 - accuracy: 0.9971 - lr: 2.8243e-04\n",
      "Epoch 122/300\n",
      "33/33 [==============================] - 13s 400ms/step - loss: 0.0083 - accuracy: 0.9971 - lr: 2.8243e-04\n",
      "Epoch 123/300\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 0.0116 - accuracy: 0.9952 - lr: 2.8243e-04\n",
      "Epoch 124/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0099 - accuracy: 0.9981 - lr: 2.8243e-04\n",
      "Epoch 125/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.0065 - accuracy: 0.9981 - lr: 2.8243e-04\n",
      "Epoch 126/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0087 - accuracy: 0.9990 - lr: 2.8243e-04\n",
      "Epoch 127/300\n",
      "33/33 [==============================] - 13s 399ms/step - loss: 0.0113 - accuracy: 0.9962 - lr: 2.8243e-04\n",
      "Epoch 128/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0162 - accuracy: 0.9942 - lr: 2.8243e-04\n",
      "Epoch 129/300\n",
      "33/33 [==============================] - 13s 375ms/step - loss: 0.0102 - accuracy: 0.9952 - lr: 2.8243e-04\n",
      "Epoch 130/300\n",
      "33/33 [==============================] - 13s 399ms/step - loss: 0.0130 - accuracy: 0.9952 - lr: 2.8243e-04\n",
      "Epoch 131/300\n",
      "33/33 [==============================] - 13s 392ms/step - loss: 0.0099 - accuracy: 0.9942 - lr: 2.5419e-04\n",
      "Epoch 132/300\n",
      "33/33 [==============================] - 13s 375ms/step - loss: 0.0040 - accuracy: 0.9990 - lr: 2.5419e-04\n",
      "Epoch 133/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.0060 - accuracy: 0.9981 - lr: 2.5419e-04\n",
      "Epoch 134/300\n",
      "33/33 [==============================] - 13s 382ms/step - loss: 0.0084 - accuracy: 0.9971 - lr: 2.5419e-04\n",
      "Epoch 135/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0045 - accuracy: 0.9981 - lr: 2.5419e-04\n",
      "Epoch 136/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0094 - accuracy: 0.9981 - lr: 2.5419e-04\n",
      "Epoch 137/300\n",
      "33/33 [==============================] - 13s 384ms/step - loss: 0.0070 - accuracy: 0.9971 - lr: 2.5419e-04\n",
      "Epoch 138/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0070 - accuracy: 0.9981 - lr: 2.5419e-04\n",
      "Epoch 139/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0052 - accuracy: 0.9981 - lr: 2.5419e-04\n",
      "Epoch 140/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0044 - accuracy: 0.9990 - lr: 2.5419e-04\n",
      "Epoch 141/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0057 - accuracy: 0.9981 - lr: 2.2877e-04\n",
      "Epoch 142/300\n",
      "33/33 [==============================] - 12s 366ms/step - loss: 0.0052 - accuracy: 0.9981 - lr: 2.2877e-04\n",
      "Epoch 143/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0061 - accuracy: 0.9981 - lr: 2.2877e-04\n",
      "Epoch 144/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0064 - accuracy: 0.9971 - lr: 2.2877e-04\n",
      "Epoch 145/300\n",
      "33/33 [==============================] - 13s 394ms/step - loss: 0.0082 - accuracy: 0.9981 - lr: 2.2877e-04\n",
      "Epoch 146/300\n",
      "33/33 [==============================] - 13s 398ms/step - loss: 0.0060 - accuracy: 0.9971 - lr: 2.2877e-04\n",
      "Epoch 147/300\n",
      "33/33 [==============================] - 14s 434ms/step - loss: 0.0171 - accuracy: 0.9942 - lr: 2.2877e-04\n",
      "Epoch 148/300\n",
      "33/33 [==============================] - 13s 376ms/step - loss: 0.0084 - accuracy: 0.9971 - lr: 2.2877e-04\n",
      "Epoch 149/300\n",
      "33/33 [==============================] - 15s 466ms/step - loss: 0.0051 - accuracy: 0.9990 - lr: 2.2877e-04\n",
      "Epoch 150/300\n",
      "33/33 [==============================] - 13s 402ms/step - loss: 0.0054 - accuracy: 0.9981 - lr: 2.2877e-04\n",
      "Epoch 151/300\n",
      "33/33 [==============================] - 13s 400ms/step - loss: 0.0027 - accuracy: 1.0000 - lr: 2.0589e-04\n",
      "Epoch 152/300\n",
      "33/33 [==============================] - 13s 398ms/step - loss: 0.0050 - accuracy: 0.9971 - lr: 2.0589e-04\n",
      "Epoch 153/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 2.0589e-04\n",
      "Epoch 154/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0029 - accuracy: 1.0000 - lr: 2.0589e-04\n",
      "Epoch 155/300\n",
      "33/33 [==============================] - 12s 365ms/step - loss: 0.0043 - accuracy: 0.9990 - lr: 2.0589e-04\n",
      "Epoch 156/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0033 - accuracy: 0.9990 - lr: 2.0589e-04\n",
      "Epoch 157/300\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.0059 - accuracy: 0.9981 - lr: 2.0589e-04\n",
      "Epoch 158/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0071 - accuracy: 0.9971 - lr: 2.0589e-04\n",
      "Epoch 159/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0047 - accuracy: 0.9990 - lr: 2.0589e-04\n",
      "Epoch 160/300\n",
      "33/33 [==============================] - 13s 379ms/step - loss: 0.0191 - accuracy: 0.9923 - lr: 2.0589e-04\n",
      "Epoch 161/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0060 - accuracy: 0.9971 - lr: 1.8530e-04\n",
      "Epoch 162/300\n",
      "33/33 [==============================] - 12s 362ms/step - loss: 0.0073 - accuracy: 0.9962 - lr: 1.8530e-04\n",
      "Epoch 163/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0052 - accuracy: 0.9971 - lr: 1.8530e-04\n",
      "Epoch 164/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0026 - accuracy: 1.0000 - lr: 1.8530e-04\n",
      "Epoch 165/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0048 - accuracy: 0.9990 - lr: 1.8530e-04\n",
      "Epoch 166/300\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.0037 - accuracy: 0.9990 - lr: 1.8530e-04\n",
      "Epoch 167/300\n",
      "33/33 [==============================] - 13s 384ms/step - loss: 0.0040 - accuracy: 0.9990 - lr: 1.8530e-04\n",
      "Epoch 168/300\n",
      "33/33 [==============================] - 12s 374ms/step - loss: 0.0041 - accuracy: 1.0000 - lr: 1.8530e-04\n",
      "Epoch 169/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0035 - accuracy: 1.0000 - lr: 1.8530e-04\n",
      "Epoch 170/300\n",
      "33/33 [==============================] - 13s 393ms/step - loss: 0.0051 - accuracy: 0.9971 - lr: 1.8530e-04\n",
      "Epoch 171/300\n",
      "33/33 [==============================] - 13s 392ms/step - loss: 0.0052 - accuracy: 0.9990 - lr: 1.6677e-04\n",
      "Epoch 172/300\n",
      "33/33 [==============================] - 13s 398ms/step - loss: 0.0029 - accuracy: 0.9990 - lr: 1.6677e-04\n",
      "Epoch 173/300\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 0.0051 - accuracy: 0.9981 - lr: 1.6677e-04\n",
      "Epoch 174/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0022 - accuracy: 0.9990 - lr: 1.6677e-04\n",
      "Epoch 175/300\n",
      "33/33 [==============================] - 12s 362ms/step - loss: 0.0092 - accuracy: 0.9962 - lr: 1.6677e-04\n",
      "Epoch 176/300\n",
      "33/33 [==============================] - 12s 363ms/step - loss: 0.0064 - accuracy: 0.9971 - lr: 1.6677e-04\n",
      "Epoch 177/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0036 - accuracy: 1.0000 - lr: 1.6677e-04\n",
      "Epoch 178/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0029 - accuracy: 0.9990 - lr: 1.6677e-04\n",
      "Epoch 179/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0025 - accuracy: 0.9990 - lr: 1.6677e-04\n",
      "Epoch 180/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0045 - accuracy: 0.9981 - lr: 1.6677e-04\n",
      "Epoch 181/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0037 - accuracy: 0.9981 - lr: 1.5009e-04\n",
      "Epoch 182/300\n",
      "33/33 [==============================] - 12s 357ms/step - loss: 0.0026 - accuracy: 1.0000 - lr: 1.5009e-04\n",
      "Epoch 183/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0079 - accuracy: 0.9971 - lr: 1.5009e-04\n",
      "Epoch 184/300\n",
      "33/33 [==============================] - 13s 397ms/step - loss: 0.0033 - accuracy: 0.9981 - lr: 1.5009e-04\n",
      "Epoch 185/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0160 - accuracy: 0.9981 - lr: 1.5009e-04\n",
      "Epoch 186/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0042 - accuracy: 0.9990 - lr: 1.5009e-04\n",
      "Epoch 187/300\n",
      "33/33 [==============================] - 14s 408ms/step - loss: 0.0040 - accuracy: 0.9990 - lr: 1.5009e-04\n",
      "Epoch 188/300\n",
      "33/33 [==============================] - 12s 365ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 1.5009e-04\n",
      "Epoch 189/300\n",
      "33/33 [==============================] - 12s 375ms/step - loss: 0.0038 - accuracy: 0.9990 - lr: 1.5009e-04\n",
      "Epoch 190/300\n",
      "33/33 [==============================] - 13s 393ms/step - loss: 0.0161 - accuracy: 0.9942 - lr: 1.5009e-04\n",
      "Epoch 191/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0053 - accuracy: 0.9971 - lr: 1.3509e-04\n",
      "Epoch 192/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0054 - accuracy: 0.9981 - lr: 1.3509e-04\n",
      "Epoch 193/300\n",
      "33/33 [==============================] - 14s 407ms/step - loss: 0.0045 - accuracy: 0.9990 - lr: 1.3509e-04\n",
      "Epoch 194/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0031 - accuracy: 1.0000 - lr: 1.3509e-04\n",
      "Epoch 195/300\n",
      "33/33 [==============================] - 12s 358ms/step - loss: 0.0016 - accuracy: 1.0000 - lr: 1.3509e-04\n",
      "Epoch 196/300\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0073 - accuracy: 0.9971 - lr: 1.3509e-04\n",
      "Epoch 197/300\n",
      "33/33 [==============================] - 13s 392ms/step - loss: 0.0025 - accuracy: 1.0000 - lr: 1.3509e-04\n",
      "Epoch 198/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0056 - accuracy: 0.9990 - lr: 1.3509e-04\n",
      "Epoch 199/300\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 0.0024 - accuracy: 1.0000 - lr: 1.3509e-04\n",
      "Epoch 200/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0049 - accuracy: 0.9981 - lr: 1.3509e-04\n",
      "Epoch 201/300\n",
      "33/33 [==============================] - 12s 370ms/step - loss: 0.0053 - accuracy: 0.9981 - lr: 1.2158e-04\n",
      "Epoch 202/300\n",
      "33/33 [==============================] - 12s 369ms/step - loss: 0.0042 - accuracy: 1.0000 - lr: 1.2158e-04\n",
      "Epoch 203/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.0022 - accuracy: 0.9990 - lr: 1.2158e-04\n",
      "Epoch 204/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0023 - accuracy: 1.0000 - lr: 1.2158e-04\n",
      "Epoch 205/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0034 - accuracy: 0.9990 - lr: 1.2158e-04\n",
      "Epoch 206/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0036 - accuracy: 0.9981 - lr: 1.2158e-04\n",
      "Epoch 207/300\n",
      "33/33 [==============================] - 13s 400ms/step - loss: 0.0032 - accuracy: 1.0000 - lr: 1.2158e-04\n",
      "Epoch 208/300\n",
      "33/33 [==============================] - 12s 370ms/step - loss: 0.0061 - accuracy: 0.9971 - lr: 1.2158e-04\n",
      "Epoch 209/300\n",
      "33/33 [==============================] - 12s 369ms/step - loss: 0.0061 - accuracy: 0.9981 - lr: 1.2158e-04\n",
      "Epoch 210/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0099 - accuracy: 0.9981 - lr: 1.2158e-04\n",
      "Epoch 211/300\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 0.0031 - accuracy: 0.9990 - lr: 1.0942e-04\n",
      "Epoch 212/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0033 - accuracy: 0.9990 - lr: 1.0942e-04\n",
      "Epoch 213/300\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0038 - accuracy: 0.9990 - lr: 1.0942e-04\n",
      "Epoch 214/300\n",
      "33/33 [==============================] - 13s 392ms/step - loss: 0.0034 - accuracy: 0.9990 - lr: 1.0942e-04\n",
      "Epoch 215/300\n",
      "33/33 [==============================] - 12s 358ms/step - loss: 0.0081 - accuracy: 0.9981 - lr: 1.0942e-04\n",
      "Epoch 216/300\n",
      "33/33 [==============================] - 12s 357ms/step - loss: 0.0049 - accuracy: 0.9981 - lr: 1.0942e-04\n",
      "Epoch 217/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0034 - accuracy: 0.9990 - lr: 1.0942e-04\n",
      "Epoch 218/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0028 - accuracy: 0.9981 - lr: 1.0942e-04\n",
      "Epoch 219/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0019 - accuracy: 0.9990 - lr: 1.0942e-04\n",
      "Epoch 220/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0036 - accuracy: 0.9990 - lr: 1.0942e-04\n",
      "Epoch 221/300\n",
      "33/33 [==============================] - 13s 380ms/step - loss: 0.0034 - accuracy: 0.9990 - lr: 9.8477e-05\n",
      "Epoch 222/300\n",
      "33/33 [==============================] - 12s 365ms/step - loss: 0.0023 - accuracy: 1.0000 - lr: 9.8477e-05\n",
      "Epoch 223/300\n",
      "33/33 [==============================] - 13s 379ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 9.8477e-05\n",
      "Epoch 224/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0030 - accuracy: 0.9990 - lr: 9.8477e-05\n",
      "Epoch 225/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0041 - accuracy: 0.9990 - lr: 9.8477e-05\n",
      "Epoch 226/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0095 - accuracy: 0.9971 - lr: 9.8477e-05\n",
      "Epoch 227/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0023 - accuracy: 0.9990 - lr: 9.8477e-05\n",
      "Epoch 228/300\n",
      "33/33 [==============================] - 12s 375ms/step - loss: 0.0028 - accuracy: 0.9990 - lr: 9.8477e-05\n",
      "Epoch 229/300\n",
      "33/33 [==============================] - 12s 358ms/step - loss: 0.0010 - accuracy: 1.0000 - lr: 9.8477e-05\n",
      "Epoch 230/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 9.8477e-05\n",
      "Epoch 231/300\n",
      "33/33 [==============================] - 13s 399ms/step - loss: 0.0014 - accuracy: 1.0000 - lr: 8.8629e-05\n",
      "Epoch 232/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0030 - accuracy: 0.9990 - lr: 8.8629e-05\n",
      "Epoch 233/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 8.8629e-05\n",
      "Epoch 234/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0041 - accuracy: 0.9990 - lr: 8.8629e-05\n",
      "Epoch 235/300\n",
      "33/33 [==============================] - 12s 346ms/step - loss: 0.0016 - accuracy: 1.0000 - lr: 8.8629e-05\n",
      "Epoch 236/300\n",
      "33/33 [==============================] - 12s 358ms/step - loss: 0.0028 - accuracy: 0.9990 - lr: 8.8629e-05\n",
      "Epoch 237/300\n",
      "33/33 [==============================] - 13s 382ms/step - loss: 0.0023 - accuracy: 0.9990 - lr: 8.8629e-05\n",
      "Epoch 238/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0029 - accuracy: 0.9990 - lr: 8.8629e-05\n",
      "Epoch 239/300\n",
      "33/33 [==============================] - 13s 397ms/step - loss: 0.0110 - accuracy: 0.9962 - lr: 8.8629e-05\n",
      "Epoch 240/300\n",
      "33/33 [==============================] - 13s 394ms/step - loss: 0.0063 - accuracy: 0.9962 - lr: 8.8629e-05\n",
      "Epoch 241/300\n",
      "33/33 [==============================] - 13s 376ms/step - loss: 0.0020 - accuracy: 1.0000 - lr: 7.9766e-05\n",
      "Epoch 242/300\n",
      "33/33 [==============================] - 12s 362ms/step - loss: 0.0057 - accuracy: 0.9990 - lr: 7.9766e-05\n",
      "Epoch 243/300\n",
      "33/33 [==============================] - 13s 378ms/step - loss: 0.0044 - accuracy: 0.9990 - lr: 7.9766e-05\n",
      "Epoch 244/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0031 - accuracy: 0.9990 - lr: 7.9766e-05\n",
      "Epoch 245/300\n",
      "33/33 [==============================] - 13s 402ms/step - loss: 0.0012 - accuracy: 1.0000 - lr: 7.9766e-05\n",
      "Epoch 246/300\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 4.8364e-04 - accuracy: 1.0000 - lr: 7.9766e-05\n",
      "Epoch 247/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0024 - accuracy: 0.9990 - lr: 7.9766e-05\n",
      "Epoch 248/300\n",
      "33/33 [==============================] - 12s 358ms/step - loss: 0.0027 - accuracy: 0.9990 - lr: 7.9766e-05\n",
      "Epoch 249/300\n",
      "33/33 [==============================] - 12s 361ms/step - loss: 0.0026 - accuracy: 0.9990 - lr: 7.9766e-05\n",
      "Epoch 250/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0021 - accuracy: 0.9990 - lr: 7.9766e-05\n",
      "Epoch 251/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0022 - accuracy: 0.9990 - lr: 7.1790e-05\n",
      "Epoch 252/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0064 - accuracy: 0.9962 - lr: 7.1790e-05\n",
      "Epoch 253/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0033 - accuracy: 0.9981 - lr: 7.1790e-05\n",
      "Epoch 254/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0032 - accuracy: 0.9990 - lr: 7.1790e-05\n",
      "Epoch 255/300\n",
      "33/33 [==============================] - 12s 362ms/step - loss: 0.0021 - accuracy: 0.9990 - lr: 7.1790e-05\n",
      "Epoch 256/300\n",
      "33/33 [==============================] - 13s 381ms/step - loss: 0.0018 - accuracy: 0.9990 - lr: 7.1790e-05\n",
      "Epoch 257/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 7.1790e-05\n",
      "Epoch 258/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0017 - accuracy: 0.9990 - lr: 7.1790e-05\n",
      "Epoch 259/300\n",
      "33/33 [==============================] - 13s 394ms/step - loss: 0.0019 - accuracy: 0.9990 - lr: 7.1790e-05\n",
      "Epoch 260/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0036 - accuracy: 0.9990 - lr: 7.1790e-05\n",
      "Epoch 261/300\n",
      "33/33 [==============================] - 13s 378ms/step - loss: 0.0022 - accuracy: 0.9990 - lr: 6.4611e-05\n",
      "Epoch 262/300\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0019 - accuracy: 1.0000 - lr: 6.4611e-05\n",
      "Epoch 263/300\n",
      "33/33 [==============================] - 13s 379ms/step - loss: 0.0017 - accuracy: 1.0000 - lr: 6.4611e-05\n",
      "Epoch 264/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0017 - accuracy: 0.9990 - lr: 6.4611e-05\n",
      "Epoch 265/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 6.4611e-05\n",
      "Epoch 266/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0017 - accuracy: 0.9990 - lr: 6.4611e-05\n",
      "Epoch 267/300\n",
      "33/33 [==============================] - 13s 382ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 6.4611e-05\n",
      "Epoch 268/300\n",
      "33/33 [==============================] - 12s 358ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 6.4611e-05\n",
      "Epoch 269/300\n",
      "33/33 [==============================] - 12s 363ms/step - loss: 6.2676e-04 - accuracy: 1.0000 - lr: 6.4611e-05\n",
      "Epoch 270/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0027 - accuracy: 0.9981 - lr: 6.4611e-05\n",
      "Epoch 271/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0024 - accuracy: 0.9990 - lr: 5.8150e-05\n",
      "Epoch 272/300\n",
      "33/33 [==============================] - 13s 392ms/step - loss: 7.9455e-04 - accuracy: 1.0000 - lr: 5.8150e-05\n",
      "Epoch 273/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0012 - accuracy: 1.0000 - lr: 5.8150e-05\n",
      "Epoch 274/300\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 0.0023 - accuracy: 0.9990 - lr: 5.8150e-05\n",
      "Epoch 275/300\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0023 - accuracy: 0.9990 - lr: 5.8150e-05\n",
      "Epoch 276/300\n",
      "33/33 [==============================] - 12s 352ms/step - loss: 0.0031 - accuracy: 0.9990 - lr: 5.8150e-05\n",
      "Epoch 277/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0014 - accuracy: 1.0000 - lr: 5.8150e-05\n",
      "Epoch 278/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 5.8150e-05\n",
      "Epoch 279/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0016 - accuracy: 0.9990 - lr: 5.8150e-05\n",
      "Epoch 280/300\n",
      "33/33 [==============================] - 13s 383ms/step - loss: 0.0014 - accuracy: 1.0000 - lr: 5.8150e-05\n",
      "Epoch 281/300\n",
      "33/33 [==============================] - 13s 385ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 5.2335e-05\n",
      "Epoch 282/300\n",
      "33/33 [==============================] - 12s 360ms/step - loss: 0.0038 - accuracy: 0.9981 - lr: 5.2335e-05\n",
      "Epoch 283/300\n",
      "33/33 [==============================] - 14s 408ms/step - loss: 0.0024 - accuracy: 0.9990 - lr: 5.2335e-05\n",
      "Epoch 284/300\n",
      "33/33 [==============================] - 13s 402ms/step - loss: 2.9754e-04 - accuracy: 1.0000 - lr: 5.2335e-05\n",
      "Epoch 285/300\n",
      "33/33 [==============================] - 13s 404ms/step - loss: 0.0017 - accuracy: 1.0000 - lr: 5.2335e-05\n",
      "Epoch 286/300\n",
      "33/33 [==============================] - 13s 393ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 5.2335e-05\n",
      "Epoch 287/300\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.0046 - accuracy: 0.9981 - lr: 5.2335e-05\n",
      "Epoch 288/300\n",
      "33/33 [==============================] - 12s 360ms/step - loss: 0.0047 - accuracy: 0.9981 - lr: 5.2335e-05\n",
      "Epoch 289/300\n",
      "33/33 [==============================] - 12s 366ms/step - loss: 9.9914e-04 - accuracy: 1.0000 - lr: 5.2335e-05\n",
      "Epoch 290/300\n",
      "33/33 [==============================] - 12s 375ms/step - loss: 0.0027 - accuracy: 0.9990 - lr: 5.2335e-05\n",
      "Epoch 291/300\n",
      "33/33 [==============================] - 13s 383ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 4.7101e-05\n",
      "Epoch 292/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 4.7101e-05\n",
      "Epoch 293/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 5.7296e-04 - accuracy: 1.0000 - lr: 4.7101e-05\n",
      "Epoch 294/300\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 0.0068 - accuracy: 0.9990 - lr: 4.7101e-05\n",
      "Epoch 295/300\n",
      "33/33 [==============================] - 12s 352ms/step - loss: 0.0036 - accuracy: 0.9990 - lr: 4.7101e-05\n",
      "Epoch 296/300\n",
      "33/33 [==============================] - 12s 362ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 4.7101e-05\n",
      "Epoch 297/300\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 0.0018 - accuracy: 0.9990 - lr: 4.7101e-05\n",
      "Epoch 298/300\n",
      "33/33 [==============================] - 13s 386ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 4.7101e-05\n",
      "Epoch 299/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 6.2184e-04 - accuracy: 1.0000 - lr: 4.7101e-05\n",
      "Epoch 300/300\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 0.0024 - accuracy: 0.9990 - lr: 4.7101e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#main trainning cnn code \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def det_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    def lr_schedule(epoch):\n",
    "        initial_learning_rate = 0.001\n",
    "        decay = 0.9\n",
    "        epochs_drop = 10\n",
    "        learning_rate = initial_learning_rate * decay ** (epoch // epochs_drop)\n",
    "        return learning_rate\n",
    "\n",
    "    lr_callback = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model, lr_callback\n",
    "\n",
    "\n",
    "data_dir = 'D:/Final Year Project/db1/PNG' \n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "cnn_model, lr_callback = det_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=300,\n",
    "    callbacks=[lr_callback]\n",
    ")\n",
    "\n",
    "# Save the trained model to disk\n",
    "cnn_model.save(\"my_trained_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c3adcd-982b-4df8-b390-a3ba31907e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1040 images belonging to 2 classes.\n",
      "(None, 150, 150, 3)\n",
      "{'cancerous': 0, 'non_cancerous': 1}\n",
      "['cancerous', 'non_cancerous']\n",
      "1040\n",
      "32\n",
      "32\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 21s 635ms/step - loss: 0.6833 - accuracy: 0.5615 - val_loss: 0.6525 - val_accuracy: 0.6519 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 20s 641ms/step - loss: 0.6116 - accuracy: 0.6984 - val_loss: 0.5406 - val_accuracy: 0.7990 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 21s 653ms/step - loss: 0.4781 - accuracy: 0.8571 - val_loss: 0.4587 - val_accuracy: 0.8529 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 21s 652ms/step - loss: 0.4301 - accuracy: 0.8909 - val_loss: 0.4072 - val_accuracy: 0.9106 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 21s 651ms/step - loss: 0.3990 - accuracy: 0.9206 - val_loss: 0.3944 - val_accuracy: 0.9212 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 21s 659ms/step - loss: 0.4048 - accuracy: 0.9137 - val_loss: 0.4077 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 21s 652ms/step - loss: 0.4046 - accuracy: 0.9127 - val_loss: 0.3887 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 21s 652ms/step - loss: 0.3887 - accuracy: 0.9286 - val_loss: 0.3957 - val_accuracy: 0.9423 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 21s 665ms/step - loss: 0.3863 - accuracy: 0.9306 - val_loss: 0.3815 - val_accuracy: 0.9317 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 22s 680ms/step - loss: 0.3944 - accuracy: 0.9167 - val_loss: 0.3809 - val_accuracy: 0.9308 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 21s 651ms/step - loss: 0.3934 - accuracy: 0.9196 - val_loss: 0.3715 - val_accuracy: 0.9433 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 21s 653ms/step - loss: 0.3834 - accuracy: 0.9315 - val_loss: 0.3793 - val_accuracy: 0.9423 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 21s 653ms/step - loss: 0.3763 - accuracy: 0.9365 - val_loss: 0.3853 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 21s 642ms/step - loss: 0.3940 - accuracy: 0.9187 - val_loss: 0.4060 - val_accuracy: 0.9067 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 21s 656ms/step - loss: 0.3976 - accuracy: 0.9157 - val_loss: 0.3883 - val_accuracy: 0.9221 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 21s 643ms/step - loss: 0.3766 - accuracy: 0.9375 - val_loss: 0.3777 - val_accuracy: 0.9308 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 21s 654ms/step - loss: 0.3816 - accuracy: 0.9296 - val_loss: 0.3929 - val_accuracy: 0.9173 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 21s 655ms/step - loss: 0.3789 - accuracy: 0.9315 - val_loss: 0.3669 - val_accuracy: 0.9490 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 21s 657ms/step - loss: 0.3720 - accuracy: 0.9404 - val_loss: 0.3662 - val_accuracy: 0.9442 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 21s 644ms/step - loss: 0.3694 - accuracy: 0.9464 - val_loss: 0.3861 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 22s 686ms/step - loss: 0.3761 - accuracy: 0.9375 - val_loss: 0.3779 - val_accuracy: 0.9298 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 21s 651ms/step - loss: 0.3784 - accuracy: 0.9306 - val_loss: 0.3694 - val_accuracy: 0.9365 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 21s 648ms/step - loss: 0.3739 - accuracy: 0.9415 - val_loss: 0.3763 - val_accuracy: 0.9346 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 21s 657ms/step - loss: 0.3733 - accuracy: 0.9365 - val_loss: 0.3660 - val_accuracy: 0.9413 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 22s 687ms/step - loss: 0.3755 - accuracy: 0.9355 - val_loss: 0.3631 - val_accuracy: 0.9433 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 22s 687ms/step - loss: 0.3713 - accuracy: 0.9405 - val_loss: 0.3586 - val_accuracy: 0.9606 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 24s 739ms/step - loss: 0.3796 - accuracy: 0.9315 - val_loss: 0.3700 - val_accuracy: 0.9433 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 22s 693ms/step - loss: 0.3679 - accuracy: 0.9454 - val_loss: 0.3583 - val_accuracy: 0.9577 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 22s 685ms/step - loss: 0.3616 - accuracy: 0.9474 - val_loss: 0.3689 - val_accuracy: 0.9452 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 22s 697ms/step - loss: 0.3727 - accuracy: 0.9425 - val_loss: 0.3563 - val_accuracy: 0.9558 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 22s 681ms/step - loss: 0.3642 - accuracy: 0.9474 - val_loss: 0.3575 - val_accuracy: 0.9548 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 22s 701ms/step - loss: 0.3807 - accuracy: 0.9306 - val_loss: 0.3768 - val_accuracy: 0.9279 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 22s 696ms/step - loss: 0.3778 - accuracy: 0.9365 - val_loss: 0.3766 - val_accuracy: 0.9337 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 21s 652ms/step - loss: 0.3639 - accuracy: 0.9554 - val_loss: 0.3728 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 21s 655ms/step - loss: 0.3619 - accuracy: 0.9484 - val_loss: 0.3622 - val_accuracy: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 21s 652ms/step - loss: 0.3556 - accuracy: 0.9583 - val_loss: 0.3576 - val_accuracy: 0.9567 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 23s 726ms/step - loss: 0.3647 - accuracy: 0.9474 - val_loss: 0.3617 - val_accuracy: 0.9471 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 21s 646ms/step - loss: 0.3612 - accuracy: 0.9484 - val_loss: 0.3714 - val_accuracy: 0.9413 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 21s 659ms/step - loss: 0.3810 - accuracy: 0.9256 - val_loss: 0.3784 - val_accuracy: 0.9327 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 23s 711ms/step - loss: 0.3675 - accuracy: 0.9435 - val_loss: 0.3540 - val_accuracy: 0.9606 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 22s 687ms/step - loss: 0.3571 - accuracy: 0.9554 - val_loss: 0.3611 - val_accuracy: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 25s 781ms/step - loss: 0.3630 - accuracy: 0.9484 - val_loss: 0.3531 - val_accuracy: 0.9615 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 25s 788ms/step - loss: 0.3599 - accuracy: 0.9534 - val_loss: 0.3561 - val_accuracy: 0.9587 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 26s 798ms/step - loss: 0.3663 - accuracy: 0.9425 - val_loss: 0.3658 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 25s 787ms/step - loss: 0.3537 - accuracy: 0.9583 - val_loss: 0.3528 - val_accuracy: 0.9644 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 26s 805ms/step - loss: 0.3563 - accuracy: 0.9534 - val_loss: 0.3495 - val_accuracy: 0.9673 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.3626 - accuracy: 0.9534 - val_loss: 0.3544 - val_accuracy: 0.9615 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 25s 798ms/step - loss: 0.3555 - accuracy: 0.9583 - val_loss: 0.3736 - val_accuracy: 0.9337 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 26s 808ms/step - loss: 0.3678 - accuracy: 0.9443 - val_loss: 0.3690 - val_accuracy: 0.9385 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 26s 800ms/step - loss: 0.3551 - accuracy: 0.9563 - val_loss: 0.3823 - val_accuracy: 0.9298 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 26s 824ms/step - loss: 0.3531 - accuracy: 0.9643 - val_loss: 0.3463 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 28s 894ms/step - loss: 0.3512 - accuracy: 0.9629 - val_loss: 0.3514 - val_accuracy: 0.9625 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 29s 913ms/step - loss: 0.3487 - accuracy: 0.9633 - val_loss: 0.3495 - val_accuracy: 0.9615 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 29s 920ms/step - loss: 0.3511 - accuracy: 0.9593 - val_loss: 0.3517 - val_accuracy: 0.9596 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 28s 885ms/step - loss: 0.3507 - accuracy: 0.9623 - val_loss: 0.3474 - val_accuracy: 0.9644 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 29s 896ms/step - loss: 0.3486 - accuracy: 0.9653 - val_loss: 0.3503 - val_accuracy: 0.9635 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 28s 885ms/step - loss: 0.3526 - accuracy: 0.9593 - val_loss: 0.3484 - val_accuracy: 0.9635 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 28s 875ms/step - loss: 0.3518 - accuracy: 0.9593 - val_loss: 0.3513 - val_accuracy: 0.9625 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 27s 870ms/step - loss: 0.3479 - accuracy: 0.9673 - val_loss: 0.3490 - val_accuracy: 0.9635 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 28s 864ms/step - loss: 0.3504 - accuracy: 0.9623 - val_loss: 0.3481 - val_accuracy: 0.9683 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 28s 887ms/step - loss: 0.3522 - accuracy: 0.9623 - val_loss: 0.3524 - val_accuracy: 0.9615 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "\n",
    "train_data_dir = 'D:/Final Year Project/db1/PNG' \n",
    "\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "epochs = 100  \n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 50:\n",
    "        return 0.0001\n",
    "    elif epoch < 75:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.000001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# Check the input shape of the model\n",
    "print(model.input_shape)\n",
    "\n",
    "# Check the class indices, class names, and sample count of the training data\n",
    "print(train_generator.class_indices)\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(class_names)\n",
    "print(train_generator.samples)\n",
    "\n",
    "# Check the batch size\n",
    "print(batch_size)\n",
    "\n",
    "# Check the number of steps per epoch\n",
    "steps_per_epoch = train_generator.samples // batch_size\n",
    "print(steps_per_epoch)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, callbacks=[lr_scheduler, early_stopping], validation_data=train_generator)\n",
    "\n",
    "\n",
    "model.save('plant_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b096589-55d1-4ada-b9b8-f2f77493b225",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The proto value '6' is already registered.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:97\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_autograph\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m debug_mode\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iterator_ops\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:980\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop):\n\u001b[0;32m    976\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m gen_dataset_ops\u001b[38;5;241m.\u001b[39mdeserialize_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop, restored_tensors[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    979\u001b[0m nested_structure_coder\u001b[38;5;241m.\u001b[39mregister_codec(\n\u001b[1;32m--> 980\u001b[0m     \u001b[43mnested_structure_coder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuiltInTypeSpecCodec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIteratorSpec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTypeSpecProto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA_ITERATOR_SPEC\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m )\n\u001b[0;32m    986\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `tf.data.Iterator.get_next_as_optional()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    988\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.experimental.get_next_as_optional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next_as_optional\u001b[39m(iterator):\n\u001b[0;32m    990\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `tf.experimental.Optional` with the next element of the iterator.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \n\u001b[0;32m    992\u001b[0m \u001b[38;5;124;03m  If the iterator has reached the end of the sequence, the returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;124;03m    of the iterator (if it exists) or no value.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\saved_model\\nested_structure_coder.py:387\u001b[0m, in \u001b[0;36mBuiltInTypeSpecCodec.__init__\u001b[1;34m(self, type_spec_class, type_spec_proto_enum)\u001b[0m\n\u001b[0;32m    383\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already has an instantiated codec.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_spec_proto_enum \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_BUILT_IN_TYPE_SPEC_PROTOS:\n\u001b[1;32m--> 387\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe proto value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_proto_enum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m   )\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(type_spec_proto_enum, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m type_spec_proto_enum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m type_spec_proto_enum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m    394\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe proto value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_proto_enum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is invalid.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The proto value '6' is already registered."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class AccuracyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        accuracy_percentage = logs['accuracy'] * 100\n",
    "        print(\"Epoch {}: Accuracy {:.0f}%\".format(epoch+1, accuracy_percentage))\n",
    "\n",
    "def det_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    def lr_schedule(epoch):\n",
    "        initial_learning_rate = 0.001\n",
    "        decay = 0.9\n",
    "        epochs_drop = 10\n",
    "        learning_rate = initial_learning_rate * decay ** (epoch // epochs_drop)\n",
    "        return learning_rate\n",
    "\n",
    "    lr_callback = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model, lr_callback\n",
    "\n",
    "data_dir = 'D:/Final Year Project/db/PNG' \n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "cnn_model, lr_callback = det_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "accuracy_callback = AccuracyCallback()\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    callbacks=[lr_callback, accuracy_callback]\n",
    ")\n",
    "\n",
    "cnn_model.save(\"my_trained_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734f6e9f-caca-40b6-8df0-e93ca6b18f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 724 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "Epoch 1/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.5700 - accuracy: \n",
      "23/23 [==============================] - 11s 450ms/step - loss: 0.5700 - accuracy: 0.6948 - val_loss: 0.3099 - val_accuracy: 0.9320\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 0.2901 - accuracy: \n",
      "23/23 [==============================] - 7s 300ms/step - loss: 0.2901 - accuracy: 0.8826 - val_loss: 0.3610 - val_accuracy: 0.7767\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.1827 - accuracy: \n",
      "23/23 [==============================] - 7s 299ms/step - loss: 0.1827 - accuracy: 0.9323 - val_loss: 0.4442 - val_accuracy: 0.7864\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 77ms/steploss: 0.1420 - accuracy: \n",
      "23/23 [==============================] - 7s 302ms/step - loss: 0.1420 - accuracy: 0.9365 - val_loss: 0.2985 - val_accuracy: 0.8447\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 0.0846 - accuracy: \n",
      "23/23 [==============================] - 7s 302ms/step - loss: 0.0846 - accuracy: 0.9751 - val_loss: 0.2727 - val_accuracy: 0.8641\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 0.0647 - accuracy: \n",
      "23/23 [==============================] - 7s 301ms/step - loss: 0.0647 - accuracy: 0.9793 - val_loss: 0.1071 - val_accuracy: 0.9515\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 0.0361 - accuracy: \n",
      "23/23 [==============================] - 7s 296ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.4604 - val_accuracy: 0.7767\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 0.0252 - accuracy: \n",
      "23/23 [==============================] - 7s 294ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.0835 - val_accuracy: 0.9709\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 77ms/steploss: 0.0281 - accuracy: \n",
      "23/23 [==============================] - 7s 300ms/step - loss: 0.0281 - accuracy: 0.9876 - val_loss: 0.0928 - val_accuracy: 0.9612\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0321 - accuracy: \n",
      "23/23 [==============================] - 7s 296ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.2610 - val_accuracy: 0.8835\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0491 - accuracy: \n",
      "23/23 [==============================] - 7s 290ms/step - loss: 0.0491 - accuracy: 0.9807 - val_loss: 0.1356 - val_accuracy: 0.9417\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 76ms/steploss: 0.0307 - accuracy: \n",
      "23/23 [==============================] - 7s 293ms/step - loss: 0.0307 - accuracy: 0.9917 - val_loss: 0.2805 - val_accuracy: 0.9126\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 0.0302 - accuracy: \n",
      "23/23 [==============================] - 7s 296ms/step - loss: 0.0302 - accuracy: 0.9876 - val_loss: 0.1966 - val_accuracy: 0.8932\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.0270 - accuracy: \n",
      "23/23 [==============================] - 7s 286ms/step - loss: 0.0270 - accuracy: 0.9862 - val_loss: 0.3189 - val_accuracy: 0.8835\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.0097 - accuracy: \n",
      "23/23 [==============================] - 7s 290ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.1373 - val_accuracy: 0.9515\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 0.0157 - accuracy: \n",
      "23/23 [==============================] - 7s 288ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.1107 - val_accuracy: 0.9612\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 74ms/steploss: 0.0070 - accuracy: \n",
      "23/23 [==============================] - 7s 294ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.1525 - val_accuracy: 0.9515\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 0.0070 - accuracy: \n",
      "23/23 [==============================] - 7s 290ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.2843 - val_accuracy: 0.9223\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0023 - accuracy: \n",
      "23/23 [==============================] - 7s 288ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 0.4727 - val_accuracy: 0.8835\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 0.0040 - accuracy: \n",
      "23/23 [==============================] - 7s 289ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.4528 - val_accuracy: 0.8544\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 77ms/steploss: 9.3997e-04 - accuracy: \n",
      "23/23 [==============================] - 7s 284ms/step - loss: 9.3997e-04 - accuracy: 1.0000 - val_loss: 0.3290 - val_accuracy: 0.9223\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 74ms/steploss: 3.2133e-04 - accuracy: \n",
      "23/23 [==============================] - 7s 281ms/step - loss: 3.2133e-04 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9223\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 7.5749e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 280ms/step - loss: 7.5749e-04 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9223\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.0239 - accuracy: \n",
      "23/23 [==============================] - 6s 279ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.1986 - val_accuracy: 0.9223\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 0.0205 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0205 - accuracy: 0.9862 - val_loss: 0.2869 - val_accuracy: 0.9223\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.0575 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0575 - accuracy: 0.9820 - val_loss: 0.4989 - val_accuracy: 0.8447\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 0.0267 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0267 - accuracy: 0.9890 - val_loss: 0.6805 - val_accuracy: 0.8350\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 0.0022 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.8835\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0023 - accuracy: \n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 0.8796 - val_accuracy: 0.8252\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0021 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9029\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 3.7262e-04 - accuracy: \n",
      "23/23 [==============================] - 7s 281ms/step - loss: 3.7262e-04 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.8835\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 6.2562e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 277ms/step - loss: 6.2562e-04 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.8835\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 3.1876e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 274ms/step - loss: 3.1876e-04 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.8835\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 4.0859e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 280ms/step - loss: 4.0859e-04 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.8835\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 1.2573e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 280ms/step - loss: 1.2573e-04 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8835\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 74ms/steploss: 0.0043 - accuracy: \n",
      "23/23 [==============================] - 6s 277ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.5906 - val_accuracy: 0.8738\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 0.0073 - accuracy: \n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.4407 - val_accuracy: 0.8835\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.0027 - accuracy: \n",
      "23/23 [==============================] - 7s 283ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.8641\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 66ms/steploss: 4.8985e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 281ms/step - loss: 4.8985e-04 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.8932\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 76ms/steploss: 7.8503e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 280ms/step - loss: 7.8503e-04 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8544\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 65ms/steploss: 1.2873e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 274ms/step - loss: 1.2873e-04 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8835\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 1.8565e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 1.8565e-04 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 0.8641\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 4.2668e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 277ms/step - loss: 4.2668e-04 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 0.8932\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 5.4722e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 278ms/step - loss: 5.4722e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8641\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 66ms/steploss: 2.3431e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 2.3431e-04 - accuracy: 1.0000 - val_loss: 0.8427 - val_accuracy: 0.8544\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 1.1045e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 1.1045e-04 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.8641\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 1.2366e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 1.2366e-04 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.8641\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 62ms/steploss: 0.0046 - accuracy: \n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.7433 - val_accuracy: 0.8447\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 0.0053 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.8310 - val_accuracy: 0.8350\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.0144 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.3869 - val_accuracy: 0.8835\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 0.0374 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0374 - accuracy: 0.9917 - val_loss: 0.5142 - val_accuracy: 0.8835\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0339 - accuracy: \n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0339 - accuracy: 0.9862 - val_loss: 0.2766 - val_accuracy: 0.9223\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 75ms/steploss: 0.0272 - accuracy: \n",
      "23/23 [==============================] - 6s 278ms/step - loss: 0.0272 - accuracy: 0.9890 - val_loss: 0.4854 - val_accuracy: 0.8932\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 0.0417 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0417 - accuracy: 0.9807 - val_loss: 0.7666 - val_accuracy: 0.8544\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 78ms/steploss: 0.0098 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.5649 - val_accuracy: 0.8738\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 0.0038 - accuracy: \n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.7650 - val_accuracy: 0.8447\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 0.0065 - accuracy: \n",
      "23/23 [==============================] - 6s 279ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 0.8790 - val_accuracy: 0.8155\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 74ms/steploss: 0.0012 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8641\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.0017 - accuracy: \n",
      "23/23 [==============================] - 6s 279ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8707 - val_accuracy: 0.8447\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 5.5775e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 279ms/step - loss: 5.5775e-04 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.8544\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 0.0011 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5472 - val_accuracy: 0.8835\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 3.6260e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 3.6260e-04 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.8932\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 77ms/steploss: 5.3115e-04 - accuracy: \n",
      "23/23 [==============================] - 7s 283ms/step - loss: 5.3115e-04 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8738\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 4.7391e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 4.7391e-04 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 0.8835\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 5.5651e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 273ms/step - loss: 5.5651e-04 - accuracy: 1.0000 - val_loss: 0.9263 - val_accuracy: 0.8447\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 66ms/steploss: 0.0017 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8297 - val_accuracy: 0.8738\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.0015 - accuracy: \n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0315 - val_accuracy: 0.8544\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 0.0029 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 0.5955 - val_accuracy: 0.8932\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 3.8401e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 280ms/step - loss: 3.8401e-05 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.9029\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 2.9280e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 2.9280e-04 - accuracy: 1.0000 - val_loss: 0.6492 - val_accuracy: 0.8835\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 1.9064e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 1.9064e-04 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.8544\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 75ms/steploss: 1.1493e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 274ms/step - loss: 1.1493e-04 - accuracy: 1.0000 - val_loss: 0.9650 - val_accuracy: 0.8447\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 77ms/steploss: 0.0014 - accuracy: \n",
      "23/23 [==============================] - 6s 278ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.8738\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 3.3082e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 272ms/step - loss: 3.3082e-04 - accuracy: 1.0000 - val_loss: 1.0724 - val_accuracy: 0.8641\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 62ms/steploss: 5.3713e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 273ms/step - loss: 5.3713e-04 - accuracy: 1.0000 - val_loss: 0.9057 - val_accuracy: 0.8641\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 81ms/steploss: 1.0309e-04 - accuracy: \n",
      "23/23 [==============================] - 7s 282ms/step - loss: 1.0309e-04 - accuracy: 1.0000 - val_loss: 0.9178 - val_accuracy: 0.8641\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 0.0184 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 1.0649 - val_accuracy: 0.8544\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.0223 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0223 - accuracy: 0.9903 - val_loss: 0.8874 - val_accuracy: 0.8447\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 76ms/steploss: 0.0263 - accuracy: \n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.1308 - val_accuracy: 0.9709\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 0.0400 - accuracy: \n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0400 - accuracy: 0.9931 - val_loss: 0.8682 - val_accuracy: 0.8058\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0142 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.8392 - val_accuracy: 0.8738\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 0.0034 - accuracy: \n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 0.9425 - val_accuracy: 0.8835\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 63ms/steploss: 0.0056 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0056 - accuracy: 0.9959 - val_loss: 0.8820 - val_accuracy: 0.8738\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.0307 - accuracy: \n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0307 - accuracy: 0.9917 - val_loss: 1.1005 - val_accuracy: 0.7573\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 62ms/steploss: 0.0129 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.4218 - val_accuracy: 0.8835\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 75ms/steploss: 0.0045 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.4231 - val_accuracy: 0.9029\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.0010 - accuracy: \n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9029\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 0.0044 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0044 - accuracy: 0.9972 - val_loss: 0.3118 - val_accuracy: 0.9417\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.0085 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0085 - accuracy: 0.9959 - val_loss: 0.4334 - val_accuracy: 0.9029\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 63ms/steploss: 0.0052 - accuracy: \n",
      "23/23 [==============================] - 6s 268ms/step - loss: 0.0052 - accuracy: 0.9972 - val_loss: 0.7323 - val_accuracy: 0.8738\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.0099 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0099 - accuracy: 0.9959 - val_loss: 0.3748 - val_accuracy: 0.9126\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 0.0014 - accuracy: \n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.8835\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 4.2961e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 267ms/step - loss: 4.2961e-04 - accuracy: 1.0000 - val_loss: 0.7367 - val_accuracy: 0.8641\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 74ms/steploss: 9.0695e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 268ms/step - loss: 9.0695e-04 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.8155\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 3.6100e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 264ms/step - loss: 3.6100e-04 - accuracy: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.8544\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 1.4465e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 1.4465e-04 - accuracy: 1.0000 - val_loss: 0.8576 - val_accuracy: 0.8738\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 0.0012 - accuracy: \n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.9029\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 8.3448e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 8.3448e-04 - accuracy: 1.0000 - val_loss: 0.6575 - val_accuracy: 0.8932\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 0.0011 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 0.0011 - accuracy: 0.9986 - val_loss: 0.8805 - val_accuracy: 0.8641\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 3.8399e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 277ms/step - loss: 3.8399e-05 - accuracy: 1.0000 - val_loss: 0.9210 - val_accuracy: 0.8641\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 3.8707e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.8707e-05 - accuracy: 1.0000 - val_loss: 0.9124 - val_accuracy: 0.8641\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 3.7098e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 3.7098e-04 - accuracy: 1.0000 - val_loss: 0.8848 - val_accuracy: 0.8641\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 3.0974e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 3.0974e-05 - accuracy: 1.0000 - val_loss: 0.8562 - val_accuracy: 0.8738\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 4.6079e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 268ms/step - loss: 4.6079e-05 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 0.8641\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 8.7828e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 267ms/step - loss: 8.7828e-05 - accuracy: 1.0000 - val_loss: 0.9113 - val_accuracy: 0.8641\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 66ms/steploss: 3.3640e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 268ms/step - loss: 3.3640e-05 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.8641\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 66ms/steploss: 6.5517e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 6.5517e-05 - accuracy: 1.0000 - val_loss: 0.9133 - val_accuracy: 0.8641\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 64ms/steploss: 5.9209e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 5.9209e-05 - accuracy: 1.0000 - val_loss: 0.9417 - val_accuracy: 0.8641\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 4.0018e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.0018e-05 - accuracy: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.8641\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 1.3469e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 1.3469e-05 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.8641\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 66ms/steploss: 4.5865e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.5865e-05 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.8641\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 6.3332e-06 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 6.3332e-06 - accuracy: 1.0000 - val_loss: 0.9821 - val_accuracy: 0.8641\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 77ms/steploss: 6.1807e-06 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 6.1807e-06 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.8641\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 7.9887e-05 - accuracy: \n",
      "23/23 [==============================] - 7s 287ms/step - loss: 7.9887e-05 - accuracy: 1.0000 - val_loss: 0.9489 - val_accuracy: 0.8641\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 1.3255e-05 - accuracy: \n",
      "23/23 [==============================] - 7s 280ms/step - loss: 1.3255e-05 - accuracy: 1.0000 - val_loss: 0.9290 - val_accuracy: 0.8738\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 7.3834e-06 - accuracy: \n",
      "23/23 [==============================] - 6s 279ms/step - loss: 7.3834e-06 - accuracy: 1.0000 - val_loss: 0.9237 - val_accuracy: 0.8738\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 68ms/steploss: 3.2963e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 3.2963e-05 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.8738\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 2.1237e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 2.1237e-05 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.8738\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 4.6894e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 4.6894e-05 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.8738\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 74ms/steploss: 5.0436e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 276ms/step - loss: 5.0436e-05 - accuracy: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.8738\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0032 - accuracy: 0.99\n",
      "23/23 [==============================] - 6s 272ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 1.1406 - val_accuracy: 0.8447\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 67ms/steploss: 0.0068 - accuracy: \n",
      "23/23 [==============================] - 6s 266ms/step - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.3977 - val_accuracy: 0.9320\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 0.0123 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.3572 - val_accuracy: 0.9029\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0017 - accuracy: \n",
      "23/23 [==============================] - 6s 279ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9223\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 2.8477e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 266ms/step - loss: 2.8477e-04 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.9126\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 1.1364e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 1.1364e-04 - accuracy: 1.0000 - val_loss: 0.5704 - val_accuracy: 0.9029\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 73ms/steploss: 1.0889e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 268ms/step - loss: 1.0889e-04 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.9029\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 7.9121e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 266ms/step - loss: 7.9121e-04 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.9029\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 65ms/steploss: 2.9412e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 264ms/step - loss: 2.9412e-04 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.8932\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 70ms/steploss: 2.6414e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 264ms/step - loss: 2.6414e-04 - accuracy: 1.0000 - val_loss: 1.1492 - val_accuracy: 0.8544\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 64ms/steploss: 9.0355e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 268ms/step - loss: 9.0355e-04 - accuracy: 1.0000 - val_loss: 0.8377 - val_accuracy: 0.8738\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 66ms/steploss: 7.0622e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 265ms/step - loss: 7.0622e-05 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.8835\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0034 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 1.4477 - val_accuracy: 0.8058\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.0042 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.6514 - val_accuracy: 0.8932\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 6.7965e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 6.7965e-04 - accuracy: 1.0000 - val_loss: 1.4517 - val_accuracy: 0.8058\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 4.7932e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 4.7932e-04 - accuracy: 1.0000 - val_loss: 1.4435 - val_accuracy: 0.8350\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 1.6434e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 270ms/step - loss: 1.6434e-04 - accuracy: 1.0000 - val_loss: 1.4477 - val_accuracy: 0.8350\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 3.1248e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 264ms/step - loss: 3.1248e-04 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 0.8447\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 64ms/steploss: 1.6836e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 1.6836e-04 - accuracy: 1.0000 - val_loss: 1.3269 - val_accuracy: 0.8350\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 1.8828e-05 - accuracy: \n",
      "23/23 [==============================] - 6s 271ms/step - loss: 1.8828e-05 - accuracy: 1.0000 - val_loss: 1.3250 - val_accuracy: 0.8350\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 78ms/steploss: 2.5754e-04 - accuracy: \n",
      "23/23 [==============================] - 6s 278ms/step - loss: 2.5754e-04 - accuracy: 1.0000 - val_loss: 1.4939 - val_accuracy: 0.8252\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0013 - accuracy: \n",
      "23/23 [==============================] - 6s 277ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 1.0736 - val_accuracy: 0.8738\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 77ms/steploss: 0.0245 - accuracy: \n",
      "23/23 [==============================] - 6s 279ms/step - loss: 0.0245 - accuracy: 0.9945 - val_loss: 1.4207 - val_accuracy: 0.8155\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 78ms/steploss: 0.0422 - accuracy: \n",
      "23/23 [==============================] - 7s 282ms/step - loss: 0.0422 - accuracy: 0.9903 - val_loss: 0.4214 - val_accuracy: 0.9320\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 72ms/steploss: 0.0089 - accuracy: \n",
      "23/23 [==============================] - 6s 275ms/step - loss: 0.0089 - accuracy: 0.9959 - val_loss: 2.9911 - val_accuracy: 0.6796\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 74ms/steploss: 0.0219 - accuracy: \n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.3755 - val_accuracy: 0.9223\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 69ms/steploss: 0.0324 - accuracy: \n",
      "23/23 [==============================] - 6s 265ms/step - loss: 0.0324 - accuracy: 0.9931 - val_loss: 0.6384 - val_accuracy: 0.8738\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 71ms/steploss: 0.0096 - accuracy: \n",
      "23/23 [==============================] - 6s 267ms/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.9294 - val_accuracy: 0.8447\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 80ms/steploss: 0.0021 - accuracy: \n",
      "23/23 [==============================] - 6s 277ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 0.7556 - val_accuracy: 0.8738\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 81ms/steploss: 0.0033 - accuracy: \n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.3151 - val_accuracy: 0.8252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, val_data_generator):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.val_data_generator = val_data_generator\n",
    "        self.metrics = {'accuracy': [], 'loss': [], 'f1_score': [], 'specificity': [], 'roc_auc': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Compute and record metrics\n",
    "        loss = logs.get('loss')\n",
    "        accuracy = logs.get('accuracy')\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_pred_probs = self.model.predict(self.val_data_generator)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "        # Get true labels from the validation data generator\n",
    "        y_true = self.val_data_generator.classes\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "        # Compute specificity\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        # Compute ROC AUC\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_probs[:, 1])\n",
    "\n",
    "        # Append metrics to the list\n",
    "        self.metrics['accuracy'].append(accuracy)\n",
    "        self.metrics['loss'].append(loss)\n",
    "        self.metrics['f1_score'].append(f1)\n",
    "        self.metrics['specificity'].append(specificity)\n",
    "        self.metrics['roc_auc'].append(roc_auc)\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Directory paths\n",
    "train_data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040'\n",
    "val_data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040 - Copy (2)'\n",
    "\n",
    "# Image dimensions and batch size\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Create the model\n",
    "model = create_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "# Initialize the MetricsCallback\n",
    "metrics_callback = MetricsCallback(val_generator)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "# Save the trained model to disk\n",
    "model.save(\"my_trained_model_training.h5\")\n",
    "\n",
    "# Save the metrics to an Excel file\n",
    "metrics_df = pd.DataFrame(metrics_callback.metrics)\n",
    "metrics_df.to_excel(\"final_training_metrics.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e7d77f3-08ea-4f18-b88b-fadb3adb8750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 213 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "Epoch 1/150\n",
      "4/4 [==============================] - 0s 68ms/stepss: 0.7867 - accuracy: \n",
      "7/7 [==============================] - 3s 392ms/step - loss: 0.7867 - accuracy: 0.5775 - val_loss: 0.6312 - val_accuracy: 0.8738\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 71ms/stepss: 0.4914 - accuracy: \n",
      "7/7 [==============================] - 2s 353ms/step - loss: 0.4914 - accuracy: 0.7840 - val_loss: 0.3856 - val_accuracy: 0.8641\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 75ms/stepss: 0.2029 - accuracy: \n",
      "7/7 [==============================] - 3s 376ms/step - loss: 0.2029 - accuracy: 0.9343 - val_loss: 0.1722 - val_accuracy: 0.9223\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 68ms/stepss: 0.0771 - accuracy: \n",
      "7/7 [==============================] - 3s 375ms/step - loss: 0.0771 - accuracy: 0.9859 - val_loss: 0.1130 - val_accuracy: 0.9709\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 67ms/stepss: 0.0302 - accuracy: \n",
      "7/7 [==============================] - 2s 336ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 0.0260 - val_accuracy: 0.9903\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 63ms/stepss: 0.0314 - accuracy: \n",
      "7/7 [==============================] - 2s 345ms/step - loss: 0.0314 - accuracy: 0.9812 - val_loss: 0.1154 - val_accuracy: 0.9806\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 68ms/stepss: 0.0212 - accuracy: \n",
      "7/7 [==============================] - 2s 336ms/step - loss: 0.0212 - accuracy: 0.9953 - val_loss: 0.0264 - val_accuracy: 0.9903\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 65ms/stepss: 0.0037 - accuracy: \n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 68ms/stepss: 0.0021 - accuracy: \n",
      "7/7 [==============================] - 2s 338ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9903\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 69ms/stepss: 5.6124e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 351ms/step - loss: 5.6124e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9806\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 71ms/stepss: 0.0028 - accuracy: \n",
      "7/7 [==============================] - 3s 362ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 64ms/stepss: 3.2262e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 337ms/step - loss: 3.2262e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 66ms/stepss: 4.7916e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 341ms/step - loss: 4.7916e-04 - accuracy: 1.0000 - val_loss: 9.0766e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 69ms/stepss: 4.2415e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 358ms/step - loss: 4.2415e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 71ms/stepss: 3.7043e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 360ms/step - loss: 3.7043e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 70ms/stepss: 2.7889e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 354ms/step - loss: 2.7889e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 68ms/stepss: 3.3874e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 350ms/step - loss: 3.3874e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9903\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 72ms/stepss: 1.3779e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 341ms/step - loss: 1.3779e-04 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9903\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 72ms/stepss: 1.5003e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 363ms/step - loss: 1.5003e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9903\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 74ms/stepss: 3.9523e-04 - accuracy: \n",
      "7/7 [==============================] - 2s 351ms/step - loss: 3.9523e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9903\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 74ms/stepss: 6.4990e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 403ms/step - loss: 6.4990e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9903\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 88ms/stepss: 1.1046e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 400ms/step - loss: 1.1046e-04 - accuracy: 1.0000 - val_loss: 2.2226e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 86ms/stepss: 2.3282e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 433ms/step - loss: 2.3282e-04 - accuracy: 1.0000 - val_loss: 2.9622e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 83ms/stepss: 6.2129e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 398ms/step - loss: 6.2129e-04 - accuracy: 1.0000 - val_loss: 1.8534e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 2.5426e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 486ms/step - loss: 2.5426e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 68ms/stepss: 5.7922e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 403ms/step - loss: 5.7922e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 3.9972e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 426ms/step - loss: 3.9972e-05 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9903\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 101ms/steps: 1.1113e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 445ms/step - loss: 1.1113e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 86ms/stepss: 2.4103e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 426ms/step - loss: 2.4103e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 4.6838e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 425ms/step - loss: 4.6838e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 4.8319e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 447ms/step - loss: 4.8319e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 6.2824e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 429ms/step - loss: 6.2824e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 92ms/stepss: 1.7489e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 424ms/step - loss: 1.7489e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 89ms/stepss: 1.4385e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 420ms/step - loss: 1.4385e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 87ms/stepss: 4.0972e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 415ms/step - loss: 4.0972e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 7.3672e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 417ms/step - loss: 7.3672e-05 - accuracy: 1.0000 - val_loss: 7.8938e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 88ms/stepss: 2.8744e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 427ms/step - loss: 2.8744e-05 - accuracy: 1.0000 - val_loss: 8.5339e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 87ms/stepss: 5.7156e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 423ms/step - loss: 5.7156e-05 - accuracy: 1.0000 - val_loss: 3.9227e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 88ms/stepss: 5.3587e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 418ms/step - loss: 5.3587e-05 - accuracy: 1.0000 - val_loss: 8.7714e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 4.7619e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 415ms/step - loss: 4.7619e-05 - accuracy: 1.0000 - val_loss: 8.9179e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 87ms/stepss: 7.8648e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 427ms/step - loss: 7.8648e-05 - accuracy: 1.0000 - val_loss: 2.5915e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 81ms/stepss: 8.4831e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 434ms/step - loss: 8.4831e-05 - accuracy: 1.0000 - val_loss: 4.6736e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 1.5729e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 414ms/step - loss: 1.5729e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 86ms/stepss: 7.3983e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 418ms/step - loss: 7.3983e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 89ms/stepss: 5.2638e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 423ms/step - loss: 5.2638e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 90ms/stepss: 1.3465e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 412ms/step - loss: 1.3465e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 85ms/stepss: 3.4397e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 417ms/step - loss: 3.4397e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 89ms/stepss: 1.0215e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 415ms/step - loss: 1.0215e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 7.3447e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 423ms/step - loss: 7.3447e-04 - accuracy: 1.0000 - val_loss: 2.5216e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 86ms/stepss: 1.6209e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 421ms/step - loss: 1.6209e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9903\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 90ms/stepss: 0.0096 - accuracy: \n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.0096 - accuracy: 0.9953 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 85ms/stepss: 0.0081 - accuracy: \n",
      "7/7 [==============================] - 3s 419ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 87ms/stepss: 0.0089 - accuracy: \n",
      "7/7 [==============================] - 3s 414ms/step - loss: 0.0089 - accuracy: 0.9953 - val_loss: 0.1401 - val_accuracy: 0.9709\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 0.1230 - accuracy: \n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.1230 - accuracy: 0.9859 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 97ms/stepss: 0.0398 - accuracy: \n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.0398 - accuracy: 0.9953 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 103ms/steps: 0.0028 - accuracy: \n",
      "7/7 [==============================] - 3s 475ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 7.6903e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 98ms/stepss: 0.0093 - accuracy: 0.\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.0093 - accuracy: 0.9953 - val_loss: 6.2515e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 100ms/steps: 0.0066 - accuracy: \n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9903\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 88ms/stepss: 0.0014 - accuracy: \n",
      "7/7 [==============================] - 3s 473ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9903\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 88ms/stepss: 3.3450e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 444ms/step - loss: 3.3450e-04 - accuracy: 1.0000 - val_loss: 7.3314e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 95ms/stepss: 2.1647e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 444ms/step - loss: 2.1647e-04 - accuracy: 1.0000 - val_loss: 6.1673e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 1.0889e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 431ms/step - loss: 1.0889e-04 - accuracy: 1.0000 - val_loss: 8.1560e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 3.6673e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 434ms/step - loss: 3.6673e-06 - accuracy: 1.0000 - val_loss: 2.5402e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 4.5208e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 405ms/step - loss: 4.5208e-05 - accuracy: 1.0000 - val_loss: 1.1191e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 86ms/stepss: 6.5340e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 422ms/step - loss: 6.5340e-06 - accuracy: 1.0000 - val_loss: 6.4696e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 89ms/stepss: 7.0013e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 398ms/step - loss: 7.0013e-07 - accuracy: 1.0000 - val_loss: 4.7451e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 89ms/stepss: 2.5185e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 403ms/step - loss: 2.5185e-08 - accuracy: 1.0000 - val_loss: 4.0623e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 82ms/stepss: 2.3941e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 398ms/step - loss: 2.3941e-06 - accuracy: 1.0000 - val_loss: 3.6920e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 76ms/stepss: 3.0919e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 395ms/step - loss: 3.0919e-06 - accuracy: 1.0000 - val_loss: 3.4489e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 4.9213e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 391ms/step - loss: 4.9213e-06 - accuracy: 1.0000 - val_loss: 3.1943e-07 - val_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 78ms/stepss: 2.2932e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 382ms/step - loss: 2.2932e-06 - accuracy: 1.0000 - val_loss: 2.9397e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 82ms/stepss: 2.0487e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 424ms/step - loss: 2.0487e-06 - accuracy: 1.0000 - val_loss: 2.7892e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 86ms/stepss: 5.2101e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 393ms/step - loss: 5.2101e-05 - accuracy: 1.0000 - val_loss: 2.3263e-07 - val_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 90ms/stepss: 5.8396e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 394ms/step - loss: 5.8396e-05 - accuracy: 1.0000 - val_loss: 1.5856e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 5.8483e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 413ms/step - loss: 5.8483e-07 - accuracy: 1.0000 - val_loss: 1.1574e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 7.0404e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 394ms/step - loss: 7.0404e-07 - accuracy: 1.0000 - val_loss: 9.7219e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 89ms/stepss: 7.7794e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 436ms/step - loss: 7.7794e-08 - accuracy: 1.0000 - val_loss: 9.1432e-08 - val_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 99ms/stepss: 6.7719e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 482ms/step - loss: 6.7719e-08 - accuracy: 1.0000 - val_loss: 8.6803e-08 - val_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 4.7476e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 425ms/step - loss: 4.7476e-04 - accuracy: 1.0000 - val_loss: 5.8138e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 6.1231e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 431ms/step - loss: 6.1231e-05 - accuracy: 1.0000 - val_loss: 7.8117e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 1.1333e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 415ms/step - loss: 1.1333e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 100ms/steps: 4.4861e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 428ms/step - loss: 4.4861e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 1.2096e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 415ms/step - loss: 1.2096e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 80ms/stepss: 9.6323e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 400ms/step - loss: 9.6323e-06 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 86ms/stepss: 4.2192e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 403ms/step - loss: 4.2192e-06 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 80ms/stepss: 1.0923e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 396ms/step - loss: 1.0923e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 85ms/stepss: 3.6248e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 414ms/step - loss: 3.6248e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 1.3218e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 426ms/step - loss: 1.3218e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 82ms/stepss: 2.3082e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 417ms/step - loss: 2.3082e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 88ms/stepss: 6.9484e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 436ms/step - loss: 6.9484e-06 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 4.9243e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 424ms/step - loss: 4.9243e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 99ms/stepss: 4.2122e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 445ms/step - loss: 4.2122e-05 - accuracy: 1.0000 - val_loss: 8.2284e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 92ms/stepss: 5.1890e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 463ms/step - loss: 5.1890e-05 - accuracy: 1.0000 - val_loss: 6.1143e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 96ms/stepss: 4.0961e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 433ms/step - loss: 4.0961e-06 - accuracy: 1.0000 - val_loss: 4.5673e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 87ms/stepss: 1.2277e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 433ms/step - loss: 1.2277e-05 - accuracy: 1.0000 - val_loss: 3.6209e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 3.3871e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 418ms/step - loss: 3.3871e-05 - accuracy: 1.0000 - val_loss: 2.9802e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 85ms/stepss: 3.9757e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 406ms/step - loss: 3.9757e-05 - accuracy: 1.0000 - val_loss: 2.5567e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 85ms/stepss: 2.0600e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 405ms/step - loss: 2.0600e-05 - accuracy: 1.0000 - val_loss: 2.1111e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 89ms/stepss: 5.3941e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 413ms/step - loss: 5.3941e-06 - accuracy: 1.0000 - val_loss: 1.7675e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 5.2079e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 426ms/step - loss: 5.2079e-06 - accuracy: 1.0000 - val_loss: 1.5907e-04 - val_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 2.3718e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 420ms/step - loss: 2.3718e-05 - accuracy: 1.0000 - val_loss: 1.3862e-04 - val_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 1s 109ms/steps: 2.3107e-04 - accuracy: \n",
      "7/7 [==============================] - 3s 469ms/step - loss: 2.3107e-04 - accuracy: 1.0000 - val_loss: 9.6972e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 97ms/stepss: 7.2628e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 453ms/step - loss: 7.2628e-06 - accuracy: 1.0000 - val_loss: 7.4412e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 104ms/steps: 1.2404e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 486ms/step - loss: 1.2404e-05 - accuracy: 1.0000 - val_loss: 6.1534e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 1.2335e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 443ms/step - loss: 1.2335e-06 - accuracy: 1.0000 - val_loss: 5.4382e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 6.8166e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 461ms/step - loss: 6.8166e-07 - accuracy: 1.0000 - val_loss: 5.0791e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 3.8576e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 442ms/step - loss: 3.8576e-05 - accuracy: 1.0000 - val_loss: 4.2665e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 1s 109ms/steps: 4.6228e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 516ms/step - loss: 4.6228e-07 - accuracy: 1.0000 - val_loss: 3.6478e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 92ms/stepss: 2.0234e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 459ms/step - loss: 2.0234e-06 - accuracy: 1.0000 - val_loss: 3.3655e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 92ms/stepss: 2.4961e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 447ms/step - loss: 2.4961e-07 - accuracy: 1.0000 - val_loss: 3.2183e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 95ms/stepss: 1.5518e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 459ms/step - loss: 1.5518e-05 - accuracy: 1.0000 - val_loss: 2.7982e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 96ms/stepss: 2.1249e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 457ms/step - loss: 2.1249e-05 - accuracy: 1.0000 - val_loss: 2.4071e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 95ms/stepss: 1.2526e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 439ms/step - loss: 1.2526e-05 - accuracy: 1.0000 - val_loss: 2.0147e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 6.7344e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 447ms/step - loss: 6.7344e-05 - accuracy: 1.0000 - val_loss: 1.0298e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 1.7250e-05 - accuracy: \n",
      "7/7 [==============================] - 3s 442ms/step - loss: 1.7250e-05 - accuracy: 1.0000 - val_loss: 5.1097e-06 - val_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 95ms/stepss: 7.5555e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 445ms/step - loss: 7.5555e-08 - accuracy: 1.0000 - val_loss: 3.5467e-06 - val_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 6.0444e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 447ms/step - loss: 6.0444e-08 - accuracy: 1.0000 - val_loss: 2.9532e-06 - val_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 97ms/stepss: 6.1057e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 448ms/step - loss: 6.1057e-07 - accuracy: 1.0000 - val_loss: 2.6778e-06 - val_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 99ms/stepss: 5.7588e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 453ms/step - loss: 5.7588e-07 - accuracy: 1.0000 - val_loss: 2.5239e-06 - val_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 101ms/steps: 6.1563e-09 - accuracy: \n",
      "7/7 [==============================] - 3s 464ms/step - loss: 6.1563e-09 - accuracy: 1.0000 - val_loss: 2.4452e-06 - val_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 1s 115ms/steps: 3.8560e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 495ms/step - loss: 3.8560e-07 - accuracy: 1.0000 - val_loss: 2.4024e-06 - val_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 1s 113ms/steps: 7.3876e-08 - accuracy: \n",
      "7/7 [==============================] - 4s 520ms/step - loss: 7.3876e-08 - accuracy: 1.0000 - val_loss: 2.3747e-06 - val_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 97ms/stepss: 4.5151e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 462ms/step - loss: 4.5151e-06 - accuracy: 1.0000 - val_loss: 2.3029e-06 - val_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 95ms/stepss: 3.4699e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 449ms/step - loss: 3.4699e-08 - accuracy: 1.0000 - val_loss: 2.2265e-06 - val_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 1.9196e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 438ms/step - loss: 1.9196e-07 - accuracy: 1.0000 - val_loss: 2.1837e-06 - val_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 98ms/stepss: 3.3580e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 506ms/step - loss: 3.3580e-08 - accuracy: 1.0000 - val_loss: 2.1606e-06 - val_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 4.4268e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 448ms/step - loss: 4.4268e-07 - accuracy: 1.0000 - val_loss: 2.1305e-06 - val_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 8.3950e-09 - accuracy: \n",
      "7/7 [==============================] - 3s 442ms/step - loss: 8.3950e-09 - accuracy: 1.0000 - val_loss: 2.1108e-06 - val_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 91ms/stepss: 6.3071e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 434ms/step - loss: 6.3071e-07 - accuracy: 1.0000 - val_loss: 2.0969e-06 - val_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 5.6355e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 433ms/step - loss: 5.6355e-07 - accuracy: 1.0000 - val_loss: 2.0611e-06 - val_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 97ms/stepss: 4.1270e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 442ms/step - loss: 4.1270e-06 - accuracy: 1.0000 - val_loss: 1.9951e-06 - val_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 9.5144e-09 - accuracy: \n",
      "7/7 [==============================] - 3s 433ms/step - loss: 9.5144e-09 - accuracy: 1.0000 - val_loss: 1.9326e-06 - val_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 1.1858e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 436ms/step - loss: 1.1858e-06 - accuracy: 1.0000 - val_loss: 1.8701e-06 - val_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 6.1563e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 448ms/step - loss: 6.1563e-08 - accuracy: 1.0000 - val_loss: 1.8377e-06 - val_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 93ms/stepss: 1.7909e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 434ms/step - loss: 1.7909e-08 - accuracy: 1.0000 - val_loss: 1.8204e-06 - val_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 90ms/stepss: 6.1563e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 432ms/step - loss: 6.1563e-08 - accuracy: 1.0000 - val_loss: 1.8100e-06 - val_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 95ms/stepss: 1.7909e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 437ms/step - loss: 1.7909e-08 - accuracy: 1.0000 - val_loss: 1.8042e-06 - val_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 99ms/stepss: 2.8522e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 443ms/step - loss: 2.8522e-06 - accuracy: 1.0000 - val_loss: 1.7417e-06 - val_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 92ms/stepss: 9.4432e-06 - accuracy: \n",
      "7/7 [==============================] - 3s 425ms/step - loss: 9.4432e-06 - accuracy: 1.0000 - val_loss: 1.5901e-06 - val_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 92ms/stepss: 1.5223e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 429ms/step - loss: 1.5223e-07 - accuracy: 1.0000 - val_loss: 1.5068e-06 - val_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 84ms/stepss: 5.0370e-09 - accuracy: \n",
      "7/7 [==============================] - 3s 420ms/step - loss: 5.0370e-09 - accuracy: 1.0000 - val_loss: 1.4651e-06 - val_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 92ms/stepss: 4.2926e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 443ms/step - loss: 4.2926e-07 - accuracy: 1.0000 - val_loss: 1.4397e-06 - val_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 1.8133e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 441ms/step - loss: 1.8133e-07 - accuracy: 1.0000 - val_loss: 1.4177e-06 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 100ms/steps: 6.3242e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 450ms/step - loss: 6.3242e-08 - accuracy: 1.0000 - val_loss: 1.4061e-06 - val_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 94ms/stepss: 2.8655e-07 - accuracy: \n",
      "7/7 [==============================] - 3s 451ms/step - loss: 2.8655e-07 - accuracy: 1.0000 - val_loss: 1.3934e-06 - val_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 103ms/steps: 1.6790e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 458ms/step - loss: 1.6790e-08 - accuracy: 1.0000 - val_loss: 1.3853e-06 - val_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 99ms/stepss: 1.4551e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 475ms/step - loss: 1.4551e-08 - accuracy: 1.0000 - val_loss: 1.3807e-06 - val_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 99ms/stepss: 4.9810e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 451ms/step - loss: 4.9810e-08 - accuracy: 1.0000 - val_loss: 1.3772e-06 - val_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 104ms/steps: 9.4024e-08 - accuracy: \n",
      "7/7 [==============================] - 3s 477ms/step - loss: 9.4024e-08 - accuracy: 1.0000 - val_loss: 1.3737e-06 - val_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 98ms/stepss: 7.2757e-09 - accuracy: \n",
      "7/7 [==============================] - 3s 471ms/step - loss: 7.2757e-09 - accuracy: 1.0000 - val_loss: 1.3702e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, val_data_generator):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.val_data_generator = val_data_generator\n",
    "        self.metrics = {'accuracy': [], 'loss': [], 'f1_score': [], 'specificity': [], 'roc_auc': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Compute and record metrics\n",
    "        loss = logs.get('loss')\n",
    "        accuracy = logs.get('accuracy')\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_pred_probs = self.model.predict(self.val_data_generator)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "        # Get true labels from the validation data generator\n",
    "        y_true = self.val_data_generator.classes\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "        # Compute specificity\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        # Compute ROC AUC\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_probs[:, 1])\n",
    "\n",
    "        # Append metrics to the list\n",
    "        self.metrics['accuracy'].append(accuracy)\n",
    "        self.metrics['loss'].append(loss)\n",
    "        self.metrics['f1_score'].append(f1)\n",
    "        self.metrics['specificity'].append(specificity)\n",
    "        self.metrics['roc_auc'].append(roc_auc)\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Directory paths\n",
    "train_data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040 - Copy'\n",
    "val_data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040 - Copy (2)'\n",
    "\n",
    "# Image dimensions and batch size\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Create the model\n",
    "model = create_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "# Initialize the MetricsCallback\n",
    "metrics_callback = MetricsCallback(val_generator)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "# Save the trained model to disk\n",
    "model.save(\"my_trained_model_testing.h5\")\n",
    "\n",
    "# Save the metrics to an Excel file\n",
    "metrics_df = pd.DataFrame(metrics_callback.metrics)\n",
    "metrics_df.to_excel(\"final_testing_metrics.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5f1039-0b05-4d4f-983c-b6783aeb9d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 images belonging to 2 classes.\n",
      "Found 213 images belonging to 2 classes.\n",
      "Epoch 1/150\n",
      "7/7 [==============================] - 1s 109ms/steps: 0.8340 - ac\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 0.8340 - accuracy: 0.4951 - val_loss: 0.7778 - val_accuracy: 0.5023\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 0.6915 - ac\n",
      "4/4 [==============================] - 3s 904ms/step - loss: 0.6915 - accuracy: 0.6019 - val_loss: 0.5994 - val_accuracy: 0.8216\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - 1s 135ms/steps: 0.4715 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.4715 - accuracy: 0.9417 - val_loss: 0.4125 - val_accuracy: 0.8216\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - 1s 140ms/steps: 0.3406 - ac\n",
      "4/4 [==============================] - 3s 938ms/step - loss: 0.3406 - accuracy: 0.9126 - val_loss: 0.1995 - val_accuracy: 0.9484\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - 1s 131ms/steps: 0.1291 - ac\n",
      "4/4 [==============================] - 3s 983ms/step - loss: 0.1291 - accuracy: 0.9806 - val_loss: 0.3858 - val_accuracy: 0.8169\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - 1s 137ms/steps: 0.0804 - ac\n",
      "4/4 [==============================] - 3s 948ms/step - loss: 0.0804 - accuracy: 0.9903 - val_loss: 0.2790 - val_accuracy: 0.8498\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - 1s 122ms/steps: 0.0185 - ac\n",
      "4/4 [==============================] - 3s 913ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.8122\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0081 - ac\n",
      "4/4 [==============================] - 3s 938ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8310\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - 1s 134ms/steps: 0.0044 - accura\n",
      "4/4 [==============================] - 3s 861ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5868 - val_accuracy: 0.8451\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - 1s 123ms/steps: 0.0023 - accu\n",
      "4/4 [==============================] - 3s 902ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8602 - val_accuracy: 0.8451\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - 1s 149ms/steps: 3.6232e-04 - ac\n",
      "4/4 [==============================] - 3s 940ms/step - loss: 3.6232e-04 - accuracy: 1.0000 - val_loss: 1.2114 - val_accuracy: 0.8216\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 2.9171e-04 - ac\n",
      "4/4 [==============================] - 3s 860ms/step - loss: 2.9171e-04 - accuracy: 1.0000 - val_loss: 1.4602 - val_accuracy: 0.8122\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - 1s 127ms/steps: 0.0012 - accu\n",
      "4/4 [==============================] - 3s 927ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3725 - val_accuracy: 0.8169\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - 1s 131ms/steps: 4.5506e-04 - ac\n",
      "4/4 [==============================] - 3s 888ms/step - loss: 4.5506e-04 - accuracy: 1.0000 - val_loss: 1.1207 - val_accuracy: 0.8357\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 4.2064e-04 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 4.2064e-04 - accuracy: 1.0000 - val_loss: 0.9449 - val_accuracy: 0.8498\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - 1s 109ms/steps: 1.6816e-04 - ac\n",
      "4/4 [==============================] - 3s 891ms/step - loss: 1.6816e-04 - accuracy: 1.0000 - val_loss: 0.8873 - val_accuracy: 0.8498\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 1.1907e-04 - ac\n",
      "4/4 [==============================] - 3s 915ms/step - loss: 1.1907e-04 - accuracy: 1.0000 - val_loss: 0.8753 - val_accuracy: 0.8498\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - 1s 121ms/steps: 0.0011 - accu\n",
      "4/4 [==============================] - 3s 886ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0211 - val_accuracy: 0.8451\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - 1s 140ms/steps: 1.0164e-04 - ac\n",
      "4/4 [==============================] - 3s 927ms/step - loss: 1.0164e-04 - accuracy: 1.0000 - val_loss: 1.2650 - val_accuracy: 0.8310\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - 1s 126ms/steps: 7.7051e-05 - ac\n",
      "4/4 [==============================] - 3s 871ms/step - loss: 7.7051e-05 - accuracy: 1.0000 - val_loss: 1.4551 - val_accuracy: 0.8122\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - 1s 126ms/steps: 0.0017 - ac\n",
      "4/4 [==============================] - 3s 883ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.8357\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 2.1871e-05 - ac\n",
      "4/4 [==============================] - 3s 956ms/step - loss: 2.1871e-05 - accuracy: 1.0000 - val_loss: 1.0850 - val_accuracy: 0.8451\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 4.3694e-05 - ac\n",
      "4/4 [==============================] - 3s 859ms/step - loss: 4.3694e-05 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.8451\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 1.3346e-04 - ac\n",
      "4/4 [==============================] - 3s 966ms/step - loss: 1.3346e-04 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.8498\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 1.6488e-04 - ac\n",
      "4/4 [==============================] - 3s 900ms/step - loss: 1.6488e-04 - accuracy: 1.0000 - val_loss: 0.8980 - val_accuracy: 0.8498\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - 1s 121ms/steps: 2.7012e-05 - ac\n",
      "4/4 [==============================] - 3s 873ms/step - loss: 2.7012e-05 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.8498\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 2.7439e-05 - ac\n",
      "4/4 [==============================] - 3s 889ms/step - loss: 2.7439e-05 - accuracy: 1.0000 - val_loss: 0.8434 - val_accuracy: 0.8498\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - 1s 123ms/steps: 6.7111e-05 - ac\n",
      "4/4 [==============================] - 3s 896ms/step - loss: 6.7111e-05 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.8498\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - 1s 121ms/steps: 3.0729e-05 - ac\n",
      "4/4 [==============================] - 3s 911ms/step - loss: 3.0729e-05 - accuracy: 1.0000 - val_loss: 0.8182 - val_accuracy: 0.8498\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - 1s 131ms/steps: 8.3304e-05 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 8.3304e-05 - accuracy: 1.0000 - val_loss: 0.8225 - val_accuracy: 0.8498\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - 1s 141ms/steps: 7.8741e-05 - ac\n",
      "4/4 [==============================] - 3s 916ms/step - loss: 7.8741e-05 - accuracy: 1.0000 - val_loss: 0.8229 - val_accuracy: 0.8498\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - 1s 122ms/steps: 4.1950e-05 - ac\n",
      "4/4 [==============================] - 3s 867ms/step - loss: 4.1950e-05 - accuracy: 1.0000 - val_loss: 0.8256 - val_accuracy: 0.8498\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - 1s 121ms/steps: 3.1169e-05 - ac\n",
      "4/4 [==============================] - 3s 870ms/step - loss: 3.1169e-05 - accuracy: 1.0000 - val_loss: 0.8274 - val_accuracy: 0.8498\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 2.9759e-04 - ac\n",
      "4/4 [==============================] - 3s 863ms/step - loss: 2.9759e-04 - accuracy: 1.0000 - val_loss: 0.8988 - val_accuracy: 0.8498\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - 1s 132ms/steps: 1.5358e-04 - ac\n",
      "4/4 [==============================] - 3s 909ms/step - loss: 1.5358e-04 - accuracy: 1.0000 - val_loss: 1.0742 - val_accuracy: 0.8451\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - 1s 167ms/steps: 3.0799e-05 - ac\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.0799e-05 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.8451\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - 1s 139ms/steps: 0.0012 - ac\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0218 - val_accuracy: 0.8451\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - 1s 112ms/steps: 2.2573e-05 - ac\n",
      "4/4 [==============================] - 3s 902ms/step - loss: 2.2573e-05 - accuracy: 1.0000 - val_loss: 0.9105 - val_accuracy: 0.8498\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - 1s 121ms/steps: 1.2271e-05 - ac\n",
      "4/4 [==============================] - 3s 843ms/step - loss: 1.2271e-05 - accuracy: 1.0000 - val_loss: 0.8413 - val_accuracy: 0.8545\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 4.3672e-05 - ac\n",
      "4/4 [==============================] - 3s 871ms/step - loss: 4.3672e-05 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.8545\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - 1s 120ms/steps: 3.8852e-06 - ac\n",
      "4/4 [==============================] - 3s 856ms/step - loss: 3.8852e-06 - accuracy: 1.0000 - val_loss: 0.7730 - val_accuracy: 0.8545\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - 1s 118ms/steps: 1.7150e-05 - ac\n",
      "4/4 [==============================] - 3s 839ms/step - loss: 1.7150e-05 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.8545\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 1.3250e-04 - ac\n",
      "4/4 [==============================] - 3s 870ms/step - loss: 1.3250e-04 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8592\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - 1s 118ms/steps: 9.4991e-06 - ac\n",
      "4/4 [==============================] - 3s 847ms/step - loss: 9.4991e-06 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.8545\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - 1s 120ms/steps: 9.5301e-05 - ac\n",
      "4/4 [==============================] - 3s 914ms/step - loss: 9.5301e-05 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.8545\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - 1s 126ms/steps: 1.4908e-05 - ac\n",
      "4/4 [==============================] - 3s 943ms/step - loss: 1.4908e-05 - accuracy: 1.0000 - val_loss: 0.8225 - val_accuracy: 0.8545\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 2.1143e-05 - ac\n",
      "4/4 [==============================] - 3s 897ms/step - loss: 2.1143e-05 - accuracy: 1.0000 - val_loss: 0.8422 - val_accuracy: 0.8545\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - 1s 117ms/steps: 9.0083e-05 - ac\n",
      "4/4 [==============================] - 3s 972ms/step - loss: 9.0083e-05 - accuracy: 1.0000 - val_loss: 0.8567 - val_accuracy: 0.8545\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - 1s 141ms/steps: 1.1220e-05 - ac\n",
      "4/4 [==============================] - 3s 920ms/step - loss: 1.1220e-05 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.8545\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - 1s 139ms/steps: 2.6191e-05 - ac\n",
      "4/4 [==============================] - 3s 924ms/step - loss: 2.6191e-05 - accuracy: 1.0000 - val_loss: 0.8874 - val_accuracy: 0.8545\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 4.3780e-05 - ac\n",
      "4/4 [==============================] - 3s 915ms/step - loss: 4.3780e-05 - accuracy: 1.0000 - val_loss: 0.8971 - val_accuracy: 0.8545\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 1.0461e-05 - ac\n",
      "4/4 [==============================] - 3s 990ms/step - loss: 1.0461e-05 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.8545\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - 1s 138ms/steps: 6.2552e-06 - ac\n",
      "4/4 [==============================] - 3s 937ms/step - loss: 6.2552e-06 - accuracy: 1.0000 - val_loss: 0.9079 - val_accuracy: 0.8545\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - 1s 120ms/steps: 3.8608e-06 - ac\n",
      "4/4 [==============================] - 3s 937ms/step - loss: 3.8608e-06 - accuracy: 1.0000 - val_loss: 0.9111 - val_accuracy: 0.8545\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - 1s 138ms/steps: 6.0318e-05 - ac\n",
      "4/4 [==============================] - 3s 912ms/step - loss: 6.0318e-05 - accuracy: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.8545\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 1.4767e-05 - ac\n",
      "4/4 [==============================] - 3s 916ms/step - loss: 1.4767e-05 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.8498\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - 1s 137ms/steps: 1.8939e-05 - ac\n",
      "4/4 [==============================] - 3s 891ms/step - loss: 1.8939e-05 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.8498\n",
      "Epoch 58/150\n",
      "7/7 [==============================] - 1s 132ms/steps: 5.6210e-06 - ac\n",
      "4/4 [==============================] - 3s 968ms/step - loss: 5.6210e-06 - accuracy: 1.0000 - val_loss: 0.9712 - val_accuracy: 0.8498\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - 1s 135ms/steps: 9.7726e-06 - ac\n",
      "4/4 [==============================] - 3s 980ms/step - loss: 9.7726e-06 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.8498\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - 1s 127ms/steps: 2.2637e-05 - ac\n",
      "4/4 [==============================] - 3s 884ms/step - loss: 2.2637e-05 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.8498\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - 1s 118ms/steps: 5.6626e-06 - ac\n",
      "4/4 [==============================] - 3s 867ms/step - loss: 5.6626e-06 - accuracy: 1.0000 - val_loss: 0.9818 - val_accuracy: 0.8498\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 2.3379e-04 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 2.3379e-04 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.8545\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - 1s 138ms/steps: 1.4357e-05 - ac\n",
      "4/4 [==============================] - 3s 892ms/step - loss: 1.4357e-05 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.8545\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - 1s 136ms/steps: 7.1116e-06 - ac\n",
      "4/4 [==============================] - 3s 940ms/step - loss: 7.1116e-06 - accuracy: 1.0000 - val_loss: 0.9509 - val_accuracy: 0.8545\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - 1s 142ms/steps: 6.8176e-06 - ac\n",
      "4/4 [==============================] - 3s 945ms/step - loss: 6.8176e-06 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.8545\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - 1s 139ms/steps: 1.7479e-05 - ac\n",
      "4/4 [==============================] - 3s 906ms/step - loss: 1.7479e-05 - accuracy: 1.0000 - val_loss: 0.9372 - val_accuracy: 0.8545\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - 1s 124ms/steps: 7.1394e-06 - ac\n",
      "4/4 [==============================] - 3s 884ms/step - loss: 7.1394e-06 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 0.8545\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 1.8627e-05 - ac\n",
      "4/4 [==============================] - 3s 923ms/step - loss: 1.8627e-05 - accuracy: 1.0000 - val_loss: 0.9367 - val_accuracy: 0.8545\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 2.0647e-05 - ac\n",
      "4/4 [==============================] - 3s 908ms/step - loss: 2.0647e-05 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.8545\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 2.3054e-06 - ac\n",
      "4/4 [==============================] - 3s 897ms/step - loss: 2.3054e-06 - accuracy: 1.0000 - val_loss: 0.9315 - val_accuracy: 0.8545\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - 1s 136ms/steps: 3.3320e-06 - ac\n",
      "4/4 [==============================] - 3s 918ms/step - loss: 3.3320e-06 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.8545\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - 1s 141ms/steps: 1.7586e-05 - ac\n",
      "4/4 [==============================] - 3s 917ms/step - loss: 1.7586e-05 - accuracy: 1.0000 - val_loss: 0.9324 - val_accuracy: 0.8545\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - 1s 112ms/steps: 0.0011 - accura\n",
      "4/4 [==============================] - 3s 869ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0962 - val_accuracy: 0.8498\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 6.0756e-05 - ac\n",
      "4/4 [==============================] - 3s 870ms/step - loss: 6.0756e-05 - accuracy: 1.0000 - val_loss: 1.5125 - val_accuracy: 0.8169\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 8.6192e-05 - ac\n",
      "4/4 [==============================] - 3s 905ms/step - loss: 8.6192e-05 - accuracy: 1.0000 - val_loss: 1.6770 - val_accuracy: 0.8122\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - 1s 137ms/steps: 2.1928e-04 - ac\n",
      "4/4 [==============================] - 3s 921ms/step - loss: 2.1928e-04 - accuracy: 1.0000 - val_loss: 1.6177 - val_accuracy: 0.8122\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - 1s 127ms/steps: 2.6049e-04 - ac\n",
      "4/4 [==============================] - 3s 989ms/step - loss: 2.6049e-04 - accuracy: 1.0000 - val_loss: 1.4918 - val_accuracy: 0.8216\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - 1s 147ms/steps: 1.9116e-04 - ac\n",
      "4/4 [==============================] - 3s 967ms/step - loss: 1.9116e-04 - accuracy: 1.0000 - val_loss: 1.3546 - val_accuracy: 0.8216\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 2.4115e-04 - ac\n",
      "4/4 [==============================] - 3s 939ms/step - loss: 2.4115e-04 - accuracy: 1.0000 - val_loss: 1.2490 - val_accuracy: 0.8310\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - 1s 119ms/steps: 6.3212e-05 - ac\n",
      "4/4 [==============================] - 3s 972ms/step - loss: 6.3212e-05 - accuracy: 1.0000 - val_loss: 1.1623 - val_accuracy: 0.8357\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 1.4901e-04 - ac\n",
      "4/4 [==============================] - 3s 928ms/step - loss: 1.4901e-04 - accuracy: 1.0000 - val_loss: 1.0687 - val_accuracy: 0.8451\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - 1s 118ms/steps: 1.2370e-05 - ac\n",
      "4/4 [==============================] - 3s 851ms/step - loss: 1.2370e-05 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.8451\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - 1s 118ms/steps: 5.3518e-05 - ac\n",
      "4/4 [==============================] - 3s 863ms/step - loss: 5.3518e-05 - accuracy: 1.0000 - val_loss: 0.8518 - val_accuracy: 0.8498\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - 1s 131ms/steps: 1.0234e-04 - ac\n",
      "4/4 [==============================] - 3s 912ms/step - loss: 1.0234e-04 - accuracy: 1.0000 - val_loss: 1.0455 - val_accuracy: 0.8451\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - 1s 134ms/steps: 5.7492e-06 - ac\n",
      "4/4 [==============================] - 3s 888ms/step - loss: 5.7492e-06 - accuracy: 1.0000 - val_loss: 1.1395 - val_accuracy: 0.8451\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - 1s 136ms/steps: 5.6757e-05 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 5.6757e-05 - accuracy: 1.0000 - val_loss: 1.1836 - val_accuracy: 0.8404\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - 1s 144ms/steps: 1.1331e-05 - ac\n",
      "4/4 [==============================] - 3s 928ms/step - loss: 1.1331e-05 - accuracy: 1.0000 - val_loss: 1.2054 - val_accuracy: 0.8404\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - 1s 121ms/steps: 6.0625e-05 - ac\n",
      "4/4 [==============================] - 3s 892ms/step - loss: 6.0625e-05 - accuracy: 1.0000 - val_loss: 1.2123 - val_accuracy: 0.8404\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - 1s 141ms/steps: 6.7226e-06 - ac\n",
      "4/4 [==============================] - 3s 948ms/step - loss: 6.7226e-06 - accuracy: 1.0000 - val_loss: 1.2063 - val_accuracy: 0.8404\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - 1s 134ms/steps: 2.0832e-06 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 2.0832e-06 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.8451\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - 1s 129ms/steps: 6.4204e-05 - ac\n",
      "4/4 [==============================] - 3s 900ms/step - loss: 6.4204e-05 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.8404\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 7.1966e-05 - ac\n",
      "4/4 [==============================] - 3s 947ms/step - loss: 7.1966e-05 - accuracy: 1.0000 - val_loss: 1.2802 - val_accuracy: 0.8357\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - 1s 138ms/steps: 1.6982e-05 - ac\n",
      "4/4 [==============================] - 3s 943ms/step - loss: 1.6982e-05 - accuracy: 1.0000 - val_loss: 1.3155 - val_accuracy: 0.8357\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - 1s 132ms/steps: 5.6325e-06 - ac\n",
      "4/4 [==============================] - 3s 931ms/step - loss: 5.6325e-06 - accuracy: 1.0000 - val_loss: 1.3377 - val_accuracy: 0.8357\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - 1s 131ms/steps: 1.3183e-05 - ac\n",
      "4/4 [==============================] - 3s 882ms/step - loss: 1.3183e-05 - accuracy: 1.0000 - val_loss: 1.3469 - val_accuracy: 0.8357\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 1.8946e-06 - ac\n",
      "4/4 [==============================] - 3s 927ms/step - loss: 1.8946e-06 - accuracy: 1.0000 - val_loss: 1.3513 - val_accuracy: 0.8357\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - 1s 137ms/steps: 1.1355e-05 - ac\n",
      "4/4 [==============================] - 3s 877ms/step - loss: 1.1355e-05 - accuracy: 1.0000 - val_loss: 1.3535 - val_accuracy: 0.8357\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - 1s 132ms/steps: 2.2744e-05 - ac\n",
      "4/4 [==============================] - 3s 891ms/step - loss: 2.2744e-05 - accuracy: 1.0000 - val_loss: 1.3457 - val_accuracy: 0.8357\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - 1s 123ms/steps: 2.1191e-06 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 2.1191e-06 - accuracy: 1.0000 - val_loss: 1.3389 - val_accuracy: 0.8357\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - 1s 142ms/steps: 6.3441e-05 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 6.3441e-05 - accuracy: 1.0000 - val_loss: 1.3266 - val_accuracy: 0.8357\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - 1s 127ms/steps: 4.7168e-06 - ac\n",
      "4/4 [==============================] - 3s 908ms/step - loss: 4.7168e-06 - accuracy: 1.0000 - val_loss: 1.3126 - val_accuracy: 0.8404\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 1.0170e-05 - ac\n",
      "4/4 [==============================] - 3s 960ms/step - loss: 1.0170e-05 - accuracy: 1.0000 - val_loss: 1.2997 - val_accuracy: 0.8404\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - 1s 124ms/steps: 6.1679e-06 - ac\n",
      "4/4 [==============================] - 3s 953ms/step - loss: 6.1679e-06 - accuracy: 1.0000 - val_loss: 1.2871 - val_accuracy: 0.8404\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - 1s 135ms/steps: 8.2952e-06 - ac\n",
      "4/4 [==============================] - 3s 924ms/step - loss: 8.2952e-06 - accuracy: 1.0000 - val_loss: 1.2730 - val_accuracy: 0.8451\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - 1s 138ms/steps: 6.2258e-06 - ac\n",
      "4/4 [==============================] - 3s 950ms/step - loss: 6.2258e-06 - accuracy: 1.0000 - val_loss: 1.2592 - val_accuracy: 0.8451\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - 1s 138ms/steps: 4.4464e-06 - ac\n",
      "4/4 [==============================] - 3s 928ms/step - loss: 4.4464e-06 - accuracy: 1.0000 - val_loss: 1.2543 - val_accuracy: 0.8451\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - 1s 140ms/steps: 2.0959e-06 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 2.0959e-06 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.8451\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 1.6599e-05 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 1.6599e-05 - accuracy: 1.0000 - val_loss: 1.2489 - val_accuracy: 0.8451\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - 1s 132ms/steps: 1.7974e-06 - ac\n",
      "4/4 [==============================] - 3s 899ms/step - loss: 1.7974e-06 - accuracy: 1.0000 - val_loss: 1.2407 - val_accuracy: 0.8451\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - 1s 120ms/steps: 5.2898e-06 - ac\n",
      "4/4 [==============================] - 3s 914ms/step - loss: 5.2898e-06 - accuracy: 1.0000 - val_loss: 1.2378 - val_accuracy: 0.8451\n",
      "Epoch 111/150\n",
      "7/7 [==============================] - 1s 136ms/steps: 2.8237e-06 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 2.8237e-06 - accuracy: 1.0000 - val_loss: 1.2367 - val_accuracy: 0.8451\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - 1s 124ms/steps: 3.7206e-06 - ac\n",
      "4/4 [==============================] - 3s 942ms/step - loss: 3.7206e-06 - accuracy: 1.0000 - val_loss: 1.2290 - val_accuracy: 0.8451\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 1.7858e-06 - ac\n",
      "4/4 [==============================] - 3s 990ms/step - loss: 1.7858e-06 - accuracy: 1.0000 - val_loss: 1.2223 - val_accuracy: 0.8451\n",
      "Epoch 114/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 1.0439e-06 - ac\n",
      "4/4 [==============================] - 3s 914ms/step - loss: 1.0439e-06 - accuracy: 1.0000 - val_loss: 1.2182 - val_accuracy: 0.8451\n",
      "Epoch 115/150\n",
      "7/7 [==============================] - 1s 114ms/steps: 5.3933e-07 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 5.3933e-07 - accuracy: 1.0000 - val_loss: 1.2149 - val_accuracy: 0.8451\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - 1s 112ms/steps: 2.3667e-06 - ac\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 2.3667e-06 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.8451\n",
      "Epoch 117/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 1.5126e-06 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 1.5126e-06 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.8451\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - 1s 138ms/steps: 1.8424e-06 - ac\n",
      "4/4 [==============================] - 3s 902ms/step - loss: 1.8424e-06 - accuracy: 1.0000 - val_loss: 1.2066 - val_accuracy: 0.8451\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - 1s 119ms/steps: 2.2001e-06 - ac\n",
      "4/4 [==============================] - 3s 963ms/step - loss: 2.2001e-06 - accuracy: 1.0000 - val_loss: 1.2035 - val_accuracy: 0.8451\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 4.5933e-06 - ac\n",
      "4/4 [==============================] - 3s 903ms/step - loss: 4.5933e-06 - accuracy: 1.0000 - val_loss: 1.1902 - val_accuracy: 0.8451\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 5.1856e-06 - ac\n",
      "4/4 [==============================] - 3s 908ms/step - loss: 5.1856e-06 - accuracy: 1.0000 - val_loss: 1.1690 - val_accuracy: 0.8498\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - 1s 135ms/steps: 9.6755e-07 - ac\n",
      "4/4 [==============================] - 3s 986ms/step - loss: 9.6755e-07 - accuracy: 1.0000 - val_loss: 1.1529 - val_accuracy: 0.8498\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - 1s 144ms/steps: 6.7706e-07 - ac\n",
      "4/4 [==============================] - 3s 947ms/step - loss: 6.7706e-07 - accuracy: 1.0000 - val_loss: 1.1409 - val_accuracy: 0.8498\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - 1s 133ms/steps: 1.0625e-06 - ac\n",
      "4/4 [==============================] - 3s 902ms/step - loss: 1.0625e-06 - accuracy: 1.0000 - val_loss: 1.1325 - val_accuracy: 0.8498\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - 1s 131ms/steps: 2.6421e-06 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 2.6421e-06 - accuracy: 1.0000 - val_loss: 1.1271 - val_accuracy: 0.8498\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - 1s 122ms/steps: 9.2589e-07 - ac\n",
      "4/4 [==============================] - 3s 998ms/step - loss: 9.2589e-07 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.8498\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - 1s 134ms/steps: 6.0530e-07 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 6.0530e-07 - accuracy: 1.0000 - val_loss: 1.1237 - val_accuracy: 0.8498\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 2.6353e-06 - ac\n",
      "4/4 [==============================] - 3s 886ms/step - loss: 2.6353e-06 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.8498\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - 1s 137ms/steps: 1.2071e-06 - ac\n",
      "4/4 [==============================] - 3s 991ms/step - loss: 1.2071e-06 - accuracy: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.8498\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 8.2172e-07 - ac\n",
      "4/4 [==============================] - 3s 911ms/step - loss: 8.2172e-07 - accuracy: 1.0000 - val_loss: 1.1081 - val_accuracy: 0.8498\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - 1s 119ms/steps: 5.8794e-07 - ac\n",
      "4/4 [==============================] - 3s 900ms/step - loss: 5.8794e-07 - accuracy: 1.0000 - val_loss: 1.1074 - val_accuracy: 0.8498\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - 1s 131ms/steps: 6.8169e-07 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 6.8169e-07 - accuracy: 1.0000 - val_loss: 1.1066 - val_accuracy: 0.8498\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - 1s 137ms/steps: 7.8006e-07 - ac\n",
      "4/4 [==============================] - 3s 903ms/step - loss: 7.8006e-07 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.8498\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - 1s 137ms/steps: 1.8193e-06 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 1.8193e-06 - accuracy: 1.0000 - val_loss: 1.1063 - val_accuracy: 0.8498\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 8.4256e-07 - ac\n",
      "4/4 [==============================] - 3s 893ms/step - loss: 8.4256e-07 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.8498\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - 1s 135ms/steps: 5.8274e-05 - ac\n",
      "4/4 [==============================] - 3s 924ms/step - loss: 5.8274e-05 - accuracy: 1.0000 - val_loss: 1.2134 - val_accuracy: 0.8451\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - 1s 125ms/steps: 2.5993e-06 - ac\n",
      "4/4 [==============================] - 3s 955ms/step - loss: 2.5993e-06 - accuracy: 1.0000 - val_loss: 1.4169 - val_accuracy: 0.8357\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - 1s 129ms/steps: 7.5807e-07 - ac\n",
      "4/4 [==============================] - 3s 950ms/step - loss: 7.5807e-07 - accuracy: 1.0000 - val_loss: 1.5030 - val_accuracy: 0.8310\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - 1s 138ms/steps: 1.0250e-05 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 1.0250e-05 - accuracy: 1.0000 - val_loss: 1.5456 - val_accuracy: 0.8310\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 1.0583e-05 - ac\n",
      "4/4 [==============================] - 3s 923ms/step - loss: 1.0583e-05 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.8310\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - 1s 127ms/steps: 3.5102e-06 - ac\n",
      "4/4 [==============================] - 3s 934ms/step - loss: 3.5102e-06 - accuracy: 1.0000 - val_loss: 1.5773 - val_accuracy: 0.8263\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 6.8628e-06 - ac\n",
      "4/4 [==============================] - 3s 874ms/step - loss: 6.8628e-06 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.8263\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - 1s 126ms/steps: 4.8560e-06 - ac\n",
      "4/4 [==============================] - 3s 958ms/step - loss: 4.8560e-06 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.8263\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - 1s 136ms/steps: 1.5865e-05 - ac\n",
      "4/4 [==============================] - 3s 936ms/step - loss: 1.5865e-05 - accuracy: 1.0000 - val_loss: 1.5789 - val_accuracy: 0.8310\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - 1s 130ms/steps: 4.7642e-06 - ac\n",
      "4/4 [==============================] - 3s 907ms/step - loss: 4.7642e-06 - accuracy: 1.0000 - val_loss: 1.5743 - val_accuracy: 0.8310\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - 1s 128ms/steps: 4.1501e-06 - ac\n",
      "4/4 [==============================] - 3s 955ms/step - loss: 4.1501e-06 - accuracy: 1.0000 - val_loss: 1.5677 - val_accuracy: 0.8310\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - 1s 124ms/steps: 4.7619e-06 - ac\n",
      "4/4 [==============================] - 3s 907ms/step - loss: 4.7619e-06 - accuracy: 1.0000 - val_loss: 1.5577 - val_accuracy: 0.8310\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - 1s 131ms/steps: 4.8388e-06 - ac\n",
      "4/4 [==============================] - 3s 1s/step - loss: 4.8388e-06 - accuracy: 1.0000 - val_loss: 1.5343 - val_accuracy: 0.8310\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - 1s 141ms/steps: 1.7256e-06 - ac\n",
      "4/4 [==============================] - 3s 902ms/step - loss: 1.7256e-06 - accuracy: 1.0000 - val_loss: 1.5169 - val_accuracy: 0.8310\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - 1s 126ms/steps: 2.6977e-06 - ac\n",
      "4/4 [==============================] - 3s 921ms/step - loss: 2.6977e-06 - accuracy: 1.0000 - val_loss: 1.5034 - val_accuracy: 0.8357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, val_data_generator):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.val_data_generator = val_data_generator\n",
    "        self.metrics = {'accuracy': [], 'loss': [], 'f1_score': [], 'specificity': [], 'roc_auc': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Compute and record metrics\n",
    "        loss = logs.get('loss')\n",
    "        accuracy = logs.get('accuracy')\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_pred_probs = self.model.predict(self.val_data_generator)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "        # Get true labels from the validation data generator\n",
    "        y_true = self.val_data_generator.classes\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "        # Compute specificity\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        # Compute ROC AUC\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_probs[:, 1])\n",
    "\n",
    "        # Append metrics to the list\n",
    "        self.metrics['accuracy'].append(accuracy)\n",
    "        self.metrics['loss'].append(loss)\n",
    "        self.metrics['f1_score'].append(f1)\n",
    "        self.metrics['specificity'].append(specificity)\n",
    "        self.metrics['roc_auc'].append(roc_auc)\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Directory paths\n",
    "train_data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040 - Copy (2)'\n",
    "val_data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040 - Copy'\n",
    "\n",
    "# Image dimensions and batch size\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Create the model\n",
    "model = create_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "# Initialize the MetricsCallback\n",
    "metrics_callback = MetricsCallback(val_generator)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "# Save the trained model to disk\n",
    "model.save(\"my_trained_model_validation.h5\")\n",
    "\n",
    "# Save the metrics to an Excel file\n",
    "metrics_df = pd.DataFrame(metrics_callback.metrics)\n",
    "metrics_df.to_excel(\"final_validation_metrics.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d081b8-b228-4366-980d-12b75fc510e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation 10%\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def det_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    def lr_schedule(epoch):\n",
    "        initial_learning_rate = 0.001\n",
    "        decay = 0.9\n",
    "        epochs_drop = 10\n",
    "        learning_rate = initial_learning_rate * decay ** (epoch // epochs_drop)\n",
    "        return learning_rate\n",
    "\n",
    "    lr_callback = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model, lr_callback\n",
    "\n",
    "\n",
    "data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040 - Copy (2)' \n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "cnn_model, lr_callback = det_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=300,\n",
    "    callbacks=[lr_callback]\n",
    ")\n",
    "\n",
    "# Save the trained model to disk\n",
    "cnn_model.save(\"my_trained_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7185d793-954a-4cfe-a420-2d3d20dd3c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 724 images belonging to 2 classes.\n",
      "Epoch 1/150\n",
      "23/23 [==============================] - 5s 211ms/step\n",
      "23/23 [==============================] - 14s 608ms/step - loss: 0.7829 - accuracy: 0.5884 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 5s 199ms/step\n",
      "23/23 [==============================] - 13s 591ms/step - loss: 0.5522 - accuracy: 0.7224 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 5s 217ms/step\n",
      "23/23 [==============================] - 14s 610ms/step - loss: 0.4126 - accuracy: 0.8163 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 6s 260ms/step\n",
      "23/23 [==============================] - 15s 655ms/step - loss: 0.3207 - accuracy: 0.8688 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 14s 612ms/step - loss: 0.3304 - accuracy: 0.8729 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.3008 - accuracy: 0.8771 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 4s 179ms/step\n",
      "23/23 [==============================] - 11s 461ms/step - loss: 0.2918 - accuracy: 0.8757 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 0.2638 - accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.2597 - accuracy: 0.8895 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.3383 - accuracy: 0.8494 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.2423 - accuracy: 0.9075 - lr: 9.0000e-04\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 454ms/step - loss: 0.2520 - accuracy: 0.8992 - lr: 9.0000e-04\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.2134 - accuracy: 0.9171 - lr: 9.0000e-04\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.1984 - accuracy: 0.9227 - lr: 9.0000e-04\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.2111 - accuracy: 0.9102 - lr: 9.0000e-04\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.1810 - accuracy: 0.9406 - lr: 9.0000e-04\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 441ms/step - loss: 0.1737 - accuracy: 0.9323 - lr: 9.0000e-04\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.1526 - accuracy: 0.9475 - lr: 9.0000e-04\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 4s 168ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.1783 - accuracy: 0.9309 - lr: 9.0000e-04\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.1833 - accuracy: 0.9351 - lr: 9.0000e-04\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.1938 - accuracy: 0.9296 - lr: 8.1000e-04\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 4s 173ms/step\n",
      "23/23 [==============================] - 10s 448ms/step - loss: 0.1641 - accuracy: 0.9420 - lr: 8.1000e-04\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.1585 - accuracy: 0.9378 - lr: 8.1000e-04\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 4s 176ms/step\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 0.1831 - accuracy: 0.9351 - lr: 8.1000e-04\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 4s 178ms/step\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.1699 - accuracy: 0.9240 - lr: 8.1000e-04\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 4s 177ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.1560 - accuracy: 0.9489 - lr: 8.1000e-04\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 0.1236 - accuracy: 0.9572 - lr: 8.1000e-04\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 445ms/step - loss: 0.1953 - accuracy: 0.9323 - lr: 8.1000e-04\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 455ms/step - loss: 0.1465 - accuracy: 0.9392 - lr: 8.1000e-04\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.1494 - accuracy: 0.9448 - lr: 8.1000e-04\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.1406 - accuracy: 0.9517 - lr: 7.2900e-04\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 441ms/step - loss: 0.1341 - accuracy: 0.9489 - lr: 7.2900e-04\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 445ms/step - loss: 0.1350 - accuracy: 0.9448 - lr: 7.2900e-04\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.1095 - accuracy: 0.9599 - lr: 7.2900e-04\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.0922 - accuracy: 0.9613 - lr: 7.2900e-04\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0934 - accuracy: 0.9572 - lr: 7.2900e-04\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 4s 182ms/step\n",
      "23/23 [==============================] - 11s 474ms/step - loss: 0.1070 - accuracy: 0.9627 - lr: 7.2900e-04\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 5s 199ms/step\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.1244 - accuracy: 0.9586 - lr: 7.2900e-04\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 4s 168ms/step\n",
      "23/23 [==============================] - 10s 445ms/step - loss: 0.1062 - accuracy: 0.9669 - lr: 7.2900e-04\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 4s 189ms/step\n",
      "23/23 [==============================] - 11s 472ms/step - loss: 0.1056 - accuracy: 0.9599 - lr: 7.2900e-04\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0902 - accuracy: 0.9627 - lr: 6.5610e-04\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.0987 - accuracy: 0.9669 - lr: 6.5610e-04\n",
      "Epoch 43/150\n",
      "23/23 [==============================] - 4s 167ms/step\n",
      "23/23 [==============================] - 10s 441ms/step - loss: 0.0849 - accuracy: 0.9724 - lr: 6.5610e-04\n",
      "Epoch 44/150\n",
      "23/23 [==============================] - 4s 168ms/step\n",
      "23/23 [==============================] - 10s 434ms/step - loss: 0.0659 - accuracy: 0.9751 - lr: 6.5610e-04\n",
      "Epoch 45/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0826 - accuracy: 0.9710 - lr: 6.5610e-04\n",
      "Epoch 46/150\n",
      "23/23 [==============================] - 4s 173ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.0991 - accuracy: 0.9613 - lr: 6.5610e-04\n",
      "Epoch 47/150\n",
      "23/23 [==============================] - 4s 166ms/step\n",
      "23/23 [==============================] - 10s 434ms/step - loss: 0.0937 - accuracy: 0.9627 - lr: 6.5610e-04\n",
      "Epoch 48/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0667 - accuracy: 0.9807 - lr: 6.5610e-04\n",
      "Epoch 49/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 437ms/step - loss: 0.0701 - accuracy: 0.9738 - lr: 6.5610e-04\n",
      "Epoch 50/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 438ms/step - loss: 0.0633 - accuracy: 0.9751 - lr: 6.5610e-04\n",
      "Epoch 51/150\n",
      "23/23 [==============================] - 4s 166ms/step\n",
      "23/23 [==============================] - 10s 434ms/step - loss: 0.0851 - accuracy: 0.9779 - lr: 5.9049e-04\n",
      "Epoch 52/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 438ms/step - loss: 0.0810 - accuracy: 0.9793 - lr: 5.9049e-04\n",
      "Epoch 53/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 448ms/step - loss: 0.0787 - accuracy: 0.9765 - lr: 5.9049e-04\n",
      "Epoch 54/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 437ms/step - loss: 0.0577 - accuracy: 0.9793 - lr: 5.9049e-04\n",
      "Epoch 55/150\n",
      "23/23 [==============================] - 4s 166ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.0531 - accuracy: 0.9807 - lr: 5.9049e-04\n",
      "Epoch 56/150\n",
      "23/23 [==============================] - 4s 166ms/step\n",
      "23/23 [==============================] - 10s 436ms/step - loss: 0.0615 - accuracy: 0.9793 - lr: 5.9049e-04\n",
      "Epoch 57/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.0836 - accuracy: 0.9641 - lr: 5.9049e-04\n",
      "Epoch 58/150\n",
      "23/23 [==============================] - 4s 175ms/step\n",
      "23/23 [==============================] - 10s 441ms/step - loss: 0.0618 - accuracy: 0.9820 - lr: 5.9049e-04\n",
      "Epoch 59/150\n",
      "23/23 [==============================] - 4s 167ms/step\n",
      "23/23 [==============================] - 10s 438ms/step - loss: 0.0607 - accuracy: 0.9834 - lr: 5.9049e-04\n",
      "Epoch 60/150\n",
      "23/23 [==============================] - 4s 166ms/step\n",
      "23/23 [==============================] - 10s 433ms/step - loss: 0.0609 - accuracy: 0.9738 - lr: 5.9049e-04\n",
      "Epoch 61/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.0585 - accuracy: 0.9724 - lr: 5.3144e-04\n",
      "Epoch 62/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0522 - accuracy: 0.9820 - lr: 5.3144e-04\n",
      "Epoch 63/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 437ms/step - loss: 0.0455 - accuracy: 0.9834 - lr: 5.3144e-04\n",
      "Epoch 64/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0537 - accuracy: 0.9807 - lr: 5.3144e-04\n",
      "Epoch 65/150\n",
      "23/23 [==============================] - 4s 173ms/step\n",
      "23/23 [==============================] - 10s 445ms/step - loss: 0.0473 - accuracy: 0.9862 - lr: 5.3144e-04\n",
      "Epoch 66/150\n",
      "23/23 [==============================] - 4s 175ms/step\n",
      "23/23 [==============================] - 10s 436ms/step - loss: 0.0505 - accuracy: 0.9807 - lr: 5.3144e-04\n",
      "Epoch 67/150\n",
      "23/23 [==============================] - 4s 173ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0319 - accuracy: 0.9848 - lr: 5.3144e-04\n",
      "Epoch 68/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0508 - accuracy: 0.9890 - lr: 5.3144e-04\n",
      "Epoch 69/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 436ms/step - loss: 0.0325 - accuracy: 0.9848 - lr: 5.3144e-04\n",
      "Epoch 70/150\n",
      "23/23 [==============================] - 4s 175ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.0357 - accuracy: 0.9931 - lr: 5.3144e-04\n",
      "Epoch 71/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.0369 - accuracy: 0.9890 - lr: 4.7830e-04\n",
      "Epoch 72/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0578 - accuracy: 0.9820 - lr: 4.7830e-04\n",
      "Epoch 73/150\n",
      "23/23 [==============================] - 4s 175ms/step\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.0277 - accuracy: 0.9931 - lr: 4.7830e-04\n",
      "Epoch 74/150\n",
      "23/23 [==============================] - 4s 175ms/step\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.0408 - accuracy: 0.9820 - lr: 4.7830e-04\n",
      "Epoch 75/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 441ms/step - loss: 0.0753 - accuracy: 0.9779 - lr: 4.7830e-04\n",
      "Epoch 76/150\n",
      "23/23 [==============================] - 4s 168ms/step\n",
      "23/23 [==============================] - 10s 435ms/step - loss: 0.0627 - accuracy: 0.9807 - lr: 4.7830e-04\n",
      "Epoch 77/150\n",
      "23/23 [==============================] - 4s 165ms/step\n",
      "23/23 [==============================] - 10s 436ms/step - loss: 0.0480 - accuracy: 0.9848 - lr: 4.7830e-04\n",
      "Epoch 78/150\n",
      "23/23 [==============================] - 4s 173ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0308 - accuracy: 0.9917 - lr: 4.7830e-04\n",
      "Epoch 79/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0245 - accuracy: 0.9931 - lr: 4.7830e-04\n",
      "Epoch 80/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 442ms/step - loss: 0.0469 - accuracy: 0.9876 - lr: 4.7830e-04\n",
      "Epoch 81/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 438ms/step - loss: 0.0235 - accuracy: 0.9917 - lr: 4.3047e-04\n",
      "Epoch 82/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0234 - accuracy: 0.9931 - lr: 4.3047e-04\n",
      "Epoch 83/150\n",
      "23/23 [==============================] - 4s 166ms/step\n",
      "23/23 [==============================] - 10s 434ms/step - loss: 0.0275 - accuracy: 0.9917 - lr: 4.3047e-04\n",
      "Epoch 84/150\n",
      "23/23 [==============================] - 4s 173ms/step\n",
      "23/23 [==============================] - 10s 437ms/step - loss: 0.0495 - accuracy: 0.9834 - lr: 4.3047e-04\n",
      "Epoch 85/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 437ms/step - loss: 0.0333 - accuracy: 0.9862 - lr: 4.3047e-04\n",
      "Epoch 86/150\n",
      "23/23 [==============================] - 4s 168ms/step\n",
      "23/23 [==============================] - 10s 436ms/step - loss: 0.0389 - accuracy: 0.9890 - lr: 4.3047e-04\n",
      "Epoch 87/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0395 - accuracy: 0.9848 - lr: 4.3047e-04\n",
      "Epoch 88/150\n",
      "23/23 [==============================] - 4s 176ms/step\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.0454 - accuracy: 0.9848 - lr: 4.3047e-04\n",
      "Epoch 89/150\n",
      "23/23 [==============================] - 4s 179ms/step\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.0310 - accuracy: 0.9876 - lr: 4.3047e-04\n",
      "Epoch 90/150\n",
      "23/23 [==============================] - 4s 175ms/step\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 0.0335 - accuracy: 0.9903 - lr: 4.3047e-04\n",
      "Epoch 91/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.0344 - accuracy: 0.9862 - lr: 3.8742e-04\n",
      "Epoch 92/150\n",
      "23/23 [==============================] - 4s 175ms/step\n",
      "23/23 [==============================] - 10s 442ms/step - loss: 0.0120 - accuracy: 0.9986 - lr: 3.8742e-04\n",
      "Epoch 93/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.0314 - accuracy: 0.9903 - lr: 3.8742e-04\n",
      "Epoch 94/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0182 - accuracy: 0.9931 - lr: 3.8742e-04\n",
      "Epoch 95/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.0245 - accuracy: 0.9917 - lr: 3.8742e-04\n",
      "Epoch 96/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 441ms/step - loss: 0.0139 - accuracy: 0.9959 - lr: 3.8742e-04\n",
      "Epoch 97/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.0256 - accuracy: 0.9917 - lr: 3.8742e-04\n",
      "Epoch 98/150\n",
      "23/23 [==============================] - 4s 177ms/step\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.0224 - accuracy: 0.9959 - lr: 3.8742e-04\n",
      "Epoch 99/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0280 - accuracy: 0.9959 - lr: 3.8742e-04\n",
      "Epoch 100/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0206 - accuracy: 0.9917 - lr: 3.8742e-04\n",
      "Epoch 101/150\n",
      "23/23 [==============================] - 4s 174ms/step\n",
      "23/23 [==============================] - 10s 445ms/step - loss: 0.0142 - accuracy: 0.9931 - lr: 3.4868e-04\n",
      "Epoch 102/150\n",
      "23/23 [==============================] - 4s 170ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0319 - accuracy: 0.9903 - lr: 3.4868e-04\n",
      "Epoch 103/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0161 - accuracy: 0.9959 - lr: 3.4868e-04\n",
      "Epoch 104/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 439ms/step - loss: 0.0311 - accuracy: 0.9903 - lr: 3.4868e-04\n",
      "Epoch 105/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.0282 - accuracy: 0.9931 - lr: 3.4868e-04\n",
      "Epoch 106/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 432ms/step - loss: 0.0182 - accuracy: 0.9931 - lr: 3.4868e-04\n",
      "Epoch 107/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 442ms/step - loss: 0.0140 - accuracy: 0.9972 - lr: 3.4868e-04\n",
      "Epoch 108/150\n",
      "23/23 [==============================] - 4s 167ms/step\n",
      "23/23 [==============================] - 10s 430ms/step - loss: 0.0182 - accuracy: 0.9945 - lr: 3.4868e-04\n",
      "Epoch 109/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.0105 - accuracy: 0.9986 - lr: 3.4868e-04\n",
      "Epoch 110/150\n",
      "23/23 [==============================] - 4s 188ms/step\n",
      "23/23 [==============================] - 10s 454ms/step - loss: 0.0151 - accuracy: 0.9959 - lr: 3.4868e-04\n",
      "Epoch 111/150\n",
      "23/23 [==============================] - 4s 190ms/step\n",
      "23/23 [==============================] - 11s 475ms/step - loss: 0.0328 - accuracy: 0.9903 - lr: 3.1381e-04\n",
      "Epoch 112/150\n",
      "23/23 [==============================] - 4s 173ms/step\n",
      "23/23 [==============================] - 11s 475ms/step - loss: 0.0221 - accuracy: 0.9917 - lr: 3.1381e-04\n",
      "Epoch 113/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 454ms/step - loss: 0.0145 - accuracy: 0.9959 - lr: 3.1381e-04\n",
      "Epoch 114/150\n",
      "23/23 [==============================] - 4s 176ms/step\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.0120 - accuracy: 0.9959 - lr: 3.1381e-04\n",
      "Epoch 115/150\n",
      "23/23 [==============================] - 4s 171ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0137 - accuracy: 0.9972 - lr: 3.1381e-04\n",
      "Epoch 116/150\n",
      "23/23 [==============================] - 4s 177ms/step\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.0123 - accuracy: 0.9972 - lr: 3.1381e-04\n",
      "Epoch 117/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0199 - accuracy: 0.9945 - lr: 3.1381e-04\n",
      "Epoch 118/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 437ms/step - loss: 0.0159 - accuracy: 0.9945 - lr: 3.1381e-04\n",
      "Epoch 119/150\n",
      "23/23 [==============================] - 4s 169ms/step\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.0175 - accuracy: 0.9945 - lr: 3.1381e-04\n",
      "Epoch 120/150\n",
      "23/23 [==============================] - 4s 179ms/step\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 0.0189 - accuracy: 0.9972 - lr: 3.1381e-04\n",
      "Epoch 121/150\n",
      "23/23 [==============================] - 4s 172ms/step\n",
      "23/23 [==============================] - 10s 442ms/step - loss: 0.0137 - accuracy: 0.9945 - lr: 2.8243e-04\n",
      "Epoch 122/150\n",
      "23/23 [==============================] - 4s 179ms/step\n",
      "23/23 [==============================] - 11s 461ms/step - loss: 0.0132 - accuracy: 0.9945 - lr: 2.8243e-04\n",
      "Epoch 123/150\n",
      "23/23 [==============================] - 4s 164ms/step\n",
      "23/23 [==============================] - 10s 441ms/step - loss: 0.0127 - accuracy: 0.9931 - lr: 2.8243e-04\n",
      "Epoch 124/150\n",
      "23/23 [==============================] - 4s 162ms/step\n",
      "23/23 [==============================] - 10s 438ms/step - loss: 0.0167 - accuracy: 0.9945 - lr: 2.8243e-04\n",
      "Epoch 125/150\n",
      "23/23 [==============================] - 4s 160ms/step\n",
      "23/23 [==============================] - 10s 440ms/step - loss: 0.0140 - accuracy: 0.9972 - lr: 2.8243e-04\n",
      "Epoch 126/150\n",
      "23/23 [==============================] - 5s 216ms/step\n",
      "23/23 [==============================] - 12s 509ms/step - loss: 0.0123 - accuracy: 0.9959 - lr: 2.8243e-04\n",
      "Epoch 127/150\n",
      "23/23 [==============================] - 5s 202ms/step\n",
      "23/23 [==============================] - 12s 542ms/step - loss: 0.0071 - accuracy: 0.9986 - lr: 2.8243e-04\n",
      "Epoch 128/150\n",
      "23/23 [==============================] - 5s 209ms/step\n",
      "23/23 [==============================] - 13s 563ms/step - loss: 0.0166 - accuracy: 0.9917 - lr: 2.8243e-04\n",
      "Epoch 129/150\n",
      "23/23 [==============================] - 5s 214ms/step\n",
      "23/23 [==============================] - 13s 554ms/step - loss: 0.0117 - accuracy: 0.9972 - lr: 2.8243e-04\n",
      "Epoch 130/150\n",
      "23/23 [==============================] - 5s 210ms/step\n",
      "23/23 [==============================] - 13s 550ms/step - loss: 0.0146 - accuracy: 0.9917 - lr: 2.8243e-04\n",
      "Epoch 131/150\n",
      "23/23 [==============================] - 5s 214ms/step\n",
      "23/23 [==============================] - 13s 551ms/step - loss: 0.0114 - accuracy: 0.9972 - lr: 2.5419e-04\n",
      "Epoch 132/150\n",
      "23/23 [==============================] - 5s 211ms/step\n",
      "23/23 [==============================] - 13s 551ms/step - loss: 0.0283 - accuracy: 0.9903 - lr: 2.5419e-04\n",
      "Epoch 133/150\n",
      "23/23 [==============================] - 5s 215ms/step\n",
      "23/23 [==============================] - 13s 567ms/step - loss: 0.0212 - accuracy: 0.9931 - lr: 2.5419e-04\n",
      "Epoch 134/150\n",
      "23/23 [==============================] - 5s 200ms/step\n",
      "23/23 [==============================] - 12s 546ms/step - loss: 0.0071 - accuracy: 0.9986 - lr: 2.5419e-04\n",
      "Epoch 135/150\n",
      "23/23 [==============================] - 5s 194ms/step\n",
      "23/23 [==============================] - 12s 533ms/step - loss: 0.0085 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 136/150\n",
      "23/23 [==============================] - 5s 228ms/step\n",
      "23/23 [==============================] - 13s 565ms/step - loss: 0.0077 - accuracy: 0.9972 - lr: 2.5419e-04\n",
      "Epoch 137/150\n",
      "23/23 [==============================] - 5s 216ms/step\n",
      "23/23 [==============================] - 13s 579ms/step - loss: 0.0186 - accuracy: 0.9903 - lr: 2.5419e-04\n",
      "Epoch 138/150\n",
      "23/23 [==============================] - 5s 202ms/step\n",
      "23/23 [==============================] - 12s 545ms/step - loss: 0.0091 - accuracy: 0.9986 - lr: 2.5419e-04\n",
      "Epoch 139/150\n",
      "23/23 [==============================] - 4s 190ms/step\n",
      "23/23 [==============================] - 12s 516ms/step - loss: 0.0144 - accuracy: 0.9945 - lr: 2.5419e-04\n",
      "Epoch 140/150\n",
      "23/23 [==============================] - 5s 196ms/step\n",
      "23/23 [==============================] - 12s 523ms/step - loss: 0.0098 - accuracy: 0.9959 - lr: 2.5419e-04\n",
      "Epoch 141/150\n",
      "23/23 [==============================] - 5s 200ms/step\n",
      "23/23 [==============================] - 12s 531ms/step - loss: 0.0200 - accuracy: 0.9890 - lr: 2.2877e-04\n",
      "Epoch 142/150\n",
      "23/23 [==============================] - 5s 199ms/step\n",
      "23/23 [==============================] - 12s 530ms/step - loss: 0.0194 - accuracy: 0.9959 - lr: 2.2877e-04\n",
      "Epoch 143/150\n",
      "23/23 [==============================] - 4s 193ms/step\n",
      "23/23 [==============================] - 12s 528ms/step - loss: 0.0112 - accuracy: 0.9986 - lr: 2.2877e-04\n",
      "Epoch 144/150\n",
      "23/23 [==============================] - 5s 197ms/step\n",
      "23/23 [==============================] - 13s 554ms/step - loss: 0.0100 - accuracy: 0.9986 - lr: 2.2877e-04\n",
      "Epoch 145/150\n",
      "23/23 [==============================] - 5s 230ms/step\n",
      "23/23 [==============================] - 14s 599ms/step - loss: 0.0145 - accuracy: 0.9931 - lr: 2.2877e-04\n",
      "Epoch 146/150\n",
      "23/23 [==============================] - 5s 233ms/step\n",
      "23/23 [==============================] - 14s 598ms/step - loss: 0.0109 - accuracy: 0.9959 - lr: 2.2877e-04\n",
      "Epoch 147/150\n",
      "23/23 [==============================] - 5s 227ms/step\n",
      "23/23 [==============================] - 14s 592ms/step - loss: 0.0096 - accuracy: 0.9986 - lr: 2.2877e-04\n",
      "Epoch 148/150\n",
      "23/23 [==============================] - 6s 246ms/step\n",
      "23/23 [==============================] - 14s 612ms/step - loss: 0.0107 - accuracy: 0.9959 - lr: 2.2877e-04\n",
      "Epoch 149/150\n",
      "23/23 [==============================] - 5s 195ms/step\n",
      "23/23 [==============================] - 13s 547ms/step - loss: 0.0118 - accuracy: 0.9959 - lr: 2.2877e-04\n",
      "Epoch 150/150\n",
      "23/23 [==============================] - 6s 258ms/step\n",
      "23/23 [==============================] - 14s 629ms/step - loss: 0.0085 - accuracy: 0.9986 - lr: 2.2877e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, train_data):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.history = {'epoch': [], 'accuracy': [], 'loss': [], 'f1_score': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.history['epoch'].append(epoch + 1)\n",
    "        self.history['accuracy'].append(logs['accuracy'])\n",
    "        self.history['loss'].append(logs['loss'])\n",
    "        \n",
    "        y_true = self.train_data.labels\n",
    "        y_pred = self.model.predict(self.train_data).argmax(axis=1)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        self.history['f1_score'].append(f1)\n",
    "\n",
    "def det_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    def lr_schedule(epoch):\n",
    "        initial_learning_rate = 0.001\n",
    "        decay = 0.9\n",
    "        epochs_drop = 10\n",
    "        learning_rate = initial_learning_rate * decay ** (epoch // epochs_drop)\n",
    "        return learning_rate\n",
    "\n",
    "    lr_callback = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model, lr_callback\n",
    "\n",
    "data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040' \n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "cnn_model, lr_callback = det_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "# Add the MetricsCallback to store accuracy, loss, and f1 score for each epoch\n",
    "metrics_callback = MetricsCallback(train_generator)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    callbacks=[lr_callback, metrics_callback]\n",
    ")\n",
    "\n",
    "# Save the trained model to disk\n",
    "cnn_model.save(\"my_trained_model.h5\")\n",
    "\n",
    "# Create a DataFrame to store accuracy, loss, and f1 score for each epoch\n",
    "metrics_df = pd.DataFrame(metrics_callback.history)\n",
    "metrics_df.to_excel(\"vgg_training_metrics.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daaf38a8-1f4d-4d81-9ce9-5dc9cc0a0b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 213 images belonging to 2 classes.\n",
      "Epoch 1/150\n",
      "7/7 [==============================] - 1s 181ms/steps: 0.9473 - ac\n",
      "7/7 [==============================] - 4s 541ms/step - loss: 0.9473 - accuracy: 0.4883 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - 1s 163ms/steps: 0.6745 - ac\n",
      "7/7 [==============================] - 3s 487ms/step - loss: 0.6745 - accuracy: 0.6479 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - 1s 164ms/steps: 0.6201 - ac\n",
      "7/7 [==============================] - 3s 508ms/step - loss: 0.6201 - accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - 1s 177ms/steps: 0.5249 - ac\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.5249 - accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - 1s 158ms/steps: 0.5097 - ac\n",
      "7/7 [==============================] - 3s 484ms/step - loss: 0.5097 - accuracy: 0.7418 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - 1s 167ms/steps: 0.4020 - ac\n",
      "7/7 [==============================] - 3s 507ms/step - loss: 0.4020 - accuracy: 0.8310 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.2872 - ac\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 0.2872 - accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.3048 - ac\n",
      "7/7 [==============================] - 3s 510ms/step - loss: 0.3048 - accuracy: 0.8638 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.3747 - ac\n",
      "7/7 [==============================] - 3s 494ms/step - loss: 0.3747 - accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - 1s 186ms/steps: 0.2786 - ac\n",
      "7/7 [==============================] - 3s 490ms/step - loss: 0.2786 - accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - 2s 215ms/steps: 0.2707 - ac\n",
      "7/7 [==============================] - 4s 564ms/step - loss: 0.2707 - accuracy: 0.8873 - lr: 9.0000e-04\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - 1s 175ms/steps: 0.2798 - ac\n",
      "7/7 [==============================] - 4s 626ms/step - loss: 0.2798 - accuracy: 0.8732 - lr: 9.0000e-04\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.1926 - ac\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.1926 - accuracy: 0.9484 - lr: 9.0000e-04\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.1927 - ac\n",
      "7/7 [==============================] - 4s 519ms/step - loss: 0.1927 - accuracy: 0.9249 - lr: 9.0000e-04\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.1858 - ac\n",
      "7/7 [==============================] - 4s 534ms/step - loss: 0.1858 - accuracy: 0.9390 - lr: 9.0000e-04\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - 1s 150ms/steps: 0.1567 - ac\n",
      "7/7 [==============================] - 4s 552ms/step - loss: 0.1567 - accuracy: 0.9390 - lr: 9.0000e-04\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.1740 - ac\n",
      "7/7 [==============================] - 3s 514ms/step - loss: 0.1740 - accuracy: 0.9390 - lr: 9.0000e-04\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.1781 - ac\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.1781 - accuracy: 0.9531 - lr: 9.0000e-04\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.1348 - ac\n",
      "7/7 [==============================] - 3s 504ms/step - loss: 0.1348 - accuracy: 0.9577 - lr: 9.0000e-04\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.1509 - ac\n",
      "7/7 [==============================] - 3s 495ms/step - loss: 0.1509 - accuracy: 0.9531 - lr: 9.0000e-04\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.1058 - ac\n",
      "7/7 [==============================] - 3s 467ms/step - loss: 0.1058 - accuracy: 0.9531 - lr: 8.1000e-04\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.1045 - ac\n",
      "7/7 [==============================] - 3s 483ms/step - loss: 0.1045 - accuracy: 0.9624 - lr: 8.1000e-04\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - 1s 163ms/steps: 0.0983 - ac\n",
      "7/7 [==============================] - 3s 494ms/step - loss: 0.0983 - accuracy: 0.9718 - lr: 8.1000e-04\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - 1s 175ms/steps: 0.1238 - ac\n",
      "7/7 [==============================] - 3s 479ms/step - loss: 0.1238 - accuracy: 0.9484 - lr: 8.1000e-04\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - 1s 203ms/steps: 0.1185 - ac\n",
      "7/7 [==============================] - 4s 610ms/step - loss: 0.1185 - accuracy: 0.9624 - lr: 8.1000e-04\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - 1s 160ms/steps: 0.0723 - ac\n",
      "7/7 [==============================] - 4s 552ms/step - loss: 0.0723 - accuracy: 0.9765 - lr: 8.1000e-04\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - 1s 161ms/steps: 0.1025 - ac\n",
      "7/7 [==============================] - 3s 471ms/step - loss: 0.1025 - accuracy: 0.9577 - lr: 8.1000e-04\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - 1s 161ms/steps: 0.1217 - ac\n",
      "7/7 [==============================] - 3s 476ms/step - loss: 0.1217 - accuracy: 0.9437 - lr: 8.1000e-04\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.1433 - ac\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.1433 - accuracy: 0.9343 - lr: 8.1000e-04\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.1741 - ac\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.1741 - accuracy: 0.9577 - lr: 8.1000e-04\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.1686 - ac\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.1686 - accuracy: 0.9155 - lr: 7.2900e-04\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.1482 - ac\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 0.1482 - accuracy: 0.9671 - lr: 7.2900e-04\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.1094 - ac\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 0.1094 - accuracy: 0.9718 - lr: 7.2900e-04\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - 1s 150ms/steps: 0.1094 - ac\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 0.1094 - accuracy: 0.9577 - lr: 7.2900e-04\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.1022 - ac\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 0.1022 - accuracy: 0.9718 - lr: 7.2900e-04\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - 1s 158ms/steps: 0.0595 - ac\n",
      "7/7 [==============================] - 3s 486ms/step - loss: 0.0595 - accuracy: 0.9859 - lr: 7.2900e-04\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.0582 - ac\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 0.0582 - accuracy: 0.9859 - lr: 7.2900e-04\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - 1s 152ms/steps: 0.0768 - ac\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.0768 - accuracy: 0.9765 - lr: 7.2900e-04\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0720 - ac\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.0720 - accuracy: 0.9671 - lr: 7.2900e-04\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.0685 - ac\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 0.0685 - accuracy: 0.9718 - lr: 7.2900e-04\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - 1s 170ms/steps: 0.0732 - ac\n",
      "7/7 [==============================] - 3s 489ms/step - loss: 0.0732 - accuracy: 0.9812 - lr: 6.5610e-04\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - 1s 166ms/steps: 0.0563 - ac\n",
      "7/7 [==============================] - 3s 496ms/step - loss: 0.0563 - accuracy: 0.9812 - lr: 6.5610e-04\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.1917 - ac\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 0.1917 - accuracy: 0.9718 - lr: 6.5610e-04\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - 1s 158ms/steps: 0.0544 - ac\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 0.0544 - accuracy: 0.9812 - lr: 6.5610e-04\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0364 - ac\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.0364 - accuracy: 0.9906 - lr: 6.5610e-04\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - 1s 152ms/steps: 0.0392 - ac\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.0392 - accuracy: 0.9906 - lr: 6.5610e-04\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - 1s 162ms/steps: 0.0748 - ac\n",
      "7/7 [==============================] - 3s 476ms/step - loss: 0.0748 - accuracy: 0.9671 - lr: 6.5610e-04\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - 1s 150ms/steps: 0.0335 - ac\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 0.0335 - accuracy: 0.9906 - lr: 6.5610e-04\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - 1s 162ms/steps: 0.0512 - ac\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.0512 - accuracy: 0.9859 - lr: 6.5610e-04\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0404 - ac\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 0.0404 - accuracy: 0.9859 - lr: 6.5610e-04\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - 1s 161ms/steps: 0.0524 - ac\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.0524 - accuracy: 0.9765 - lr: 5.9049e-04\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - 1s 160ms/steps: 0.1108 - ac\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 0.1108 - accuracy: 0.9718 - lr: 5.9049e-04\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0475 - ac\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.0475 - accuracy: 0.9859 - lr: 5.9049e-04\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - 1s 162ms/steps: 0.0534 - ac\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 0.0534 - accuracy: 0.9906 - lr: 5.9049e-04\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.0248 - ac\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.0248 - accuracy: 0.9953 - lr: 5.9049e-04\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0197 - ac\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.0197 - accuracy: 0.9859 - lr: 5.9049e-04\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0599 - ac\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.0599 - accuracy: 0.9765 - lr: 5.9049e-04\n",
      "Epoch 58/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0947 - ac\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.0947 - accuracy: 0.9718 - lr: 5.9049e-04\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.0372 - ac\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.0372 - accuracy: 0.9859 - lr: 5.9049e-04\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0506 - ac\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.0506 - accuracy: 0.9812 - lr: 5.9049e-04\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - 1s 150ms/steps: 0.0485 - ac\n",
      "7/7 [==============================] - 3s 467ms/step - loss: 0.0485 - accuracy: 0.9812 - lr: 5.3144e-04\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - 1s 152ms/steps: 0.0512 - ac\n",
      "7/7 [==============================] - 3s 474ms/step - loss: 0.0512 - accuracy: 0.9859 - lr: 5.3144e-04\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0354 - ac\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.0354 - accuracy: 0.9812 - lr: 5.3144e-04\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - 1s 149ms/steps: 0.0323 - ac\n",
      "7/7 [==============================] - 3s 439ms/step - loss: 0.0323 - accuracy: 0.9953 - lr: 5.3144e-04\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0378 - ac\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 0.0378 - accuracy: 0.9812 - lr: 5.3144e-04\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0368 - ac\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.0368 - accuracy: 0.9812 - lr: 5.3144e-04\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.0686 - ac\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.0686 - accuracy: 0.9718 - lr: 5.3144e-04\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0533 - ac\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.0533 - accuracy: 0.9765 - lr: 5.3144e-04\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0756 - ac\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.0756 - accuracy: 0.9859 - lr: 5.3144e-04\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0400 - ac\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.0400 - accuracy: 0.9953 - lr: 5.3144e-04\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.0661 - ac\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 0.0661 - accuracy: 0.9718 - lr: 4.7830e-04\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0396 - ac\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.0396 - accuracy: 0.9765 - lr: 4.7830e-04\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - 1s 179ms/steps: 0.0420 - ac\n",
      "7/7 [==============================] - 4s 556ms/step - loss: 0.0420 - accuracy: 0.9906 - lr: 4.7830e-04\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - 1s 167ms/steps: 0.0224 - ac\n",
      "7/7 [==============================] - 3s 467ms/step - loss: 0.0224 - accuracy: 0.9953 - lr: 4.7830e-04\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - 1s 172ms/steps: 0.0543 - ac\n",
      "7/7 [==============================] - 4s 525ms/step - loss: 0.0543 - accuracy: 0.9765 - lr: 4.7830e-04\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0271 - ac\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 0.0271 - accuracy: 0.9906 - lr: 4.7830e-04\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0269 - ac\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.0269 - accuracy: 0.9859 - lr: 4.7830e-04\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - 1s 149ms/steps: 0.0293 - ac\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.0293 - accuracy: 0.9906 - lr: 4.7830e-04\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0290 - ac\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.0290 - accuracy: 0.9906 - lr: 4.7830e-04\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.0103 - ac\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.0103 - accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0152 - ac\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.0152 - accuracy: 0.9906 - lr: 4.3047e-04\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - 1s 160ms/steps: 0.0120 - ac\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.0120 - accuracy: 1.0000 - lr: 4.3047e-04\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.0310 - ac\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 0.0310 - accuracy: 0.9859 - lr: 4.3047e-04\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - 1s 158ms/steps: 0.0485 - ac\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.0485 - accuracy: 0.9812 - lr: 4.3047e-04\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0488 - ac\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 0.0488 - accuracy: 0.9859 - lr: 4.3047e-04\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0585 - ac\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.0585 - accuracy: 0.9718 - lr: 4.3047e-04\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.0958 - ac\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.0958 - accuracy: 0.9577 - lr: 4.3047e-04\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.0475 - ac\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.0475 - accuracy: 0.9765 - lr: 4.3047e-04\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0360 - ac\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.0360 - accuracy: 0.9859 - lr: 4.3047e-04\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - 1s 158ms/steps: 0.0296 - ac\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.0296 - accuracy: 0.9859 - lr: 4.3047e-04\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.0183 - ac\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 0.0183 - accuracy: 0.9953 - lr: 3.8742e-04\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0184 - ac\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.0184 - accuracy: 0.9953 - lr: 3.8742e-04\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0173 - ac\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 0.0173 - accuracy: 0.9906 - lr: 3.8742e-04\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - 1s 164ms/steps: 0.0175 - ac\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 0.0175 - accuracy: 0.9953 - lr: 3.8742e-04\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0132 - ac\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.0132 - accuracy: 0.9953 - lr: 3.8742e-04\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0258 - ac\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0258 - accuracy: 0.9906 - lr: 3.8742e-04\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - 1s 152ms/steps: 0.0192 - ac\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.0192 - accuracy: 0.9953 - lr: 3.8742e-04\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.0147 - ac\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.0147 - accuracy: 0.9953 - lr: 3.8742e-04\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.0224 - ac\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 0.0224 - accuracy: 0.9906 - lr: 3.8742e-04\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0341 - ac\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.0341 - accuracy: 0.9812 - lr: 3.8742e-04\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.0142 - ac\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.0142 - accuracy: 0.9953 - lr: 3.4868e-04\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0144 - ac\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.0144 - accuracy: 0.9953 - lr: 3.4868e-04\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.0191 - ac\n",
      "7/7 [==============================] - 3s 438ms/step - loss: 0.0191 - accuracy: 0.9906 - lr: 3.4868e-04\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - 1s 144ms/steps: 0.0274 - ac\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.0274 - accuracy: 0.9859 - lr: 3.4868e-04\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0110 - ac\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.0110 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - 1s 142ms/steps: 0.0206 - ac\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.0206 - accuracy: 0.9953 - lr: 3.4868e-04\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.0051 - ac\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.0051 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - 1s 152ms/steps: 0.0169 - ac\n",
      "7/7 [==============================] - 3s 467ms/step - loss: 0.0169 - accuracy: 0.9906 - lr: 3.4868e-04\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0086 - ac\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.0086 - accuracy: 0.9953 - lr: 3.4868e-04\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - 1s 147ms/steps: 0.0139 - ac\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.0139 - accuracy: 0.9906 - lr: 3.4868e-04\n",
      "Epoch 111/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0094 - ac\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.0094 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0120 - ac\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.0120 - accuracy: 0.9953 - lr: 3.1381e-04\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - 1s 158ms/steps: 0.0034 - ac\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.0034 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 114/150\n",
      "7/7 [==============================] - 1s 163ms/steps: 0.0112 - ac\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.0112 - accuracy: 0.9953 - lr: 3.1381e-04\n",
      "Epoch 115/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0124 - ac\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 0.0124 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - 1s 158ms/steps: 0.0062 - ac\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.0062 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 117/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0119 - ac\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.0119 - accuracy: 0.9953 - lr: 3.1381e-04\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0100 - ac\n",
      "7/7 [==============================] - 3s 438ms/step - loss: 0.0100 - accuracy: 0.9953 - lr: 3.1381e-04\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - 1s 159ms/steps: 0.0987 - ac\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.0987 - accuracy: 0.9859 - lr: 3.1381e-04\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0377 - ac\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 0.0377 - accuracy: 0.9906 - lr: 3.1381e-04\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0826 - ac\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.0826 - accuracy: 0.9577 - lr: 2.8243e-04\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - 1s 143ms/steps: 0.0136 - ac\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.0136 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - 1s 148ms/steps: 0.0223 - ac\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.0223 - accuracy: 0.9859 - lr: 2.8243e-04\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - 1s 149ms/steps: 0.0079 - ac\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.0079 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0147 - ac\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.0147 - accuracy: 0.9953 - lr: 2.8243e-04\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0105 - ac\n",
      "7/7 [==============================] - 3s 438ms/step - loss: 0.0105 - accuracy: 0.9953 - lr: 2.8243e-04\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - 1s 149ms/steps: 0.0115 - ac\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.0115 - accuracy: 0.9953 - lr: 2.8243e-04\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.0181 - ac\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.0181 - accuracy: 0.9906 - lr: 2.8243e-04\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - 1s 144ms/steps: 0.0178 - ac\n",
      "7/7 [==============================] - 3s 436ms/step - loss: 0.0178 - accuracy: 0.9953 - lr: 2.8243e-04\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0122 - ac\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 0.0122 - accuracy: 0.9953 - lr: 2.8243e-04\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - 1s 162ms/steps: 0.0111 - ac\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.0111 - accuracy: 0.9953 - lr: 2.5419e-04\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0126 - ac\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.0126 - accuracy: 0.9953 - lr: 2.5419e-04\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.0177 - ac\n",
      "7/7 [==============================] - 3s 438ms/step - loss: 0.0177 - accuracy: 0.9906 - lr: 2.5419e-04\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0057 - ac\n",
      "7/7 [==============================] - 3s 436ms/step - loss: 0.0057 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - 1s 160ms/steps: 0.0073 - ac\n",
      "7/7 [==============================] - 3s 478ms/step - loss: 0.0073 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - 1s 158ms/steps: 0.0112 - ac\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.0112 - accuracy: 0.9953 - lr: 2.5419e-04\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0138 - ac\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.0138 - accuracy: 0.9953 - lr: 2.5419e-04\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - 1s 151ms/steps: 0.0224 - ac\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.0224 - accuracy: 0.9906 - lr: 2.5419e-04\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - 1s 149ms/steps: 0.0108 - ac\n",
      "7/7 [==============================] - 3s 439ms/step - loss: 0.0108 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - 1s 153ms/steps: 0.0117 - ac\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.0117 - accuracy: 0.9953 - lr: 2.5419e-04\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - 1s 154ms/steps: 0.0144 - ac\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.0144 - accuracy: 0.9906 - lr: 2.2877e-04\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - 1s 157ms/steps: 0.0081 - ac\n",
      "7/7 [==============================] - 3s 436ms/step - loss: 0.0081 - accuracy: 0.9953 - lr: 2.2877e-04\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - 1s 147ms/steps: 0.0102 - ac\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.0102 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - 1s 143ms/steps: 0.0115 - ac\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.0115 - accuracy: 0.9953 - lr: 2.2877e-04\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - 1s 145ms/steps: 0.0049 - ac\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 0.0049 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - 1s 156ms/steps: 0.0039 - ac\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.0039 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - 1s 150ms/steps: 0.0034 - ac\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 0.0034 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - 1s 152ms/steps: 0.0062 - ac\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.0062 - accuracy: 0.9953 - lr: 2.2877e-04\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - 1s 146ms/steps: 0.0030 - ac\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.0030 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - 1s 155ms/steps: 0.0030 - ac\n",
      "7/7 [==============================] - 3s 436ms/step - loss: 0.0030 - accuracy: 1.0000 - lr: 2.2877e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, train_data):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.history = {'epoch': [], 'accuracy': [], 'loss': [], 'f1_score': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.history['epoch'].append(epoch + 1)\n",
    "        self.history['accuracy'].append(logs['accuracy'])\n",
    "        self.history['loss'].append(logs['loss'])\n",
    "        \n",
    "        y_true = self.train_data.labels\n",
    "        y_pred = self.model.predict(self.train_data).argmax(axis=1)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        self.history['f1_score'].append(f1)\n",
    "\n",
    "def det_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    def lr_schedule(epoch):\n",
    "        initial_learning_rate = 0.001\n",
    "        decay = 0.9\n",
    "        epochs_drop = 10\n",
    "        learning_rate = initial_learning_rate * decay ** (epoch // epochs_drop)\n",
    "        return learning_rate\n",
    "\n",
    "    lr_callback = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model, lr_callback\n",
    "\n",
    "data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040 - Copy' \n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "cnn_model, lr_callback = det_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "# Add the MetricsCallback to store accuracy, loss, and f1 score for each epoch\n",
    "metrics_callback = MetricsCallback(train_generator)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    callbacks=[lr_callback, metrics_callback]\n",
    ")\n",
    "\n",
    "# Save the trained model to disk\n",
    "cnn_model.save(\"my_trained_model.h5\")\n",
    "\n",
    "# Create a DataFrame to store accuracy, loss, and f1 score for each epoch\n",
    "metrics_df = pd.DataFrame(metrics_callback.history)\n",
    "metrics_df.to_excel(\"vgg_testing_metrics.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae9c8fa-cbec-484b-bb27-1b4a708c735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 images belonging to 2 classes.\n",
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 124ms/steps: 1.1265 - accuracy: \n",
      "4/4 [==============================] - 2s 556ms/step - loss: 1.1265 - accuracy: 0.3981 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 1s 123ms/steps: 0.6991 - accuracy: \n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.6991 - accuracy: 0.5437 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 1s 132ms/steps: 0.6910 - accuracy: \n",
      "4/4 [==============================] - 2s 471ms/step - loss: 0.6910 - accuracy: 0.4854 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 1s 132ms/steps: 0.6818 - accuracy: \n",
      "4/4 [==============================] - 2s 467ms/step - loss: 0.6818 - accuracy: 0.5534 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 1s 150ms/steps: 0.6529 - accuracy: \n",
      "4/4 [==============================] - 2s 464ms/step - loss: 0.6529 - accuracy: 0.5825 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 1s 118ms/steps: 0.6141 - accuracy: \n",
      "4/4 [==============================] - 2s 494ms/step - loss: 0.6141 - accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 1s 158ms/steps: 0.5595 - accuracy: \n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.5595 - accuracy: 0.7573 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 1s 128ms/steps: 0.4847 - accuracy: \n",
      "4/4 [==============================] - 2s 530ms/step - loss: 0.4847 - accuracy: 0.7864 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 1s 120ms/steps: 0.5104 - accuracy: \n",
      "4/4 [==============================] - 2s 463ms/step - loss: 0.5104 - accuracy: 0.7379 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 1s 144ms/steps: 0.3949 - accuracy: \n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.3949 - accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 1s 115ms/steps: 0.3189 - accuracy: \n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.3189 - accuracy: 0.8835 - lr: 9.0000e-04\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 1s 136ms/steps: 0.3473 - accuracy: \n",
      "4/4 [==============================] - 2s 630ms/step - loss: 0.3473 - accuracy: 0.8544 - lr: 9.0000e-04\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 1s 126ms/steps: 0.3042 - accuracy: \n",
      "4/4 [==============================] - 2s 458ms/step - loss: 0.3042 - accuracy: 0.8738 - lr: 9.0000e-04\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 1s 106ms/steps: 0.3409 - accuracy: \n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.3409 - accuracy: 0.8641 - lr: 9.0000e-04\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 1s 136ms/steps: 0.2183 - accuracy: \n",
      "4/4 [==============================] - 2s 455ms/step - loss: 0.2183 - accuracy: 0.9320 - lr: 9.0000e-04\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 1s 130ms/steps: 0.1810 - accuracy: \n",
      "4/4 [==============================] - 2s 529ms/step - loss: 0.1810 - accuracy: 0.9320 - lr: 9.0000e-04\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 1s 139ms/steps: 0.2583 - accuracy: \n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.2583 - accuracy: 0.8835 - lr: 9.0000e-04\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 1s 126ms/steps: 0.1773 - accuracy: \n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.1773 - accuracy: 0.9612 - lr: 9.0000e-04\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 1s 119ms/steps: 0.1422 - accuracy: \n",
      "4/4 [==============================] - 2s 427ms/step - loss: 0.1422 - accuracy: 0.9515 - lr: 9.0000e-04\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 1s 122ms/steps: 0.1705 - accuracy: \n",
      "4/4 [==============================] - 2s 440ms/step - loss: 0.1705 - accuracy: 0.9417 - lr: 9.0000e-04\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 1s 129ms/steps: 0.1352 - accuracy: \n",
      "4/4 [==============================] - 2s 422ms/step - loss: 0.1352 - accuracy: 0.9320 - lr: 8.1000e-04\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 1s 111ms/steps: 0.1793 - accuracy: \n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.1793 - accuracy: 0.9515 - lr: 8.1000e-04\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 1s 126ms/steps: 0.1498 - accuracy: \n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.1498 - accuracy: 0.9515 - lr: 8.1000e-04\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 1s 110ms/steps: 0.0726 - accuracy: \n",
      "4/4 [==============================] - 2s 497ms/step - loss: 0.0726 - accuracy: 0.9806 - lr: 8.1000e-04\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 1s 117ms/steps: 0.1606 - accuracy: \n",
      "4/4 [==============================] - 2s 447ms/step - loss: 0.1606 - accuracy: 0.9515 - lr: 8.1000e-04\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 1s 132ms/steps: 0.1694 - accuracy: \n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.1694 - accuracy: 0.9223 - lr: 8.1000e-04\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 1s 117ms/steps: 0.1132 - accuracy: \n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.1132 - accuracy: 0.9612 - lr: 8.1000e-04\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 1s 115ms/steps: 0.1307 - accuracy: \n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.1307 - accuracy: 0.9417 - lr: 8.1000e-04\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 1s 115ms/steps: 0.1437 - accuracy: \n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.1437 - accuracy: 0.9515 - lr: 8.1000e-04\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 100ms/steps: 0.1358 - accuracy: \n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.1358 - accuracy: 0.9417 - lr: 8.1000e-04\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 1s 123ms/steps: 0.0829 - accuracy: \n",
      "4/4 [==============================] - 2s 430ms/step - loss: 0.0829 - accuracy: 0.9709 - lr: 7.2900e-04\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 1s 98ms/stepss: 0.1715 - accuracy: \n",
      "4/4 [==============================] - 2s 511ms/step - loss: 0.1715 - accuracy: 0.9417 - lr: 7.2900e-04\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 1s 122ms/steps: 0.1114 - accuracy: \n",
      "4/4 [==============================] - 2s 454ms/step - loss: 0.1114 - accuracy: 0.9612 - lr: 7.2900e-04\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 1s 123ms/steps: 0.0802 - accuracy: \n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.0802 - accuracy: 1.0000 - lr: 7.2900e-04\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 1s 129ms/steps: 0.1339 - accuracy: \n",
      "4/4 [==============================] - 2s 449ms/step - loss: 0.1339 - accuracy: 0.9515 - lr: 7.2900e-04\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 1s 113ms/steps: 0.0615 - accuracy: \n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.0615 - accuracy: 0.9806 - lr: 7.2900e-04\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 1s 124ms/steps: 0.0585 - accuracy: \n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.0585 - accuracy: 0.9806 - lr: 7.2900e-04\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 1s 107ms/steps: 0.0681 - accuracy: \n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.0681 - accuracy: 0.9709 - lr: 7.2900e-04\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 1s 107ms/steps: 0.0860 - accuracy: \n",
      "4/4 [==============================] - 2s 430ms/step - loss: 0.0860 - accuracy: 0.9709 - lr: 7.2900e-04\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 1s 120ms/steps: 0.0932 - accuracy: \n",
      "4/4 [==============================] - 2s 504ms/step - loss: 0.0932 - accuracy: 0.9612 - lr: 7.2900e-04\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 1s 125ms/steps: 0.0775 - accuracy: \n",
      "4/4 [==============================] - 2s 443ms/step - loss: 0.0775 - accuracy: 0.9709 - lr: 6.5610e-04\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 1s 121ms/steps: 0.1169 - accuracy: \n",
      "4/4 [==============================] - 2s 430ms/step - loss: 0.1169 - accuracy: 0.9709 - lr: 6.5610e-04\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 1s 130ms/steps: 0.1649 - accuracy: \n",
      "4/4 [==============================] - 2s 472ms/step - loss: 0.1649 - accuracy: 0.9612 - lr: 6.5610e-04\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 1s 128ms/steps: 0.0435 - accuracy: \n",
      "4/4 [==============================] - 2s 447ms/step - loss: 0.0435 - accuracy: 0.9903 - lr: 6.5610e-04\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 1s 130ms/steps: 0.0986 - accuracy: \n",
      "4/4 [==============================] - 2s 478ms/step - loss: 0.0986 - accuracy: 0.9806 - lr: 6.5610e-04\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 1s 112ms/steps: 0.0906 - accuracy: \n",
      "4/4 [==============================] - 2s 536ms/step - loss: 0.0906 - accuracy: 0.9806 - lr: 6.5610e-04\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 1s 151ms/steps: 0.0625 - accuracy: \n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.0625 - accuracy: 0.9806 - lr: 6.5610e-04\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 1s 141ms/steps: 0.0609 - accuracy: \n",
      "4/4 [==============================] - 2s 507ms/step - loss: 0.0609 - accuracy: 0.9806 - lr: 6.5610e-04\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 1s 125ms/steps: 0.0730 - accuracy: \n",
      "4/4 [==============================] - 2s 468ms/step - loss: 0.0730 - accuracy: 0.9709 - lr: 6.5610e-04\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 1s 113ms/steps: 0.0469 - accuracy: \n",
      "4/4 [==============================] - 2s 402ms/step - loss: 0.0469 - accuracy: 0.9903 - lr: 6.5610e-04\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 1s 109ms/steps: 0.1035 - accuracy: \n",
      "4/4 [==============================] - 2s 410ms/step - loss: 0.1035 - accuracy: 0.9806 - lr: 5.9049e-04\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 1s 116ms/steps: 0.0687 - accuracy: \n",
      "4/4 [==============================] - 2s 450ms/step - loss: 0.0687 - accuracy: 0.9903 - lr: 5.9049e-04\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 1s 112ms/steps: 0.0730 - accuracy: \n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.0730 - accuracy: 0.9903 - lr: 5.9049e-04\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 1s 123ms/steps: 0.0711 - accuracy: \n",
      "4/4 [==============================] - 2s 523ms/step - loss: 0.0711 - accuracy: 0.9806 - lr: 5.9049e-04\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 1s 102ms/steps: 0.0305 - accuracy: \n",
      "4/4 [==============================] - 2s 507ms/step - loss: 0.0305 - accuracy: 0.9903 - lr: 5.9049e-04\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 1s 119ms/steps: 0.0264 - accuracy: \n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.0264 - accuracy: 0.9903 - lr: 5.9049e-04\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 1s 124ms/steps: 0.0623 - accuracy: \n",
      "4/4 [==============================] - 2s 459ms/step - loss: 0.0623 - accuracy: 0.9806 - lr: 5.9049e-04\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 1s 115ms/steps: 0.1054 - accuracy: \n",
      "4/4 [==============================] - 2s 520ms/step - loss: 0.1054 - accuracy: 0.9515 - lr: 5.9049e-04\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 1s 117ms/steps: 0.0389 - accuracy: \n",
      "4/4 [==============================] - 2s 424ms/step - loss: 0.0389 - accuracy: 0.9903 - lr: 5.9049e-04\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 1s 110ms/steps: 0.0875 - accuracy: \n",
      "4/4 [==============================] - 2s 430ms/step - loss: 0.0875 - accuracy: 0.9806 - lr: 5.9049e-04\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 1s 131ms/steps: 0.0421 - accuracy: \n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.0421 - accuracy: 0.9903 - lr: 5.3144e-04\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 1s 123ms/steps: 0.0154 - accuracy: \n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.0154 - accuracy: 1.0000 - lr: 5.3144e-04\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 1s 117ms/steps: 0.0219 - accuracy: \n",
      "4/4 [==============================] - 2s 442ms/step - loss: 0.0219 - accuracy: 1.0000 - lr: 5.3144e-04\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 1s 143ms/steps: 0.0579 - accuracy: \n",
      "4/4 [==============================] - 2s 646ms/step - loss: 0.0579 - accuracy: 0.9612 - lr: 5.3144e-04\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 1s 117ms/steps: 0.0502 - accuracy: \n",
      "4/4 [==============================] - 2s 473ms/step - loss: 0.0502 - accuracy: 0.9806 - lr: 5.3144e-04\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 1s 125ms/steps: 0.0164 - accuracy: \n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.0164 - accuracy: 1.0000 - lr: 5.3144e-04\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 1s 117ms/steps: 0.3590 - accuracy: \n",
      "4/4 [==============================] - 2s 435ms/step - loss: 0.3590 - accuracy: 0.9806 - lr: 5.3144e-04\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 1s 124ms/steps: 0.0403 - accuracy: \n",
      "4/4 [==============================] - 2s 421ms/step - loss: 0.0403 - accuracy: 0.9806 - lr: 5.3144e-04\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 1s 108ms/steps: 0.0405 - accuracy: \n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.0405 - accuracy: 0.9903 - lr: 5.3144e-04\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 1s 107ms/steps: 0.0297 - accuracy: \n",
      "4/4 [==============================] - 2s 432ms/step - loss: 0.0297 - accuracy: 0.9903 - lr: 5.3144e-04\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 1s 130ms/steps: 0.0112 - accuracy: \n",
      "4/4 [==============================] - 2s 443ms/step - loss: 0.0112 - accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 1s 130ms/steps: 0.0210 - accuracy: \n",
      "4/4 [==============================] - 2s 450ms/step - loss: 0.0210 - accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 1s 127ms/steps: 0.0578 - accuracy: \n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.0578 - accuracy: 0.9709 - lr: 4.7830e-04\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 1s 121ms/steps: 0.0075 - accuracy: \n",
      "4/4 [==============================] - 2s 458ms/step - loss: 0.0075 - accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 1s 131ms/steps: 0.0282 - accuracy: \n",
      "4/4 [==============================] - 2s 513ms/step - loss: 0.0282 - accuracy: 0.9903 - lr: 4.7830e-04\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 1s 120ms/steps: 0.0258 - accuracy: \n",
      "4/4 [==============================] - 2s 457ms/step - loss: 0.0258 - accuracy: 0.9903 - lr: 4.7830e-04\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 1s 121ms/steps: 0.0141 - accuracy: \n",
      "4/4 [==============================] - 2s 463ms/step - loss: 0.0141 - accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 1s 110ms/steps: 0.0212 - accuracy: \n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.0212 - accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 1s 111ms/steps: 0.0072 - accuracy: \n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.0072 - accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 1s 136ms/steps: 0.0076 - accuracy: \n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.0076 - accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 1s 131ms/steps: 0.0148 - accuracy: \n",
      "4/4 [==============================] - 2s 468ms/step - loss: 0.0148 - accuracy: 1.0000 - lr: 4.3047e-04\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 1s 118ms/steps: 0.0375 - accuracy: \n",
      "4/4 [==============================] - 2s 498ms/step - loss: 0.0375 - accuracy: 0.9806 - lr: 4.3047e-04\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 1s 146ms/steps: 0.0134 - accuracy: \n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.0134 - accuracy: 1.0000 - lr: 4.3047e-04\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 1s 141ms/steps: 0.0213 - accuracy: \n",
      "4/4 [==============================] - 2s 505ms/step - loss: 0.0213 - accuracy: 0.9903 - lr: 4.3047e-04\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 1s 139ms/steps: 0.0064 - accuracy: \n",
      "4/4 [==============================] - 2s 486ms/step - loss: 0.0064 - accuracy: 1.0000 - lr: 4.3047e-04\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 1s 127ms/steps: 0.0598 - accuracy: \n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0598 - accuracy: 0.9903 - lr: 4.3047e-04\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 1s 129ms/steps: 0.0223 - accuracy: \n",
      "4/4 [==============================] - 2s 472ms/step - loss: 0.0223 - accuracy: 0.9806 - lr: 4.3047e-04\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 1s 118ms/steps: 0.0064 - accuracy: 1.\n",
      "4/4 [==============================] - 2s 552ms/step - loss: 0.0064 - accuracy: 1.0000 - lr: 4.3047e-04\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 1s 116ms/steps: 0.0080 - accuracy: \n",
      "4/4 [==============================] - 2s 498ms/step - loss: 0.0080 - accuracy: 1.0000 - lr: 4.3047e-04\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 1s 144ms/steps: 0.0345 - accuracy: \n",
      "4/4 [==============================] - 2s 596ms/step - loss: 0.0345 - accuracy: 0.9806 - lr: 4.3047e-04\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 1s 127ms/steps: 0.0155 - accuracy: \n",
      "4/4 [==============================] - 2s 453ms/step - loss: 0.0155 - accuracy: 1.0000 - lr: 3.8742e-04\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 1s 162ms/steps: 0.0073 - accuracy: \n",
      "4/4 [==============================] - 2s 468ms/step - loss: 0.0073 - accuracy: 1.0000 - lr: 3.8742e-04\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 1s 147ms/steps: 0.0025 - accuracy: \n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.0025 - accuracy: 1.0000 - lr: 3.8742e-04\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 1s 146ms/steps: 0.0242 - accuracy: \n",
      "4/4 [==============================] - 2s 522ms/step - loss: 0.0242 - accuracy: 1.0000 - lr: 3.8742e-04\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 1s 138ms/steps: 0.0272 - accuracy: \n",
      "4/4 [==============================] - 2s 520ms/step - loss: 0.0272 - accuracy: 0.9903 - lr: 3.8742e-04\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 1s 114ms/steps: 0.0210 - accuracy: \n",
      "4/4 [==============================] - 2s 476ms/step - loss: 0.0210 - accuracy: 0.9903 - lr: 3.8742e-04\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 1s 119ms/steps: 0.0101 - accuracy: \n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.0101 - accuracy: 1.0000 - lr: 3.8742e-04\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 1s 120ms/steps: 0.0325 - accuracy: \n",
      "4/4 [==============================] - 2s 479ms/step - loss: 0.0325 - accuracy: 0.9806 - lr: 3.8742e-04\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 1s 154ms/steps: 0.0168 - accuracy: \n",
      "4/4 [==============================] - 2s 515ms/step - loss: 0.0168 - accuracy: 0.9903 - lr: 3.8742e-04\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 1s 134ms/steps: 0.0117 - accuracy: \n",
      "4/4 [==============================] - 2s 504ms/step - loss: 0.0117 - accuracy: 1.0000 - lr: 3.8742e-04\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 1s 123ms/steps: 0.0048 - accuracy: \n",
      "4/4 [==============================] - 2s 487ms/step - loss: 0.0048 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 1s 114ms/steps: 0.0033 - accuracy: \n",
      "4/4 [==============================] - 2s 526ms/step - loss: 0.0033 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 1s 116ms/steps: 0.0244 - accuracy: \n",
      "4/4 [==============================] - 2s 446ms/step - loss: 0.0244 - accuracy: 0.9806 - lr: 3.4868e-04\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 1s 133ms/steps: 0.0138 - accuracy: \n",
      "4/4 [==============================] - 2s 647ms/step - loss: 0.0138 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 1s 141ms/steps: 0.0431 - accuracy: \n",
      "4/4 [==============================] - 2s 514ms/step - loss: 0.0431 - accuracy: 0.9709 - lr: 3.4868e-04\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 1s 144ms/steps: 0.0056 - accuracy: \n",
      "4/4 [==============================] - 2s 529ms/step - loss: 0.0056 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 1s 115ms/steps: 0.0094 - accuracy: \n",
      "4/4 [==============================] - 2s 466ms/step - loss: 0.0094 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 1s 130ms/steps: 0.0214 - accuracy: \n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0214 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 1s 147ms/steps: 0.0075 - accuracy: \n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.0075 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 1s 123ms/steps: 0.0142 - accuracy: \n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.0142 - accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 1s 122ms/steps: 0.0243 - accuracy: \n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.0243 - accuracy: 0.9903 - lr: 3.1381e-04\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 1s 127ms/steps: 0.0094 - accuracy: \n",
      "4/4 [==============================] - 2s 463ms/step - loss: 0.0094 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 1s 113ms/steps: 0.0271 - accuracy: \n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.0271 - accuracy: 0.9903 - lr: 3.1381e-04\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 1s 129ms/steps: 0.0061 - accuracy: \n",
      "4/4 [==============================] - 2s 461ms/step - loss: 0.0061 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 1s 128ms/steps: 0.0061 - accuracy: \n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.0061 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 1s 148ms/steps: 0.0081 - accuracy: \n",
      "4/4 [==============================] - 2s 641ms/step - loss: 0.0081 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 1s 129ms/steps: 0.0029 - accuracy: \n",
      "4/4 [==============================] - 2s 494ms/step - loss: 0.0029 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 1s 121ms/steps: 0.0066 - accuracy: \n",
      "4/4 [==============================] - 2s 474ms/step - loss: 0.0066 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 1s 135ms/steps: 0.0053 - accuracy: \n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0053 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 1s 124ms/steps: 0.0034 - accuracy: \n",
      "4/4 [==============================] - 2s 475ms/step - loss: 0.0034 - accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 1s 117ms/steps: 0.0021 - accuracy: \n",
      "4/4 [==============================] - 2s 471ms/step - loss: 0.0021 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 1s 138ms/steps: 0.0151 - accuracy: \n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.0151 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 1s 160ms/steps: 0.0128 - accuracy: \n",
      "4/4 [==============================] - 2s 628ms/step - loss: 0.0128 - accuracy: 0.9903 - lr: 2.8243e-04\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 1s 138ms/steps: 0.0020 - accuracy: 1.\n",
      "4/4 [==============================] - 2s 519ms/step - loss: 0.0020 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 1s 161ms/steps: 0.0039 - accuracy: \n",
      "4/4 [==============================] - 2s 528ms/step - loss: 0.0039 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 1s 136ms/steps: 0.0042 - accuracy: \n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.0042 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 1s 120ms/steps: 0.0178 - accuracy: \n",
      "4/4 [==============================] - 2s 465ms/step - loss: 0.0178 - accuracy: 0.9903 - lr: 2.8243e-04\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 1s 123ms/steps: 0.0012 - accuracy: \n",
      "4/4 [==============================] - 2s 430ms/step - loss: 0.0012 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 1s 135ms/steps: 0.0194 - accuracy: \n",
      "4/4 [==============================] - 2s 496ms/step - loss: 0.0194 - accuracy: 0.9903 - lr: 2.8243e-04\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 1s 122ms/steps: 0.0016 - accuracy: 1.00\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0016 - accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 1s 118ms/steps: 0.0031 - accuracy: \n",
      "4/4 [==============================] - 2s 462ms/step - loss: 0.0031 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 1s 105ms/steps: 0.0140 - accuracy: \n",
      "4/4 [==============================] - 2s 429ms/step - loss: 0.0140 - accuracy: 0.9903 - lr: 2.5419e-04\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 1s 118ms/steps: 0.0075 - accuracy: \n",
      "4/4 [==============================] - 2s 522ms/step - loss: 0.0075 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 1s 116ms/steps: 0.0130 - accuracy: \n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.0130 - accuracy: 0.9903 - lr: 2.5419e-04\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 1s 120ms/steps: 0.0013 - accuracy: \n",
      "4/4 [==============================] - 2s 465ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 1s 145ms/steps: 0.0017 - accuracy: \n",
      "4/4 [==============================] - 2s 482ms/step - loss: 0.0017 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 1s 133ms/steps: 0.0273 - accuracy: \n",
      "4/4 [==============================] - 2s 495ms/step - loss: 0.0273 - accuracy: 0.9903 - lr: 2.5419e-04\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 1s 126ms/steps: 0.0046 - accuracy: 1.00\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.0046 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 1s 129ms/steps: 0.0042 - accuracy: \n",
      "4/4 [==============================] - 2s 449ms/step - loss: 0.0042 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 1s 131ms/steps: 0.0038 - accuracy: \n",
      "4/4 [==============================] - 2s 450ms/step - loss: 0.0038 - accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 1s 143ms/steps: 0.0138 - accuracy: 1.\n",
      "4/4 [==============================] - 2s 483ms/step - loss: 0.0138 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 1s 126ms/steps: 0.0057 - accuracy: \n",
      "4/4 [==============================] - 2s 497ms/step - loss: 0.0057 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 1s 119ms/steps: 0.0027 - accuracy: 1.\n",
      "4/4 [==============================] - 2s 488ms/step - loss: 0.0027 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 1s 110ms/steps: 0.0029 - accuracy: \n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.0029 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 1s 137ms/steps: 0.0024 - accuracy: 1.00\n",
      "4/4 [==============================] - 2s 460ms/step - loss: 0.0024 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 1s 141ms/steps: 0.0096 - accuracy: \n",
      "4/4 [==============================] - 2s 493ms/step - loss: 0.0096 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 1s 124ms/steps: 0.0013 - accuracy: 1.\n",
      "4/4 [==============================] - 2s 490ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 1s 129ms/steps: 6.9784e-04 - accuracy: \n",
      "4/4 [==============================] - 2s 565ms/step - loss: 6.9784e-04 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 1s 124ms/steps: 5.4265e-04 - accuracy: \n",
      "4/4 [==============================] - 2s 583ms/step - loss: 5.4265e-04 - accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 1s 143ms/steps: 0.0040 - accuracy: \n",
      "4/4 [==============================] - 2s 504ms/step - loss: 0.0040 - accuracy: 1.0000 - lr: 2.2877e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, train_data):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.history = {'epoch': [], 'accuracy': [], 'loss': [], 'f1_score': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.history['epoch'].append(epoch + 1)\n",
    "        self.history['accuracy'].append(logs['accuracy'])\n",
    "        self.history['loss'].append(logs['loss'])\n",
    "        \n",
    "        y_true = self.train_data.labels\n",
    "        y_pred = self.model.predict(self.train_data).argmax(axis=1)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        self.history['f1_score'].append(f1)\n",
    "\n",
    "def det_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    def lr_schedule(epoch):\n",
    "        initial_learning_rate = 0.001\n",
    "        decay = 0.9\n",
    "        epochs_drop = 10\n",
    "        learning_rate = initial_learning_rate * decay ** (epoch // epochs_drop)\n",
    "        return learning_rate\n",
    "\n",
    "    lr_callback = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model, lr_callback\n",
    "\n",
    "data_dir = 'D:/Final Year Project/database_FP/database/db1/PNG_1040 - Copy (2)' \n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "cnn_model, lr_callback = det_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "# Add the MetricsCallback to store accuracy, loss, and f1 score for each epoch\n",
    "metrics_callback = MetricsCallback(train_generator)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    callbacks=[lr_callback, metrics_callback]\n",
    ")\n",
    "\n",
    "# Save the trained model to disk\n",
    "cnn_model.save(\"my_trained_model.h5\")\n",
    "\n",
    "# Create a DataFrame to store accuracy, loss, and f1 score for each epoch\n",
    "metrics_df = pd.DataFrame(metrics_callback.history)\n",
    "metrics_df.to_excel(\"vgg_validation_metrics.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df38ab0c-8c72-4d7d-a698-a7cae90462c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
